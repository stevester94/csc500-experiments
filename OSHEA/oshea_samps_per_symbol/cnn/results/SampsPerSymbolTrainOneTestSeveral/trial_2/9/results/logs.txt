[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 438], examples_per_second: 3630.9715, train_label_loss: 2.0795, 
epoch: 1, [batch: 88 / 438], examples_per_second: 14737.5060, train_label_loss: 2.0798, 
epoch: 1, [batch: 175 / 438], examples_per_second: 14691.9072, train_label_loss: 2.0810, 
epoch: 1, [batch: 263 / 438], examples_per_second: 17925.0357, train_label_loss: 2.0792, 
epoch: 1, [batch: 350 / 438], examples_per_second: 14519.1380, train_label_loss: 2.0792, 
=============================================================
epoch: 1, val_acc_label: 0.1242, val_label_loss: 2.0795, 
=============================================================
New best
epoch: 2, [batch: 1 / 438], examples_per_second: 256.1667, train_label_loss: 2.0795, 
epoch: 2, [batch: 88 / 438], examples_per_second: 14518.2760, train_label_loss: 2.0799, 
epoch: 2, [batch: 175 / 438], examples_per_second: 14665.9397, train_label_loss: 2.0794, 
epoch: 2, [batch: 263 / 438], examples_per_second: 17547.4989, train_label_loss: 2.0797, 
epoch: 2, [batch: 350 / 438], examples_per_second: 14550.7251, train_label_loss: 2.0802, 
=============================================================
epoch: 2, val_acc_label: 0.1242, val_label_loss: 2.0795, 
=============================================================
New best
epoch: 3, [batch: 1 / 438], examples_per_second: 265.3571, train_label_loss: 2.0799, 
epoch: 3, [batch: 88 / 438], examples_per_second: 14590.0068, train_label_loss: 2.0796, 
epoch: 3, [batch: 175 / 438], examples_per_second: 14460.6545, train_label_loss: 2.0802, 
epoch: 3, [batch: 263 / 438], examples_per_second: 17546.5441, train_label_loss: 2.0802, 
epoch: 3, [batch: 350 / 438], examples_per_second: 14778.1033, train_label_loss: 2.0798, 
=============================================================
epoch: 3, val_acc_label: 0.1235, val_label_loss: 2.0795, 
=============================================================
epoch: 4, [batch: 1 / 438], examples_per_second: 266.2745, train_label_loss: 2.0798, 
epoch: 4, [batch: 88 / 438], examples_per_second: 14720.5435, train_label_loss: 2.0804, 
epoch: 4, [batch: 175 / 438], examples_per_second: 14413.6115, train_label_loss: 2.0798, 
epoch: 4, [batch: 263 / 438], examples_per_second: 17578.5932, train_label_loss: 2.0793, 
epoch: 4, [batch: 350 / 438], examples_per_second: 14624.9800, train_label_loss: 2.0791, 
=============================================================
epoch: 4, val_acc_label: 0.1242, val_label_loss: 2.0795, 
=============================================================
epoch: 5, [batch: 1 / 438], examples_per_second: 265.9042, train_label_loss: 2.0791, 
epoch: 5, [batch: 88 / 438], examples_per_second: 14575.6490, train_label_loss: 2.0795, 
epoch: 5, [batch: 175 / 438], examples_per_second: 14537.2724, train_label_loss: 2.0792, 
epoch: 5, [batch: 263 / 438], examples_per_second: 17425.9682, train_label_loss: 2.0791, 
epoch: 5, [batch: 350 / 438], examples_per_second: 14577.4414, train_label_loss: 2.0786, 
=============================================================
epoch: 5, val_acc_label: 0.1230, val_label_loss: 2.0795, 
=============================================================
epoch: 6, [batch: 1 / 438], examples_per_second: 264.6217, train_label_loss: 2.0796, 
epoch: 6, [batch: 88 / 438], examples_per_second: 14556.5318, train_label_loss: 2.0794, 
epoch: 6, [batch: 175 / 438], examples_per_second: 14505.0364, train_label_loss: 2.0794, 
epoch: 6, [batch: 263 / 438], examples_per_second: 17765.0599, train_label_loss: 2.0793, 
epoch: 6, [batch: 350 / 438], examples_per_second: 14823.3998, train_label_loss: 2.0796, 
=============================================================
epoch: 6, val_acc_label: 0.1230, val_label_loss: 2.0795, 
=============================================================
epoch: 7, [batch: 1 / 438], examples_per_second: 263.9606, train_label_loss: 2.0796, 
epoch: 7, [batch: 88 / 438], examples_per_second: 14651.6895, train_label_loss: 2.0803, 
epoch: 7, [batch: 175 / 438], examples_per_second: 14570.1179, train_label_loss: 2.0801, 
epoch: 7, [batch: 263 / 438], examples_per_second: 17933.0848, train_label_loss: 2.0803, 
epoch: 7, [batch: 350 / 438], examples_per_second: 14481.2466, train_label_loss: 2.0798, 
=============================================================
epoch: 7, val_acc_label: 0.1262, val_label_loss: 2.0795, 
=============================================================
epoch: 8, [batch: 1 / 438], examples_per_second: 264.7244, train_label_loss: 2.0806, 
epoch: 8, [batch: 88 / 438], examples_per_second: 14580.6837, train_label_loss: 2.0789, 
epoch: 8, [batch: 175 / 438], examples_per_second: 14524.8676, train_label_loss: 2.0789, 
epoch: 8, [batch: 263 / 438], examples_per_second: 17725.0731, train_label_loss: 2.0790, 
epoch: 8, [batch: 350 / 438], examples_per_second: 14638.6735, train_label_loss: 2.0797, 
=============================================================
epoch: 8, val_acc_label: 0.1230, val_label_loss: 2.0795, 
=============================================================
epoch: 9, [batch: 1 / 438], examples_per_second: 264.3540, train_label_loss: 2.0793, 
epoch: 9, [batch: 88 / 438], examples_per_second: 14503.6357, train_label_loss: 2.0792, 
epoch: 9, [batch: 175 / 438], examples_per_second: 14573.3820, train_label_loss: 2.0786, 
epoch: 9, [batch: 263 / 438], examples_per_second: 17729.6395, train_label_loss: 2.0792, 
epoch: 9, [batch: 350 / 438], examples_per_second: 14535.9423, train_label_loss: 2.0786, 
=============================================================
epoch: 9, val_acc_label: 0.1234, val_label_loss: 2.0795, 
=============================================================
epoch: 10, [batch: 1 / 438], examples_per_second: 258.5564, train_label_loss: 2.0792, 
epoch: 10, [batch: 88 / 438], examples_per_second: 14479.7090, train_label_loss: 2.0796, 
epoch: 10, [batch: 175 / 438], examples_per_second: 14472.7816, train_label_loss: 2.0803, 
epoch: 10, [batch: 263 / 438], examples_per_second: 17517.4268, train_label_loss: 2.0791, 
epoch: 10, [batch: 350 / 438], examples_per_second: 14576.1494, train_label_loss: 2.0797, 
=============================================================
epoch: 10, val_acc_label: 0.1242, val_label_loss: 2.0795, 
=============================================================
epoch: 11, [batch: 1 / 438], examples_per_second: 262.1044, train_label_loss: 2.0798, 
epoch: 11, [batch: 88 / 438], examples_per_second: 14518.5536, train_label_loss: 2.0794, 
epoch: 11, [batch: 175 / 438], examples_per_second: 14712.0537, train_label_loss: 2.0789, 
epoch: 11, [batch: 263 / 438], examples_per_second: 17651.0627, train_label_loss: 2.0795, 
epoch: 11, [batch: 350 / 438], examples_per_second: 14644.6540, train_label_loss: 2.0790, 
=============================================================
epoch: 11, val_acc_label: 0.1242, val_label_loss: 2.0795, 
=============================================================
epoch: 12, [batch: 1 / 438], examples_per_second: 264.7661, train_label_loss: 2.0798, 
epoch: 12, [batch: 88 / 438], examples_per_second: 14758.3235, train_label_loss: 2.0809, 
epoch: 12, [batch: 175 / 438], examples_per_second: 14599.9967, train_label_loss: 2.0803, 
epoch: 12, [batch: 263 / 438], examples_per_second: 17793.2745, train_label_loss: 2.0793, 
epoch: 12, [batch: 350 / 438], examples_per_second: 14485.2952, train_label_loss: 2.0792, 
=============================================================
epoch: 12, val_acc_label: 0.1234, val_label_loss: 2.0795, 
=============================================================
New best
epoch: 13, [batch: 1 / 438], examples_per_second: 262.8078, train_label_loss: 2.0793, 
epoch: 13, [batch: 88 / 438], examples_per_second: 14741.5061, train_label_loss: 2.0796, 
epoch: 13, [batch: 175 / 438], examples_per_second: 14567.8298, train_label_loss: 2.0795, 
epoch: 13, [batch: 263 / 438], examples_per_second: 17237.1812, train_label_loss: 2.0789, 
epoch: 13, [batch: 350 / 438], examples_per_second: 14592.4682, train_label_loss: 2.0786, 
=============================================================
epoch: 13, val_acc_label: 0.1266, val_label_loss: 2.0795, 
=============================================================
New best
epoch: 14, [batch: 1 / 438], examples_per_second: 261.4558, train_label_loss: 2.0796, 
epoch: 14, [batch: 88 / 438], examples_per_second: 14672.4471, train_label_loss: 2.0785, 
epoch: 14, [batch: 175 / 438], examples_per_second: 14622.6243, train_label_loss: 2.0789, 
epoch: 14, [batch: 263 / 438], examples_per_second: 17343.2330, train_label_loss: 2.0795, 
epoch: 14, [batch: 350 / 438], examples_per_second: 14679.2833, train_label_loss: 2.0799, 
=============================================================
epoch: 14, val_acc_label: 0.1234, val_label_loss: 2.0795, 
=============================================================
epoch: 15, [batch: 1 / 438], examples_per_second: 267.4928, train_label_loss: 2.0800, 
epoch: 15, [batch: 88 / 438], examples_per_second: 14519.9730, train_label_loss: 2.0789, 
epoch: 15, [batch: 175 / 438], examples_per_second: 14805.2535, train_label_loss: 2.0792, 
epoch: 15, [batch: 263 / 438], examples_per_second: 17584.1119, train_label_loss: 2.0797, 
epoch: 15, [batch: 350 / 438], examples_per_second: 14578.5106, train_label_loss: 2.0792, 
=============================================================
epoch: 15, val_acc_label: 0.1266, val_label_loss: 2.0794, 
=============================================================
New best
epoch: 16, [batch: 1 / 438], examples_per_second: 265.8284, train_label_loss: 2.0793, 
epoch: 16, [batch: 88 / 438], examples_per_second: 14536.2748, train_label_loss: 2.0795, 
epoch: 16, [batch: 175 / 438], examples_per_second: 14625.5410, train_label_loss: 2.0792, 
epoch: 16, [batch: 263 / 438], examples_per_second: 17409.8983, train_label_loss: 2.0801, 
epoch: 16, [batch: 350 / 438], examples_per_second: 14874.4060, train_label_loss: 2.0794, 
=============================================================
epoch: 16, val_acc_label: 0.1242, val_label_loss: 2.0795, 
=============================================================
epoch: 17, [batch: 1 / 438], examples_per_second: 267.7582, train_label_loss: 2.0802, 
epoch: 17, [batch: 88 / 438], examples_per_second: 14714.3248, train_label_loss: 2.0793, 
epoch: 17, [batch: 175 / 438], examples_per_second: 14621.0978, train_label_loss: 2.0799, 
epoch: 17, [batch: 263 / 438], examples_per_second: 17590.2268, train_label_loss: 2.0788, 
epoch: 17, [batch: 350 / 438], examples_per_second: 14668.9013, train_label_loss: 2.0792, 
=============================================================
epoch: 17, val_acc_label: 0.1234, val_label_loss: 2.0795, 
=============================================================
epoch: 18, [batch: 1 / 438], examples_per_second: 262.7439, train_label_loss: 2.0799, 
epoch: 18, [batch: 88 / 438], examples_per_second: 14569.7588, train_label_loss: 2.0789, 
epoch: 18, [batch: 175 / 438], examples_per_second: 14764.8128, train_label_loss: 2.0792, 
epoch: 18, [batch: 263 / 438], examples_per_second: 17690.1463, train_label_loss: 2.0782, 
epoch: 18, [batch: 350 / 438], examples_per_second: 14570.3997, train_label_loss: 2.0789, 
=============================================================
epoch: 18, val_acc_label: 0.1235, val_label_loss: 2.0795, 
=============================================================
epoch: 19, [batch: 1 / 438], examples_per_second: 262.0771, train_label_loss: 2.0800, 
epoch: 19, [batch: 88 / 438], examples_per_second: 14620.6836, train_label_loss: 2.0803, 
epoch: 19, [batch: 175 / 438], examples_per_second: 14641.8353, train_label_loss: 2.0794, 
epoch: 19, [batch: 263 / 438], examples_per_second: 17329.4412, train_label_loss: 2.0795, 
epoch: 19, [batch: 350 / 438], examples_per_second: 14670.8272, train_label_loss: 2.0793, 
=============================================================
epoch: 19, val_acc_label: 0.1235, val_label_loss: 2.0795, 
=============================================================
epoch: 20, [batch: 1 / 438], examples_per_second: 268.3409, train_label_loss: 2.0793, 
epoch: 20, [batch: 88 / 438], examples_per_second: 14518.2422, train_label_loss: 2.0792, 
epoch: 20, [batch: 175 / 438], examples_per_second: 14685.9065, train_label_loss: 2.0791, 
epoch: 20, [batch: 263 / 438], examples_per_second: 17264.6228, train_label_loss: 2.0800, 
epoch: 20, [batch: 350 / 438], examples_per_second: 14746.0368, train_label_loss: 2.0797, 
=============================================================
epoch: 20, val_acc_label: 0.1242, val_label_loss: 2.0795, 
=============================================================
epoch: 21, [batch: 1 / 438], examples_per_second: 264.0439, train_label_loss: 2.0792, 
epoch: 21, [batch: 88 / 438], examples_per_second: 14651.7240, train_label_loss: 2.0790, 
epoch: 21, [batch: 175 / 438], examples_per_second: 14540.3362, train_label_loss: 2.0795, 
epoch: 21, [batch: 263 / 438], examples_per_second: 17576.4776, train_label_loss: 2.0797, 
epoch: 21, [batch: 350 / 438], examples_per_second: 14910.6910, train_label_loss: 2.0799, 
=============================================================
epoch: 21, val_acc_label: 0.1230, val_label_loss: 2.0795, 
=============================================================
epoch: 22, [batch: 1 / 438], examples_per_second: 265.8192, train_label_loss: 2.0792, 
epoch: 22, [batch: 88 / 438], examples_per_second: 14533.0952, train_label_loss: 2.0794, 
epoch: 22, [batch: 175 / 438], examples_per_second: 14527.6483, train_label_loss: 2.0793, 
epoch: 22, [batch: 263 / 438], examples_per_second: 17292.8924, train_label_loss: 2.0794, 
epoch: 22, [batch: 350 / 438], examples_per_second: 14905.1595, train_label_loss: 2.0791, 
=============================================================
epoch: 22, val_acc_label: 0.1234, val_label_loss: 2.0795, 
=============================================================
epoch: 23, [batch: 1 / 438], examples_per_second: 266.7777, train_label_loss: 2.0793, 
epoch: 23, [batch: 88 / 438], examples_per_second: 14458.3492, train_label_loss: 2.0796, 
epoch: 23, [batch: 175 / 438], examples_per_second: 14747.3894, train_label_loss: 2.0785, 
epoch: 23, [batch: 263 / 438], examples_per_second: 16930.2890, train_label_loss: 2.0791, 
epoch: 23, [batch: 350 / 438], examples_per_second: 15131.6197, train_label_loss: 2.0795, 
=============================================================
epoch: 23, val_acc_label: 0.1266, val_label_loss: 2.0795, 
=============================================================
epoch: 24, [batch: 1 / 438], examples_per_second: 263.8720, train_label_loss: 2.0796, 
epoch: 24, [batch: 88 / 438], examples_per_second: 14614.6129, train_label_loss: 2.0799, 
epoch: 24, [batch: 175 / 438], examples_per_second: 14664.3350, train_label_loss: 2.0795, 
epoch: 24, [batch: 263 / 438], examples_per_second: 16959.9693, train_label_loss: 2.0793, 
epoch: 24, [batch: 350 / 438], examples_per_second: 15105.9250, train_label_loss: 2.0794, 
=============================================================
epoch: 24, val_acc_label: 0.1235, val_label_loss: 2.0795, 
=============================================================
epoch: 25, [batch: 1 / 438], examples_per_second: 263.5779, train_label_loss: 2.0795, 
epoch: 25, [batch: 88 / 438], examples_per_second: 14462.6403, train_label_loss: 2.0808, 
epoch: 25, [batch: 175 / 438], examples_per_second: 14612.8411, train_label_loss: 2.0794, 
epoch: 25, [batch: 263 / 438], examples_per_second: 16926.6587, train_label_loss: 2.0791, 
epoch: 25, [batch: 350 / 438], examples_per_second: 14981.9034, train_label_loss: 2.0796, 
=============================================================
epoch: 25, val_acc_label: 0.1230, val_label_loss: 2.0795, 
=============================================================
epoch: 26, [batch: 1 / 438], examples_per_second: 267.1725, train_label_loss: 2.0796, 
epoch: 26, [batch: 88 / 438], examples_per_second: 14679.4540, train_label_loss: 2.0791, 
epoch: 26, [batch: 175 / 438], examples_per_second: 14495.8980, train_label_loss: 2.0792, 
epoch: 26, [batch: 263 / 438], examples_per_second: 16914.5870, train_label_loss: 2.0793, 
epoch: 26, [batch: 350 / 438], examples_per_second: 15000.9625, train_label_loss: 2.0792, 
=============================================================
epoch: 26, val_acc_label: 0.1262, val_label_loss: 2.0795, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.12429166666666666 Target Test Label Accuracy: 0.125625
Source Val Label Accuracy: 0.126625 Target Val Label Accuracy: 0.12383333333333334
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
