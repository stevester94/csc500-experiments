{
  "experiment_name": "CNN SampsPerSymbol Train One Test Several Trial 2",
  "parameters": {
    "experiment_name": "CNN SampsPerSymbol Train One Test Several Trial 2",
    "lr": 0.001,
    "n_epoch": 1000,
    "batch_size": 256,
    "patience": 10,
    "device": "cuda",
    "source_domains": [
      8
    ],
    "target_domains": [
      2,
      6,
      10,
      12
    ],
    "x_net": [
      {
        "class": "Conv1d",
        "kargs": {
          "in_channels": 2,
          "out_channels": 50,
          "kernel_size": 7,
          "stride": 1,
          "padding": 0
        }
      },
      {
        "class": "ReLU",
        "kargs": {
          "inplace": true
        }
      },
      {
        "class": "Conv1d",
        "kargs": {
          "in_channels": 50,
          "out_channels": 50,
          "kernel_size": 7,
          "stride": 2,
          "padding": 0
        }
      },
      {
        "class": "ReLU",
        "kargs": {
          "inplace": true
        }
      },
      {
        "class": "Dropout",
        "kargs": {
          "p": 0.5
        }
      },
      {
        "class": "Flatten",
        "kargs": {}
      },
      {
        "class": "Linear",
        "kargs": {
          "in_features": 2900,
          "out_features": 256
        }
      },
      {
        "class": "ReLU",
        "kargs": {
          "inplace": true
        }
      },
      {
        "class": "Dropout",
        "kargs": {
          "p": 0.5
        }
      },
      {
        "class": "Linear",
        "kargs": {
          "in_features": 256,
          "out_features": 80
        }
      },
      {
        "class": "ReLU",
        "kargs": {
          "inplace": true
        }
      },
      {
        "class": "Linear",
        "kargs": {
          "in_features": 80,
          "out_features": 8
        }
      }
    ],
    "seed": 43
  },
  "results": {
    "source_test_label_accuracy": 0.12525,
    "source_test_label_loss": 2.079448601032825,
    "target_test_label_accuracy": 0.12325,
    "target_test_label_loss": 2.0794550247192385,
    "source_val_label_accuracy": 0.12525,
    "source_val_label_loss": 2.079431077267261,
    "target_val_label_accuracy": 0.12582291666666667,
    "target_val_label_loss": 2.079446723937988,
    "total_epochs_trained": 27,
    "total_experiment_time_secs": 162.52275347709656,
    "confusion": {
      "12": {
        "7": {
          "4": 2944
        },
        "4": {
          "4": 2991
        },
        "6": {
          "4": 3033
        },
        "2": {
          "4": 2998
        },
        "0": {
          "4": 2955
        },
        "3": {
          "4": 2934
        },
        "1": {
          "4": 3081
        },
        "5": {
          "4": 3022
        }
      },
      "6": {
        "6": {
          "4": 3001
        },
        "0": {
          "4": 2956
        },
        "5": {
          "4": 3037
        },
        "7": {
          "4": 2951
        },
        "2": {
          "4": 3007
        },
        "3": {
          "4": 2932
        },
        "1": {
          "4": 3036
        },
        "4": {
          "4": 3034
        }
      },
      "2": {
        "3": {
          "4": 3073
        },
        "1": {
          "4": 2976
        },
        "0": {
          "4": 2993
        },
        "5": {
          "4": 3023
        },
        "6": {
          "4": 2959
        },
        "7": {
          "4": 2979
        },
        "4": {
          "4": 3159
        },
        "2": {
          "4": 2931
        }
      },
      "8": {
        "2": {
          "4": 3010
        },
        "6": {
          "4": 2912
        },
        "5": {
          "4": 3013
        },
        "4": {
          "4": 3006
        },
        "1": {
          "4": 3025
        },
        "0": {
          "4": 2955
        },
        "7": {
          "4": 3028
        },
        "3": {
          "4": 3051
        }
      },
      "10": {
        "2": {
          "4": 3035
        },
        "3": {
          "4": 2972
        },
        "6": {
          "4": 3031
        },
        "4": {
          "4": 2895
        },
        "0": {
          "4": 3030
        },
        "7": {
          "4": 2998
        },
        "1": {
          "4": 3018
        },
        "5": {
          "4": 3016
        }
      }
    },
    "per_domain_accuracy": {
      "12": {
        "accuracy": 0.1248434760831455,
        "source?": false
      },
      "6": {
        "accuracy": 0.12665943057526927,
        "source?": false
      },
      "2": {
        "accuracy": 0.13111692192753083,
        "source?": false
      },
      "8": {
        "accuracy": 0.12525,
        "source?": true
      },
      "10": {
        "accuracy": 0.12065013544488436,
        "source?": false
      }
    }
  },
  "history": {
    "epoch_indices": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27
    ],
    "train_label_loss": [
      2.0795028275006437,
      2.079494140463877,
      2.0794986257814383,
      2.0794925711470653,
      2.079511255434115,
      2.0794975066293864,
      2.079511171062243,
      2.079500762294961,
      2.07949488565802,
      2.0794952960863506,
      2.079496303105463,
      2.079497188737948,
      2.0795055655039607,
      2.07949505168009,
      2.0794934159544507,
      2.0794861126163777,
      2.0795025166855554,
      2.079501993035617,
      2.079492150920711,
      2.0794842471815134,
      2.0795052416248407,
      2.0795049166570516,
      2.079494693507887,
      2.079506083166218,
      2.0795039597167273,
      2.07949563629551,
      2.079508629019402
    ],
    "val_label_loss": [
      2.0794878158163517,
      2.079534652385306,
      2.079461206781103,
      2.079518924368189,
      2.0794671926092594,
      2.0794444287076908,
      2.0794504931632507,
      2.07948995397446,
      2.079527482073358,
      2.0794942277543087,
      2.0794849979116563,
      2.0794507265090942,
      2.079482956135527,
      2.079512776212489,
      2.0795362477606916,
      2.079430856603257,
      2.0794836866094712,
      2.0794816473697093,
      2.0795430147901492,
      2.0794346941278334,
      2.079462097046223,
      2.079451304800967,
      2.0794669136087944,
      2.0794503003992935,
      2.079472442890735,
      2.0795102220900517,
      2.0794401118095887
    ]
  }
}