[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 438], examples_per_second: 3377.0829, train_label_loss: 2.0795, 
epoch: 1, [batch: 88 / 438], examples_per_second: 14661.0255, train_label_loss: 2.0787, 
epoch: 1, [batch: 175 / 438], examples_per_second: 14448.5655, train_label_loss: 2.0807, 
epoch: 1, [batch: 263 / 438], examples_per_second: 17843.3060, train_label_loss: 2.0796, 
epoch: 1, [batch: 350 / 438], examples_per_second: 14539.2228, train_label_loss: 2.0793, 
=============================================================
epoch: 1, val_acc_label: 0.1264, val_label_loss: 2.0795, 
=============================================================
New best
epoch: 2, [batch: 1 / 438], examples_per_second: 256.9186, train_label_loss: 2.0791, 
epoch: 2, [batch: 88 / 438], examples_per_second: 14639.2539, train_label_loss: 2.0793, 
epoch: 2, [batch: 175 / 438], examples_per_second: 14395.3604, train_label_loss: 2.0796, 
epoch: 2, [batch: 263 / 438], examples_per_second: 17313.8849, train_label_loss: 2.0788, 
epoch: 2, [batch: 350 / 438], examples_per_second: 14736.6690, train_label_loss: 2.0799, 
=============================================================
epoch: 2, val_acc_label: 0.1264, val_label_loss: 2.0795, 
=============================================================
New best
epoch: 3, [batch: 1 / 438], examples_per_second: 267.7592, train_label_loss: 2.0792, 
epoch: 3, [batch: 88 / 438], examples_per_second: 14688.8138, train_label_loss: 2.0788, 
epoch: 3, [batch: 175 / 438], examples_per_second: 14764.3321, train_label_loss: 2.0796, 
epoch: 3, [batch: 263 / 438], examples_per_second: 17508.2540, train_label_loss: 2.0785, 
epoch: 3, [batch: 350 / 438], examples_per_second: 14495.4234, train_label_loss: 2.0787, 
=============================================================
epoch: 3, val_acc_label: 0.1223, val_label_loss: 2.0796, 
=============================================================
epoch: 4, [batch: 1 / 438], examples_per_second: 268.0486, train_label_loss: 2.0800, 
epoch: 4, [batch: 88 / 438], examples_per_second: 14645.1476, train_label_loss: 2.0791, 
epoch: 4, [batch: 175 / 438], examples_per_second: 14519.1831, train_label_loss: 2.0795, 
epoch: 4, [batch: 263 / 438], examples_per_second: 17539.4112, train_label_loss: 2.0779, 
epoch: 4, [batch: 350 / 438], examples_per_second: 14687.0679, train_label_loss: 2.0794, 
=============================================================
epoch: 4, val_acc_label: 0.1233, val_label_loss: 2.0795, 
=============================================================
epoch: 5, [batch: 1 / 438], examples_per_second: 261.8429, train_label_loss: 2.0794, 
epoch: 5, [batch: 88 / 438], examples_per_second: 14584.5832, train_label_loss: 2.0793, 
epoch: 5, [batch: 175 / 438], examples_per_second: 14535.2706, train_label_loss: 2.0786, 
epoch: 5, [batch: 263 / 438], examples_per_second: 17623.6487, train_label_loss: 2.0801, 
epoch: 5, [batch: 350 / 438], examples_per_second: 14515.0389, train_label_loss: 2.0794, 
=============================================================
epoch: 5, val_acc_label: 0.1264, val_label_loss: 2.0795, 
=============================================================
New best
epoch: 6, [batch: 1 / 438], examples_per_second: 264.7714, train_label_loss: 2.0796, 
epoch: 6, [batch: 88 / 438], examples_per_second: 14524.3301, train_label_loss: 2.0796, 
epoch: 6, [batch: 175 / 438], examples_per_second: 14551.5547, train_label_loss: 2.0791, 
epoch: 6, [batch: 263 / 438], examples_per_second: 17764.0914, train_label_loss: 2.0792, 
epoch: 6, [batch: 350 / 438], examples_per_second: 14570.5383, train_label_loss: 2.0799, 
=============================================================
epoch: 6, val_acc_label: 0.1223, val_label_loss: 2.0795, 
=============================================================
epoch: 7, [batch: 1 / 438], examples_per_second: 264.5090, train_label_loss: 2.0794, 
epoch: 7, [batch: 88 / 438], examples_per_second: 14571.2952, train_label_loss: 2.0792, 
epoch: 7, [batch: 175 / 438], examples_per_second: 14563.0697, train_label_loss: 2.0792, 
epoch: 7, [batch: 263 / 438], examples_per_second: 17488.2798, train_label_loss: 2.0793, 
epoch: 7, [batch: 350 / 438], examples_per_second: 14553.6290, train_label_loss: 2.0793, 
=============================================================
epoch: 7, val_acc_label: 0.1223, val_label_loss: 2.0795, 
=============================================================
epoch: 8, [batch: 1 / 438], examples_per_second: 264.2948, train_label_loss: 2.0789, 
epoch: 8, [batch: 88 / 438], examples_per_second: 14610.7384, train_label_loss: 2.0801, 
epoch: 8, [batch: 175 / 438], examples_per_second: 14566.1580, train_label_loss: 2.0800, 
epoch: 8, [batch: 263 / 438], examples_per_second: 17809.7851, train_label_loss: 2.0795, 
epoch: 8, [batch: 350 / 438], examples_per_second: 14402.5203, train_label_loss: 2.0783, 
=============================================================
epoch: 8, val_acc_label: 0.1251, val_label_loss: 2.0796, 
=============================================================
epoch: 9, [batch: 1 / 438], examples_per_second: 259.1765, train_label_loss: 2.0797, 
epoch: 9, [batch: 88 / 438], examples_per_second: 14354.8416, train_label_loss: 2.0809, 
epoch: 9, [batch: 175 / 438], examples_per_second: 14432.8076, train_label_loss: 2.0790, 
epoch: 9, [batch: 263 / 438], examples_per_second: 17269.6936, train_label_loss: 2.0791, 
epoch: 9, [batch: 350 / 438], examples_per_second: 14311.5700, train_label_loss: 2.0784, 
=============================================================
epoch: 9, val_acc_label: 0.1251, val_label_loss: 2.0795, 
=============================================================
epoch: 10, [batch: 1 / 438], examples_per_second: 256.7069, train_label_loss: 2.0789, 
epoch: 10, [batch: 88 / 438], examples_per_second: 14368.8935, train_label_loss: 2.0783, 
epoch: 10, [batch: 175 / 438], examples_per_second: 14537.4534, train_label_loss: 2.0797, 
epoch: 10, [batch: 263 / 438], examples_per_second: 16959.8049, train_label_loss: 2.0800, 
epoch: 10, [batch: 350 / 438], examples_per_second: 14384.7890, train_label_loss: 2.0797, 
=============================================================
epoch: 10, val_acc_label: 0.1263, val_label_loss: 2.0795, 
=============================================================
epoch: 11, [batch: 1 / 438], examples_per_second: 259.4833, train_label_loss: 2.0786, 
epoch: 11, [batch: 88 / 438], examples_per_second: 14394.3312, train_label_loss: 2.0805, 
epoch: 11, [batch: 175 / 438], examples_per_second: 14390.3088, train_label_loss: 2.0796, 
epoch: 11, [batch: 263 / 438], examples_per_second: 17278.0715, train_label_loss: 2.0790, 
epoch: 11, [batch: 350 / 438], examples_per_second: 14386.8936, train_label_loss: 2.0795, 
=============================================================
epoch: 11, val_acc_label: 0.1251, val_label_loss: 2.0795, 
=============================================================
epoch: 12, [batch: 1 / 438], examples_per_second: 255.4863, train_label_loss: 2.0792, 
epoch: 12, [batch: 88 / 438], examples_per_second: 14404.1215, train_label_loss: 2.0795, 
epoch: 12, [batch: 175 / 438], examples_per_second: 14322.8202, train_label_loss: 2.0799, 
epoch: 12, [batch: 263 / 438], examples_per_second: 17313.9611, train_label_loss: 2.0794, 
epoch: 12, [batch: 350 / 438], examples_per_second: 14275.1804, train_label_loss: 2.0799, 
=============================================================
epoch: 12, val_acc_label: 0.1251, val_label_loss: 2.0795, 
=============================================================
epoch: 13, [batch: 1 / 438], examples_per_second: 259.1924, train_label_loss: 2.0801, 
epoch: 13, [batch: 88 / 438], examples_per_second: 14251.6444, train_label_loss: 2.0797, 
epoch: 13, [batch: 175 / 438], examples_per_second: 14231.0709, train_label_loss: 2.0794, 
epoch: 13, [batch: 263 / 438], examples_per_second: 17575.3628, train_label_loss: 2.0791, 
epoch: 13, [batch: 350 / 438], examples_per_second: 14483.2246, train_label_loss: 2.0796, 
=============================================================
epoch: 13, val_acc_label: 0.1251, val_label_loss: 2.0795, 
=============================================================
epoch: 14, [batch: 1 / 438], examples_per_second: 260.4265, train_label_loss: 2.0794, 
epoch: 14, [batch: 88 / 438], examples_per_second: 14273.8150, train_label_loss: 2.0799, 
epoch: 14, [batch: 175 / 438], examples_per_second: 14461.0082, train_label_loss: 2.0789, 
epoch: 14, [batch: 263 / 438], examples_per_second: 17403.3856, train_label_loss: 2.0801, 
epoch: 14, [batch: 350 / 438], examples_per_second: 14535.8971, train_label_loss: 2.0800, 
=============================================================
epoch: 14, val_acc_label: 0.1223, val_label_loss: 2.0795, 
=============================================================
epoch: 15, [batch: 1 / 438], examples_per_second: 267.3059, train_label_loss: 2.0799, 
epoch: 15, [batch: 88 / 438], examples_per_second: 14497.9070, train_label_loss: 2.0798, 
epoch: 15, [batch: 175 / 438], examples_per_second: 14508.9654, train_label_loss: 2.0799, 
epoch: 15, [batch: 263 / 438], examples_per_second: 17616.7387, train_label_loss: 2.0791, 
epoch: 15, [batch: 350 / 438], examples_per_second: 14545.9104, train_label_loss: 2.0803, 
=============================================================
epoch: 15, val_acc_label: 0.1223, val_label_loss: 2.0795, 
=============================================================
epoch: 16, [batch: 1 / 438], examples_per_second: 265.8141, train_label_loss: 2.0794, 
epoch: 16, [batch: 88 / 438], examples_per_second: 14436.3272, train_label_loss: 2.0793, 
epoch: 16, [batch: 175 / 438], examples_per_second: 14547.4734, train_label_loss: 2.0805, 
epoch: 16, [batch: 263 / 438], examples_per_second: 17276.3434, train_label_loss: 2.0795, 
epoch: 16, [batch: 350 / 438], examples_per_second: 14549.4152, train_label_loss: 2.0790, 
=============================================================
epoch: 16, val_acc_label: 0.1223, val_label_loss: 2.0795, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.12441666666666666 Target Test Label Accuracy: 0.12614583333333335
Source Val Label Accuracy: 0.12641666666666668 Target Val Label Accuracy: 0.123875
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
