[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 438], examples_per_second: 2059.3832, train_label_loss: 2.0793, 
epoch: 1, [batch: 88 / 438], examples_per_second: 27668.1601, train_label_loss: 2.0787, 
epoch: 1, [batch: 175 / 438], examples_per_second: 28709.3568, train_label_loss: 2.0797, 
epoch: 1, [batch: 263 / 438], examples_per_second: 28495.2501, train_label_loss: 2.0800, 
epoch: 1, [batch: 350 / 438], examples_per_second: 28477.4647, train_label_loss: 2.0804, 
=============================================================
epoch: 1, val_acc_label: 0.1261, val_label_loss: 2.0795, 
=============================================================
New best
epoch: 2, [batch: 1 / 438], examples_per_second: 467.7008, train_label_loss: 2.0792, 
epoch: 2, [batch: 88 / 438], examples_per_second: 28092.7951, train_label_loss: 2.0781, 
epoch: 2, [batch: 175 / 438], examples_per_second: 28234.3468, train_label_loss: 2.0800, 
epoch: 2, [batch: 263 / 438], examples_per_second: 28237.9804, train_label_loss: 2.0790, 
epoch: 2, [batch: 350 / 438], examples_per_second: 28125.0371, train_label_loss: 2.0804, 
=============================================================
epoch: 2, val_acc_label: 0.1213, val_label_loss: 2.0796, 
=============================================================
epoch: 3, [batch: 1 / 438], examples_per_second: 503.2891, train_label_loss: 2.0800, 
epoch: 3, [batch: 88 / 438], examples_per_second: 27924.8387, train_label_loss: 2.0795, 
epoch: 3, [batch: 175 / 438], examples_per_second: 28135.2698, train_label_loss: 2.0798, 
epoch: 3, [batch: 263 / 438], examples_per_second: 28154.6736, train_label_loss: 2.0799, 
epoch: 3, [batch: 350 / 438], examples_per_second: 28260.6892, train_label_loss: 2.0796, 
=============================================================
epoch: 3, val_acc_label: 0.1229, val_label_loss: 2.0797, 
=============================================================
epoch: 4, [batch: 1 / 438], examples_per_second: 517.0865, train_label_loss: 2.0787, 
epoch: 4, [batch: 88 / 438], examples_per_second: 28334.2100, train_label_loss: 2.0799, 
epoch: 4, [batch: 175 / 438], examples_per_second: 28225.9010, train_label_loss: 2.0796, 
epoch: 4, [batch: 263 / 438], examples_per_second: 27998.7983, train_label_loss: 2.0800, 
epoch: 4, [batch: 350 / 438], examples_per_second: 27879.8342, train_label_loss: 2.0794, 
=============================================================
epoch: 4, val_acc_label: 0.1213, val_label_loss: 2.0796, 
=============================================================
epoch: 5, [batch: 1 / 438], examples_per_second: 496.6988, train_label_loss: 2.0785, 
epoch: 5, [batch: 88 / 438], examples_per_second: 28318.4485, train_label_loss: 2.0792, 
epoch: 5, [batch: 175 / 438], examples_per_second: 28031.1817, train_label_loss: 2.0792, 
epoch: 5, [batch: 263 / 438], examples_per_second: 28448.9986, train_label_loss: 2.0789, 
epoch: 5, [batch: 350 / 438], examples_per_second: 28369.8345, train_label_loss: 2.0789, 
=============================================================
epoch: 5, val_acc_label: 0.1213, val_label_loss: 2.0795, 
=============================================================
epoch: 6, [batch: 1 / 438], examples_per_second: 509.9327, train_label_loss: 2.0789, 
epoch: 6, [batch: 88 / 438], examples_per_second: 28084.6195, train_label_loss: 2.0799, 
epoch: 6, [batch: 175 / 438], examples_per_second: 27310.6759, train_label_loss: 2.0802, 
epoch: 6, [batch: 263 / 438], examples_per_second: 27935.6138, train_label_loss: 2.0798, 
epoch: 6, [batch: 350 / 438], examples_per_second: 28225.7986, train_label_loss: 2.0797, 
=============================================================
epoch: 6, val_acc_label: 0.1213, val_label_loss: 2.0796, 
=============================================================
epoch: 7, [batch: 1 / 438], examples_per_second: 523.5220, train_label_loss: 2.0795, 
epoch: 7, [batch: 88 / 438], examples_per_second: 28160.5532, train_label_loss: 2.0785, 
epoch: 7, [batch: 175 / 438], examples_per_second: 28370.7478, train_label_loss: 2.0795, 
epoch: 7, [batch: 263 / 438], examples_per_second: 28360.2042, train_label_loss: 2.0790, 
epoch: 7, [batch: 350 / 438], examples_per_second: 28135.7443, train_label_loss: 2.0798, 
=============================================================
epoch: 7, val_acc_label: 0.1229, val_label_loss: 2.0795, 
=============================================================
New best
epoch: 8, [batch: 1 / 438], examples_per_second: 519.6760, train_label_loss: 2.0791, 
epoch: 8, [batch: 88 / 438], examples_per_second: 28434.0119, train_label_loss: 2.0789, 
epoch: 8, [batch: 175 / 438], examples_per_second: 28806.8748, train_label_loss: 2.0792, 
epoch: 8, [batch: 263 / 438], examples_per_second: 28460.7381, train_label_loss: 2.0790, 
epoch: 8, [batch: 350 / 438], examples_per_second: 28131.1182, train_label_loss: 2.0790, 
=============================================================
epoch: 8, val_acc_label: 0.1213, val_label_loss: 2.0795, 
=============================================================
epoch: 9, [batch: 1 / 438], examples_per_second: 513.7006, train_label_loss: 2.0795, 
epoch: 9, [batch: 88 / 438], examples_per_second: 27868.9217, train_label_loss: 2.0790, 
epoch: 9, [batch: 175 / 438], examples_per_second: 28238.3924, train_label_loss: 2.0789, 
epoch: 9, [batch: 263 / 438], examples_per_second: 27862.1527, train_label_loss: 2.0798, 
epoch: 9, [batch: 350 / 438], examples_per_second: 27810.5786, train_label_loss: 2.0795, 
=============================================================
epoch: 9, val_acc_label: 0.1213, val_label_loss: 2.0795, 
=============================================================
epoch: 10, [batch: 1 / 438], examples_per_second: 449.5270, train_label_loss: 2.0791, 
epoch: 10, [batch: 88 / 438], examples_per_second: 22818.0150, train_label_loss: 2.0790, 
epoch: 10, [batch: 175 / 438], examples_per_second: 22767.7794, train_label_loss: 2.0793, 
epoch: 10, [batch: 263 / 438], examples_per_second: 22647.5688, train_label_loss: 2.0789, 
epoch: 10, [batch: 350 / 438], examples_per_second: 22650.1172, train_label_loss: 2.0798, 
=============================================================
epoch: 10, val_acc_label: 0.1213, val_label_loss: 2.0795, 
=============================================================
epoch: 11, [batch: 1 / 438], examples_per_second: 423.4808, train_label_loss: 2.0792, 
epoch: 11, [batch: 88 / 438], examples_per_second: 22693.0517, train_label_loss: 2.0795, 
epoch: 11, [batch: 175 / 438], examples_per_second: 23217.6378, train_label_loss: 2.0791, 
epoch: 11, [batch: 263 / 438], examples_per_second: 23336.0394, train_label_loss: 2.0792, 
epoch: 11, [batch: 350 / 438], examples_per_second: 24590.9056, train_label_loss: 2.0793, 
=============================================================
epoch: 11, val_acc_label: 0.1229, val_label_loss: 2.0796, 
=============================================================
epoch: 12, [batch: 1 / 438], examples_per_second: 519.1455, train_label_loss: 2.0787, 
epoch: 12, [batch: 88 / 438], examples_per_second: 27696.1821, train_label_loss: 2.0805, 
epoch: 12, [batch: 175 / 438], examples_per_second: 28180.5763, train_label_loss: 2.0795, 
epoch: 12, [batch: 263 / 438], examples_per_second: 28065.4032, train_label_loss: 2.0797, 
epoch: 12, [batch: 350 / 438], examples_per_second: 28163.7794, train_label_loss: 2.0797, 
=============================================================
epoch: 12, val_acc_label: 0.1213, val_label_loss: 2.0796, 
=============================================================
epoch: 13, [batch: 1 / 438], examples_per_second: 507.4819, train_label_loss: 2.0791, 
epoch: 13, [batch: 88 / 438], examples_per_second: 27937.7918, train_label_loss: 2.0800, 
epoch: 13, [batch: 175 / 438], examples_per_second: 28059.2615, train_label_loss: 2.0790, 
epoch: 13, [batch: 263 / 438], examples_per_second: 28002.2252, train_label_loss: 2.0797, 
epoch: 13, [batch: 350 / 438], examples_per_second: 28264.9647, train_label_loss: 2.0791, 
=============================================================
epoch: 13, val_acc_label: 0.1213, val_label_loss: 2.0796, 
=============================================================
epoch: 14, [batch: 1 / 438], examples_per_second: 520.4120, train_label_loss: 2.0794, 
epoch: 14, [batch: 88 / 438], examples_per_second: 27111.9067, train_label_loss: 2.0799, 
epoch: 14, [batch: 175 / 438], examples_per_second: 26082.7901, train_label_loss: 2.0785, 
epoch: 14, [batch: 263 / 438], examples_per_second: 27983.7731, train_label_loss: 2.0789, 
epoch: 14, [batch: 350 / 438], examples_per_second: 26413.1778, train_label_loss: 2.0803, 
=============================================================
epoch: 14, val_acc_label: 0.1213, val_label_loss: 2.0795, 
=============================================================
epoch: 15, [batch: 1 / 438], examples_per_second: 458.9196, train_label_loss: 2.0801, 
epoch: 15, [batch: 88 / 438], examples_per_second: 28204.6808, train_label_loss: 2.0795, 
epoch: 15, [batch: 175 / 438], examples_per_second: 28362.1169, train_label_loss: 2.0790, 
epoch: 15, [batch: 263 / 438], examples_per_second: 26808.7323, train_label_loss: 2.0798, 
epoch: 15, [batch: 350 / 438], examples_per_second: 28293.4722, train_label_loss: 2.0793, 
=============================================================
epoch: 15, val_acc_label: 0.1213, val_label_loss: 2.0795, 
=============================================================
epoch: 16, [batch: 1 / 438], examples_per_second: 498.9818, train_label_loss: 2.0794, 
epoch: 16, [batch: 88 / 438], examples_per_second: 28023.2436, train_label_loss: 2.0795, 
epoch: 16, [batch: 175 / 438], examples_per_second: 28243.1051, train_label_loss: 2.0786, 
epoch: 16, [batch: 263 / 438], examples_per_second: 28575.4362, train_label_loss: 2.0791, 
epoch: 16, [batch: 350 / 438], examples_per_second: 28501.8452, train_label_loss: 2.0797, 
=============================================================
epoch: 16, val_acc_label: 0.1213, val_label_loss: 2.0796, 
=============================================================
epoch: 17, [batch: 1 / 438], examples_per_second: 511.8038, train_label_loss: 2.0799, 
epoch: 17, [batch: 88 / 438], examples_per_second: 28076.8115, train_label_loss: 2.0797, 
epoch: 17, [batch: 175 / 438], examples_per_second: 27649.0629, train_label_loss: 2.0797, 
epoch: 17, [batch: 263 / 438], examples_per_second: 27961.5881, train_label_loss: 2.0809, 
epoch: 17, [batch: 350 / 438], examples_per_second: 28220.7762, train_label_loss: 2.0798, 
=============================================================
epoch: 17, val_acc_label: 0.1261, val_label_loss: 2.0796, 
=============================================================
epoch: 18, [batch: 1 / 438], examples_per_second: 506.8582, train_label_loss: 2.0791, 
epoch: 18, [batch: 88 / 438], examples_per_second: 27960.6876, train_label_loss: 2.0804, 
epoch: 18, [batch: 175 / 438], examples_per_second: 28381.8328, train_label_loss: 2.0789, 
epoch: 18, [batch: 263 / 438], examples_per_second: 27303.8955, train_label_loss: 2.0805, 
epoch: 18, [batch: 350 / 438], examples_per_second: 27526.5521, train_label_loss: 2.0799, 
=============================================================
epoch: 18, val_acc_label: 0.1213, val_label_loss: 2.0796, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.12416666666666666 Target Test Label Accuracy: 0.12619791666666666
Source Val Label Accuracy: 0.122875 Target Val Label Accuracy: 0.12385416666666667
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
