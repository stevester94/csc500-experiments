[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 438], examples_per_second: 2912.5333, train_label_loss: 2.0793, 
epoch: 1, [batch: 88 / 438], examples_per_second: 14560.1552, train_label_loss: 2.0793, 
epoch: 1, [batch: 175 / 438], examples_per_second: 14637.6780, train_label_loss: 2.0800, 
epoch: 1, [batch: 263 / 438], examples_per_second: 14604.4264, train_label_loss: 2.0794, 
epoch: 1, [batch: 350 / 438], examples_per_second: 17336.0386, train_label_loss: 2.0797, 
=============================================================
epoch: 1, val_acc_label: 0.1241, val_label_loss: 2.0795, 
=============================================================
New best
epoch: 2, [batch: 1 / 438], examples_per_second: 254.3866, train_label_loss: 2.0793, 
epoch: 2, [batch: 88 / 438], examples_per_second: 14601.1104, train_label_loss: 2.0792, 
epoch: 2, [batch: 175 / 438], examples_per_second: 14531.7749, train_label_loss: 2.0797, 
epoch: 2, [batch: 263 / 438], examples_per_second: 15092.0392, train_label_loss: 2.0804, 
epoch: 2, [batch: 350 / 438], examples_per_second: 16687.5146, train_label_loss: 2.0796, 
=============================================================
epoch: 2, val_acc_label: 0.1241, val_label_loss: 2.0795, 
=============================================================
epoch: 3, [batch: 1 / 438], examples_per_second: 260.0610, train_label_loss: 2.0793, 
epoch: 3, [batch: 88 / 438], examples_per_second: 14812.1506, train_label_loss: 2.0799, 
epoch: 3, [batch: 175 / 438], examples_per_second: 14686.4237, train_label_loss: 2.0794, 
epoch: 3, [batch: 263 / 438], examples_per_second: 15550.4199, train_label_loss: 2.0794, 
epoch: 3, [batch: 350 / 438], examples_per_second: 16310.3384, train_label_loss: 2.0790, 
=============================================================
epoch: 3, val_acc_label: 0.1241, val_label_loss: 2.0795, 
=============================================================
epoch: 4, [batch: 1 / 438], examples_per_second: 254.9939, train_label_loss: 2.0789, 
epoch: 4, [batch: 88 / 438], examples_per_second: 14655.0937, train_label_loss: 2.0792, 
epoch: 4, [batch: 175 / 438], examples_per_second: 14597.9228, train_label_loss: 2.0795, 
epoch: 4, [batch: 263 / 438], examples_per_second: 16348.1412, train_label_loss: 2.0793, 
epoch: 4, [batch: 350 / 438], examples_per_second: 15402.2016, train_label_loss: 2.0796, 
=============================================================
epoch: 4, val_acc_label: 0.1241, val_label_loss: 2.0795, 
=============================================================
epoch: 5, [batch: 1 / 438], examples_per_second: 262.8139, train_label_loss: 2.0800, 
epoch: 5, [batch: 88 / 438], examples_per_second: 14487.6900, train_label_loss: 2.0798, 
epoch: 5, [batch: 175 / 438], examples_per_second: 14483.0719, train_label_loss: 2.0796, 
epoch: 5, [batch: 263 / 438], examples_per_second: 17064.9692, train_label_loss: 2.0796, 
epoch: 5, [batch: 350 / 438], examples_per_second: 14741.9295, train_label_loss: 2.0795, 
=============================================================
epoch: 5, val_acc_label: 0.1241, val_label_loss: 2.0795, 
=============================================================
epoch: 6, [batch: 1 / 438], examples_per_second: 263.3892, train_label_loss: 2.0797, 
epoch: 6, [batch: 88 / 438], examples_per_second: 14623.4232, train_label_loss: 2.0795, 
epoch: 6, [batch: 175 / 438], examples_per_second: 14513.5888, train_label_loss: 2.0784, 
epoch: 6, [batch: 263 / 438], examples_per_second: 17655.1061, train_label_loss: 2.0796, 
epoch: 6, [batch: 350 / 438], examples_per_second: 14587.2045, train_label_loss: 2.0795, 
=============================================================
epoch: 6, val_acc_label: 0.1257, val_label_loss: 2.0795, 
=============================================================
epoch: 7, [batch: 1 / 438], examples_per_second: 264.8878, train_label_loss: 2.0796, 
epoch: 7, [batch: 88 / 438], examples_per_second: 14675.8149, train_label_loss: 2.0804, 
epoch: 7, [batch: 175 / 438], examples_per_second: 14670.5392, train_label_loss: 2.0795, 
epoch: 7, [batch: 263 / 438], examples_per_second: 17773.4942, train_label_loss: 2.0793, 
epoch: 7, [batch: 350 / 438], examples_per_second: 14544.2730, train_label_loss: 2.0803, 
=============================================================
epoch: 7, val_acc_label: 0.1241, val_label_loss: 2.0795, 
=============================================================
epoch: 8, [batch: 1 / 438], examples_per_second: 264.0374, train_label_loss: 2.0798, 
epoch: 8, [batch: 88 / 438], examples_per_second: 14651.6688, train_label_loss: 2.0790, 
epoch: 8, [batch: 175 / 438], examples_per_second: 14649.1093, train_label_loss: 2.0792, 
epoch: 8, [batch: 263 / 438], examples_per_second: 18042.7730, train_label_loss: 2.0795, 
epoch: 8, [batch: 350 / 438], examples_per_second: 14653.0363, train_label_loss: 2.0793, 
=============================================================
epoch: 8, val_acc_label: 0.1241, val_label_loss: 2.0796, 
=============================================================
epoch: 9, [batch: 1 / 438], examples_per_second: 270.8732, train_label_loss: 2.0792, 
epoch: 9, [batch: 88 / 438], examples_per_second: 14652.5306, train_label_loss: 2.0781, 
epoch: 9, [batch: 175 / 438], examples_per_second: 14652.5628, train_label_loss: 2.0804, 
epoch: 9, [batch: 263 / 438], examples_per_second: 17211.0274, train_label_loss: 2.0796, 
epoch: 9, [batch: 350 / 438], examples_per_second: 14963.8874, train_label_loss: 2.0796, 
=============================================================
epoch: 9, val_acc_label: 0.1235, val_label_loss: 2.0795, 
=============================================================
epoch: 10, [batch: 1 / 438], examples_per_second: 266.2406, train_label_loss: 2.0796, 
epoch: 10, [batch: 88 / 438], examples_per_second: 14622.2512, train_label_loss: 2.0794, 
epoch: 10, [batch: 175 / 438], examples_per_second: 14554.4158, train_label_loss: 2.0803, 
epoch: 10, [batch: 263 / 438], examples_per_second: 17340.8299, train_label_loss: 2.0795, 
epoch: 10, [batch: 350 / 438], examples_per_second: 14807.5253, train_label_loss: 2.0796, 
=============================================================
epoch: 10, val_acc_label: 0.1235, val_label_loss: 2.0795, 
=============================================================
epoch: 11, [batch: 1 / 438], examples_per_second: 260.4528, train_label_loss: 2.0794, 
epoch: 11, [batch: 88 / 438], examples_per_second: 14433.8111, train_label_loss: 2.0798, 
epoch: 11, [batch: 175 / 438], examples_per_second: 14538.3901, train_label_loss: 2.0789, 
epoch: 11, [batch: 263 / 438], examples_per_second: 17655.1820, train_label_loss: 2.0797, 
epoch: 11, [batch: 350 / 438], examples_per_second: 14538.9173, train_label_loss: 2.0795, 
=============================================================
epoch: 11, val_acc_label: 0.1241, val_label_loss: 2.0795, 
=============================================================
epoch: 12, [batch: 1 / 438], examples_per_second: 265.6329, train_label_loss: 2.0795, 
epoch: 12, [batch: 88 / 438], examples_per_second: 14637.7354, train_label_loss: 2.0787, 
epoch: 12, [batch: 175 / 438], examples_per_second: 14635.4627, train_label_loss: 2.0786, 
epoch: 12, [batch: 263 / 438], examples_per_second: 17834.9872, train_label_loss: 2.0797, 
epoch: 12, [batch: 350 / 438], examples_per_second: 14510.6896, train_label_loss: 2.0794, 
=============================================================
epoch: 12, val_acc_label: 0.1233, val_label_loss: 2.0795, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.12145833333333333 Target Test Label Accuracy: 0.12517708333333333
Source Val Label Accuracy: 0.124125 Target Val Label Accuracy: 0.12444791666666667
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
