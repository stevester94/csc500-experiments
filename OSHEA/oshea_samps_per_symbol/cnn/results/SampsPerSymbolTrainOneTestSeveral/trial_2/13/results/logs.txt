[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 438], examples_per_second: 3032.2867, train_label_loss: 2.0795, 
epoch: 1, [batch: 88 / 438], examples_per_second: 11707.7073, train_label_loss: 2.0800, 
epoch: 1, [batch: 175 / 438], examples_per_second: 11801.4998, train_label_loss: 2.0792, 
epoch: 1, [batch: 263 / 438], examples_per_second: 11744.8822, train_label_loss: 2.0798, 
epoch: 1, [batch: 350 / 438], examples_per_second: 11650.0874, train_label_loss: 2.0797, 
=============================================================
epoch: 1, val_acc_label: 0.1253, val_label_loss: 2.0795, 
=============================================================
New best
epoch: 2, [batch: 1 / 438], examples_per_second: 208.2689, train_label_loss: 2.0792, 
epoch: 2, [batch: 88 / 438], examples_per_second: 11906.4890, train_label_loss: 2.0800, 
epoch: 2, [batch: 175 / 438], examples_per_second: 11738.6156, train_label_loss: 2.0802, 
epoch: 2, [batch: 263 / 438], examples_per_second: 11852.8926, train_label_loss: 2.0785, 
epoch: 2, [batch: 350 / 438], examples_per_second: 11885.3172, train_label_loss: 2.0792, 
=============================================================
epoch: 2, val_acc_label: 0.1253, val_label_loss: 2.0794, 
=============================================================
New best
epoch: 3, [batch: 1 / 438], examples_per_second: 234.6232, train_label_loss: 2.0788, 
epoch: 3, [batch: 88 / 438], examples_per_second: 11803.8872, train_label_loss: 2.0802, 
epoch: 3, [batch: 175 / 438], examples_per_second: 11684.8954, train_label_loss: 2.0791, 
epoch: 3, [batch: 263 / 438], examples_per_second: 11512.5700, train_label_loss: 2.0788, 
epoch: 3, [batch: 350 / 438], examples_per_second: 11196.1945, train_label_loss: 2.0796, 
=============================================================
epoch: 3, val_acc_label: 0.1253, val_label_loss: 2.0795, 
=============================================================
epoch: 4, [batch: 1 / 438], examples_per_second: 222.4762, train_label_loss: 2.0795, 
epoch: 4, [batch: 88 / 438], examples_per_second: 11475.7692, train_label_loss: 2.0791, 
epoch: 4, [batch: 175 / 438], examples_per_second: 11613.3549, train_label_loss: 2.0792, 
epoch: 4, [batch: 263 / 438], examples_per_second: 11589.7509, train_label_loss: 2.0797, 
epoch: 4, [batch: 350 / 438], examples_per_second: 11517.4814, train_label_loss: 2.0788, 
=============================================================
epoch: 4, val_acc_label: 0.1253, val_label_loss: 2.0795, 
=============================================================
epoch: 5, [batch: 1 / 438], examples_per_second: 226.5386, train_label_loss: 2.0791, 
epoch: 5, [batch: 88 / 438], examples_per_second: 11641.1284, train_label_loss: 2.0796, 
epoch: 5, [batch: 175 / 438], examples_per_second: 11583.2225, train_label_loss: 2.0787, 
epoch: 5, [batch: 263 / 438], examples_per_second: 11722.5086, train_label_loss: 2.0796, 
epoch: 5, [batch: 350 / 438], examples_per_second: 13211.4918, train_label_loss: 2.0789, 
=============================================================
epoch: 5, val_acc_label: 0.1221, val_label_loss: 2.0795, 
=============================================================
epoch: 6, [batch: 1 / 438], examples_per_second: 279.2987, train_label_loss: 2.0799, 
epoch: 6, [batch: 88 / 438], examples_per_second: 14571.4043, train_label_loss: 2.0796, 
epoch: 6, [batch: 175 / 438], examples_per_second: 14389.8743, train_label_loss: 2.0805, 
epoch: 6, [batch: 263 / 438], examples_per_second: 14354.2135, train_label_loss: 2.0792, 
epoch: 6, [batch: 350 / 438], examples_per_second: 14617.7414, train_label_loss: 2.0794, 
=============================================================
epoch: 6, val_acc_label: 0.1253, val_label_loss: 2.0795, 
=============================================================
epoch: 7, [batch: 1 / 438], examples_per_second: 303.2736, train_label_loss: 2.0791, 
epoch: 7, [batch: 88 / 438], examples_per_second: 14498.8116, train_label_loss: 2.0780, 
epoch: 7, [batch: 175 / 438], examples_per_second: 14469.1747, train_label_loss: 2.0795, 
epoch: 7, [batch: 263 / 438], examples_per_second: 14464.5077, train_label_loss: 2.0789, 
epoch: 7, [batch: 350 / 438], examples_per_second: 14486.9621, train_label_loss: 2.0798, 
=============================================================
epoch: 7, val_acc_label: 0.1221, val_label_loss: 2.0795, 
=============================================================
epoch: 8, [batch: 1 / 438], examples_per_second: 294.4530, train_label_loss: 2.0794, 
epoch: 8, [batch: 88 / 438], examples_per_second: 14391.1468, train_label_loss: 2.0795, 
epoch: 8, [batch: 175 / 438], examples_per_second: 14745.1384, train_label_loss: 2.0787, 
epoch: 8, [batch: 263 / 438], examples_per_second: 14512.6054, train_label_loss: 2.0803, 
epoch: 8, [batch: 350 / 438], examples_per_second: 14448.2012, train_label_loss: 2.0792, 
=============================================================
epoch: 8, val_acc_label: 0.1221, val_label_loss: 2.0795, 
=============================================================
epoch: 9, [batch: 1 / 438], examples_per_second: 307.3038, train_label_loss: 2.0793, 
epoch: 9, [batch: 88 / 438], examples_per_second: 14548.7218, train_label_loss: 2.0809, 
epoch: 9, [batch: 175 / 438], examples_per_second: 14470.6652, train_label_loss: 2.0791, 
epoch: 9, [batch: 263 / 438], examples_per_second: 14593.2456, train_label_loss: 2.0798, 
epoch: 9, [batch: 350 / 438], examples_per_second: 14474.2280, train_label_loss: 2.0793, 
=============================================================
epoch: 9, val_acc_label: 0.1221, val_label_loss: 2.0795, 
=============================================================
epoch: 10, [batch: 1 / 438], examples_per_second: 279.3559, train_label_loss: 2.0791, 
epoch: 10, [batch: 88 / 438], examples_per_second: 10620.2826, train_label_loss: 2.0799, 
epoch: 10, [batch: 175 / 438], examples_per_second: 10610.9045, train_label_loss: 2.0799, 
epoch: 10, [batch: 263 / 438], examples_per_second: 10569.2885, train_label_loss: 2.0788, 
epoch: 10, [batch: 350 / 438], examples_per_second: 10617.8539, train_label_loss: 2.0802, 
=============================================================
epoch: 10, val_acc_label: 0.1276, val_label_loss: 2.0794, 
=============================================================
New best
epoch: 11, [batch: 1 / 438], examples_per_second: 204.4481, train_label_loss: 2.0796, 
epoch: 11, [batch: 88 / 438], examples_per_second: 10592.2701, train_label_loss: 2.0797, 
epoch: 11, [batch: 175 / 438], examples_per_second: 10529.6893, train_label_loss: 2.0797, 
epoch: 11, [batch: 263 / 438], examples_per_second: 10579.0368, train_label_loss: 2.0796, 
epoch: 11, [batch: 350 / 438], examples_per_second: 10619.3554, train_label_loss: 2.0791, 
=============================================================
epoch: 11, val_acc_label: 0.1242, val_label_loss: 2.0795, 
=============================================================
epoch: 12, [batch: 1 / 438], examples_per_second: 207.6049, train_label_loss: 2.0792, 
epoch: 12, [batch: 88 / 438], examples_per_second: 10611.6736, train_label_loss: 2.0801, 
epoch: 12, [batch: 175 / 438], examples_per_second: 10637.6723, train_label_loss: 2.0797, 
epoch: 12, [batch: 263 / 438], examples_per_second: 10566.4743, train_label_loss: 2.0804, 
epoch: 12, [batch: 350 / 438], examples_per_second: 10515.1237, train_label_loss: 2.0795, 
=============================================================
epoch: 12, val_acc_label: 0.1221, val_label_loss: 2.0795, 
=============================================================
epoch: 13, [batch: 1 / 438], examples_per_second: 202.6595, train_label_loss: 2.0790, 
epoch: 13, [batch: 88 / 438], examples_per_second: 10500.3151, train_label_loss: 2.0794, 
epoch: 13, [batch: 175 / 438], examples_per_second: 10693.9626, train_label_loss: 2.0789, 
epoch: 13, [batch: 263 / 438], examples_per_second: 10675.2302, train_label_loss: 2.0801, 
epoch: 13, [batch: 350 / 438], examples_per_second: 10686.3718, train_label_loss: 2.0798, 
=============================================================
epoch: 13, val_acc_label: 0.1221, val_label_loss: 2.0795, 
=============================================================
epoch: 14, [batch: 1 / 438], examples_per_second: 203.1200, train_label_loss: 2.0796, 
epoch: 14, [batch: 88 / 438], examples_per_second: 10605.3006, train_label_loss: 2.0798, 
epoch: 14, [batch: 175 / 438], examples_per_second: 10697.7382, train_label_loss: 2.0800, 
epoch: 14, [batch: 263 / 438], examples_per_second: 10594.5175, train_label_loss: 2.0797, 
epoch: 14, [batch: 350 / 438], examples_per_second: 13341.2156, train_label_loss: 2.0795, 
=============================================================
epoch: 14, val_acc_label: 0.1221, val_label_loss: 2.0796, 
=============================================================
epoch: 15, [batch: 1 / 438], examples_per_second: 231.8784, train_label_loss: 2.0801, 
epoch: 15, [batch: 88 / 438], examples_per_second: 10480.1510, train_label_loss: 2.0796, 
epoch: 15, [batch: 175 / 438], examples_per_second: 10305.0526, train_label_loss: 2.0798, 
epoch: 15, [batch: 263 / 438], examples_per_second: 10497.9656, train_label_loss: 2.0791, 
epoch: 15, [batch: 350 / 438], examples_per_second: 10537.2837, train_label_loss: 2.0798, 
=============================================================
epoch: 15, val_acc_label: 0.1253, val_label_loss: 2.0795, 
=============================================================
epoch: 16, [batch: 1 / 438], examples_per_second: 203.2614, train_label_loss: 2.0793, 
epoch: 16, [batch: 88 / 438], examples_per_second: 10582.1465, train_label_loss: 2.0782, 
epoch: 16, [batch: 175 / 438], examples_per_second: 10461.5765, train_label_loss: 2.0792, 
epoch: 16, [batch: 263 / 438], examples_per_second: 10542.9029, train_label_loss: 2.0791, 
epoch: 16, [batch: 350 / 438], examples_per_second: 10437.2501, train_label_loss: 2.0792, 
=============================================================
epoch: 16, val_acc_label: 0.1221, val_label_loss: 2.0795, 
=============================================================
epoch: 17, [batch: 1 / 438], examples_per_second: 203.0522, train_label_loss: 2.0802, 
epoch: 17, [batch: 88 / 438], examples_per_second: 10458.3475, train_label_loss: 2.0803, 
epoch: 17, [batch: 175 / 438], examples_per_second: 10546.8750, train_label_loss: 2.0796, 
epoch: 17, [batch: 263 / 438], examples_per_second: 10462.2121, train_label_loss: 2.0802, 
epoch: 17, [batch: 350 / 438], examples_per_second: 10526.2365, train_label_loss: 2.0798, 
=============================================================
epoch: 17, val_acc_label: 0.1221, val_label_loss: 2.0795, 
=============================================================
epoch: 18, [batch: 1 / 438], examples_per_second: 203.2135, train_label_loss: 2.0799, 
epoch: 18, [batch: 88 / 438], examples_per_second: 10513.9130, train_label_loss: 2.0793, 
epoch: 18, [batch: 175 / 438], examples_per_second: 10607.1852, train_label_loss: 2.0794, 
epoch: 18, [batch: 263 / 438], examples_per_second: 10641.4589, train_label_loss: 2.0794, 
epoch: 18, [batch: 350 / 438], examples_per_second: 10488.9507, train_label_loss: 2.0798, 
=============================================================
epoch: 18, val_acc_label: 0.1253, val_label_loss: 2.0795, 
=============================================================
epoch: 19, [batch: 1 / 438], examples_per_second: 205.8287, train_label_loss: 2.0790, 
epoch: 19, [batch: 88 / 438], examples_per_second: 10636.0191, train_label_loss: 2.0796, 
epoch: 19, [batch: 175 / 438], examples_per_second: 10550.4569, train_label_loss: 2.0799, 
epoch: 19, [batch: 263 / 438], examples_per_second: 12352.1438, train_label_loss: 2.0798, 
epoch: 19, [batch: 350 / 438], examples_per_second: 13084.7264, train_label_loss: 2.0798, 
=============================================================
epoch: 19, val_acc_label: 0.1221, val_label_loss: 2.0795, 
=============================================================
epoch: 20, [batch: 1 / 438], examples_per_second: 201.8100, train_label_loss: 2.0790, 
epoch: 20, [batch: 88 / 438], examples_per_second: 10555.4186, train_label_loss: 2.0799, 
epoch: 20, [batch: 175 / 438], examples_per_second: 10669.9596, train_label_loss: 2.0806, 
epoch: 20, [batch: 263 / 438], examples_per_second: 10523.0986, train_label_loss: 2.0796, 
epoch: 20, [batch: 350 / 438], examples_per_second: 10615.8883, train_label_loss: 2.0792, 
=============================================================
epoch: 20, val_acc_label: 0.1253, val_label_loss: 2.0795, 
=============================================================
epoch: 21, [batch: 1 / 438], examples_per_second: 203.4958, train_label_loss: 2.0786, 
epoch: 21, [batch: 88 / 438], examples_per_second: 10608.3391, train_label_loss: 2.0803, 
epoch: 21, [batch: 175 / 438], examples_per_second: 10531.6741, train_label_loss: 2.0789, 
epoch: 21, [batch: 263 / 438], examples_per_second: 10479.9311, train_label_loss: 2.0796, 
epoch: 21, [batch: 350 / 438], examples_per_second: 10561.2983, train_label_loss: 2.0798, 
=============================================================
epoch: 21, val_acc_label: 0.1249, val_label_loss: 2.0795, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.124125 Target Test Label Accuracy: 0.12422916666666667
Source Val Label Accuracy: 0.127625 Target Val Label Accuracy: 0.12480208333333333
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
