[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 438], examples_per_second: 3428.1905, train_label_loss: 2.0795, 
epoch: 1, [batch: 88 / 438], examples_per_second: 27924.2794, train_label_loss: 2.0789, 
epoch: 1, [batch: 175 / 438], examples_per_second: 26924.0547, train_label_loss: 2.0795, 
epoch: 1, [batch: 263 / 438], examples_per_second: 26721.1294, train_label_loss: 2.0793, 
epoch: 1, [batch: 350 / 438], examples_per_second: 27434.7809, train_label_loss: 2.0795, 
=============================================================
epoch: 1, val_acc_label: 0.1207, val_label_loss: 2.0796, 
=============================================================
New best
epoch: 2, [batch: 1 / 438], examples_per_second: 459.0558, train_label_loss: 2.0793, 
epoch: 2, [batch: 88 / 438], examples_per_second: 28878.3043, train_label_loss: 2.0799, 
epoch: 2, [batch: 175 / 438], examples_per_second: 28974.5577, train_label_loss: 2.0790, 
epoch: 2, [batch: 263 / 438], examples_per_second: 28897.3774, train_label_loss: 2.0794, 
epoch: 2, [batch: 350 / 438], examples_per_second: 29016.9574, train_label_loss: 2.0800, 
=============================================================
epoch: 2, val_acc_label: 0.1225, val_label_loss: 2.0795, 
=============================================================
New best
epoch: 3, [batch: 1 / 438], examples_per_second: 510.9908, train_label_loss: 2.0797, 
epoch: 3, [batch: 88 / 438], examples_per_second: 28404.8232, train_label_loss: 2.0790, 
epoch: 3, [batch: 175 / 438], examples_per_second: 29058.2610, train_label_loss: 2.0797, 
epoch: 3, [batch: 263 / 438], examples_per_second: 28308.7400, train_label_loss: 2.0798, 
epoch: 3, [batch: 350 / 438], examples_per_second: 26723.4131, train_label_loss: 2.0793, 
=============================================================
epoch: 3, val_acc_label: 0.1207, val_label_loss: 2.0796, 
=============================================================
epoch: 4, [batch: 1 / 438], examples_per_second: 509.2547, train_label_loss: 2.0788, 
epoch: 4, [batch: 88 / 438], examples_per_second: 25176.4996, train_label_loss: 2.0802, 
epoch: 4, [batch: 175 / 438], examples_per_second: 14632.1662, train_label_loss: 2.0794, 
epoch: 4, [batch: 263 / 438], examples_per_second: 14311.7675, train_label_loss: 2.0797, 
epoch: 4, [batch: 350 / 438], examples_per_second: 14641.7641, train_label_loss: 2.0795, 
=============================================================
epoch: 4, val_acc_label: 0.1207, val_label_loss: 2.0796, 
=============================================================
epoch: 5, [batch: 1 / 438], examples_per_second: 257.7341, train_label_loss: 2.0786, 
epoch: 5, [batch: 88 / 438], examples_per_second: 18265.6535, train_label_loss: 2.0809, 
epoch: 5, [batch: 175 / 438], examples_per_second: 14452.5892, train_label_loss: 2.0789, 
epoch: 5, [batch: 263 / 438], examples_per_second: 14502.8757, train_label_loss: 2.0804, 
epoch: 5, [batch: 350 / 438], examples_per_second: 14495.6326, train_label_loss: 2.0788, 
=============================================================
epoch: 5, val_acc_label: 0.1259, val_label_loss: 2.0794, 
=============================================================
New best
epoch: 6, [batch: 1 / 438], examples_per_second: 254.2047, train_label_loss: 2.0795, 
epoch: 6, [batch: 88 / 438], examples_per_second: 16784.2034, train_label_loss: 2.0790, 
epoch: 6, [batch: 175 / 438], examples_per_second: 14388.5489, train_label_loss: 2.0798, 
epoch: 6, [batch: 263 / 438], examples_per_second: 14338.1496, train_label_loss: 2.0785, 
epoch: 6, [batch: 350 / 438], examples_per_second: 14329.1278, train_label_loss: 2.0805, 
=============================================================
epoch: 6, val_acc_label: 0.1259, val_label_loss: 2.0795, 
=============================================================
epoch: 7, [batch: 1 / 438], examples_per_second: 262.1595, train_label_loss: 2.0798, 
epoch: 7, [batch: 88 / 438], examples_per_second: 17224.0578, train_label_loss: 2.0801, 
epoch: 7, [batch: 175 / 438], examples_per_second: 14455.0492, train_label_loss: 2.0803, 
epoch: 7, [batch: 263 / 438], examples_per_second: 14196.7223, train_label_loss: 2.0792, 
epoch: 7, [batch: 350 / 438], examples_per_second: 13759.0393, train_label_loss: 2.0793, 
=============================================================
epoch: 7, val_acc_label: 0.1259, val_label_loss: 2.0796, 
=============================================================
epoch: 8, [batch: 1 / 438], examples_per_second: 259.8855, train_label_loss: 2.0791, 
epoch: 8, [batch: 88 / 438], examples_per_second: 17701.8047, train_label_loss: 2.0793, 
epoch: 8, [batch: 175 / 438], examples_per_second: 14402.4737, train_label_loss: 2.0786, 
epoch: 8, [batch: 263 / 438], examples_per_second: 14483.1978, train_label_loss: 2.0799, 
epoch: 8, [batch: 350 / 438], examples_per_second: 14390.5770, train_label_loss: 2.0791, 
=============================================================
epoch: 8, val_acc_label: 0.1259, val_label_loss: 2.0796, 
=============================================================
epoch: 9, [batch: 1 / 438], examples_per_second: 257.4059, train_label_loss: 2.0794, 
epoch: 9, [batch: 88 / 438], examples_per_second: 17542.9197, train_label_loss: 2.0796, 
epoch: 9, [batch: 175 / 438], examples_per_second: 14370.3214, train_label_loss: 2.0801, 
epoch: 9, [batch: 263 / 438], examples_per_second: 14299.8031, train_label_loss: 2.0802, 
epoch: 9, [batch: 350 / 438], examples_per_second: 14151.3651, train_label_loss: 2.0792, 
=============================================================
epoch: 9, val_acc_label: 0.1207, val_label_loss: 2.0795, 
=============================================================
epoch: 10, [batch: 1 / 438], examples_per_second: 264.1585, train_label_loss: 2.0793, 
epoch: 10, [batch: 88 / 438], examples_per_second: 17640.4113, train_label_loss: 2.0786, 
epoch: 10, [batch: 175 / 438], examples_per_second: 14379.0985, train_label_loss: 2.0795, 
epoch: 10, [batch: 263 / 438], examples_per_second: 14331.9884, train_label_loss: 2.0795, 
epoch: 10, [batch: 350 / 438], examples_per_second: 14290.7445, train_label_loss: 2.0791, 
=============================================================
epoch: 10, val_acc_label: 0.1225, val_label_loss: 2.0796, 
=============================================================
epoch: 11, [batch: 1 / 438], examples_per_second: 261.6086, train_label_loss: 2.0796, 
epoch: 11, [batch: 88 / 438], examples_per_second: 17880.4439, train_label_loss: 2.0789, 
epoch: 11, [batch: 175 / 438], examples_per_second: 14476.4083, train_label_loss: 2.0799, 
epoch: 11, [batch: 263 / 438], examples_per_second: 14182.6881, train_label_loss: 2.0791, 
epoch: 11, [batch: 350 / 438], examples_per_second: 13806.1919, train_label_loss: 2.0799, 
=============================================================
epoch: 11, val_acc_label: 0.1207, val_label_loss: 2.0796, 
=============================================================
epoch: 12, [batch: 1 / 438], examples_per_second: 264.7042, train_label_loss: 2.0788, 
epoch: 12, [batch: 88 / 438], examples_per_second: 17712.4445, train_label_loss: 2.0796, 
epoch: 12, [batch: 175 / 438], examples_per_second: 14616.0512, train_label_loss: 2.0791, 
epoch: 12, [batch: 263 / 438], examples_per_second: 14575.7071, train_label_loss: 2.0794, 
epoch: 12, [batch: 350 / 438], examples_per_second: 14548.8011, train_label_loss: 2.0792, 
=============================================================
epoch: 12, val_acc_label: 0.1207, val_label_loss: 2.0797, 
=============================================================
epoch: 13, [batch: 1 / 438], examples_per_second: 266.5900, train_label_loss: 2.0793, 
epoch: 13, [batch: 88 / 438], examples_per_second: 17411.9452, train_label_loss: 2.0793, 
epoch: 13, [batch: 175 / 438], examples_per_second: 14718.5396, train_label_loss: 2.0801, 
epoch: 13, [batch: 263 / 438], examples_per_second: 14535.6719, train_label_loss: 2.0785, 
epoch: 13, [batch: 350 / 438], examples_per_second: 14493.0328, train_label_loss: 2.0789, 
=============================================================
epoch: 13, val_acc_label: 0.1207, val_label_loss: 2.0795, 
=============================================================
epoch: 14, [batch: 1 / 438], examples_per_second: 259.9772, train_label_loss: 2.0792, 
epoch: 14, [batch: 88 / 438], examples_per_second: 17072.3612, train_label_loss: 2.0792, 
epoch: 14, [batch: 175 / 438], examples_per_second: 14620.7636, train_label_loss: 2.0802, 
epoch: 14, [batch: 263 / 438], examples_per_second: 14539.2505, train_label_loss: 2.0800, 
epoch: 14, [batch: 350 / 438], examples_per_second: 14604.9135, train_label_loss: 2.0795, 
=============================================================
epoch: 14, val_acc_label: 0.1207, val_label_loss: 2.0796, 
=============================================================
epoch: 15, [batch: 1 / 438], examples_per_second: 266.4378, train_label_loss: 2.0799, 
epoch: 15, [batch: 88 / 438], examples_per_second: 17681.4166, train_label_loss: 2.0796, 
epoch: 15, [batch: 175 / 438], examples_per_second: 13486.1673, train_label_loss: 2.0796, 
epoch: 15, [batch: 263 / 438], examples_per_second: 10619.0890, train_label_loss: 2.0793, 
epoch: 15, [batch: 350 / 438], examples_per_second: 10466.5499, train_label_loss: 2.0792, 
=============================================================
epoch: 15, val_acc_label: 0.1207, val_label_loss: 2.0795, 
=============================================================
epoch: 16, [batch: 1 / 438], examples_per_second: 179.8971, train_label_loss: 2.0795, 
epoch: 16, [batch: 88 / 438], examples_per_second: 12109.8749, train_label_loss: 2.0798, 
epoch: 16, [batch: 175 / 438], examples_per_second: 10385.4009, train_label_loss: 2.0794, 
epoch: 16, [batch: 263 / 438], examples_per_second: 10582.8687, train_label_loss: 2.0796, 
epoch: 16, [batch: 350 / 438], examples_per_second: 10382.8049, train_label_loss: 2.0801, 
=============================================================
epoch: 16, val_acc_label: 0.1207, val_label_loss: 2.0795, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.124875 Target Test Label Accuracy: 0.12691666666666668
Source Val Label Accuracy: 0.125875 Target Val Label Accuracy: 0.12434375
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
