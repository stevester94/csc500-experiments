[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 438], examples_per_second: 3154.8166, train_label_loss: 2.7685, 
epoch: 1, [batch: 88 / 438], examples_per_second: 11740.4922, train_label_loss: 2.0923, 
epoch: 1, [batch: 175 / 438], examples_per_second: 11760.1365, train_label_loss: 2.0948, 
epoch: 1, [batch: 263 / 438], examples_per_second: 11758.7967, train_label_loss: 2.0902, 
epoch: 1, [batch: 350 / 438], examples_per_second: 11753.6304, train_label_loss: 2.0861, 
=============================================================
epoch: 1, val_acc_label: 0.1212, val_label_loss: 2.0840, 
=============================================================
New best
epoch: 2, [batch: 1 / 438], examples_per_second: 208.0998, train_label_loss: 2.0873, 
epoch: 2, [batch: 88 / 438], examples_per_second: 17661.6030, train_label_loss: 2.0853, 
epoch: 2, [batch: 175 / 438], examples_per_second: 19534.3931, train_label_loss: 2.0850, 
epoch: 2, [batch: 263 / 438], examples_per_second: 18988.6942, train_label_loss: 2.0757, 
epoch: 2, [batch: 350 / 438], examples_per_second: 19007.7874, train_label_loss: 2.0835, 
=============================================================
epoch: 2, val_acc_label: 0.1212, val_label_loss: 2.0841, 
=============================================================
epoch: 3, [batch: 1 / 438], examples_per_second: 361.2435, train_label_loss: 2.0913, 
epoch: 3, [batch: 88 / 438], examples_per_second: 18913.2747, train_label_loss: 2.0785, 
epoch: 3, [batch: 175 / 438], examples_per_second: 18927.1928, train_label_loss: 2.0798, 
epoch: 3, [batch: 263 / 438], examples_per_second: 18959.4554, train_label_loss: 2.0861, 
epoch: 3, [batch: 350 / 438], examples_per_second: 19034.6433, train_label_loss: 2.0828, 
=============================================================
epoch: 3, val_acc_label: 0.1212, val_label_loss: 2.0804, 
=============================================================
New best
epoch: 4, [batch: 1 / 438], examples_per_second: 230.9833, train_label_loss: 2.0839, 
epoch: 4, [batch: 88 / 438], examples_per_second: 11458.8574, train_label_loss: 2.0815, 
epoch: 4, [batch: 175 / 438], examples_per_second: 11530.4053, train_label_loss: 2.0871, 
epoch: 4, [batch: 263 / 438], examples_per_second: 11496.0407, train_label_loss: 2.0840, 
epoch: 4, [batch: 350 / 438], examples_per_second: 11668.7727, train_label_loss: 2.0830, 
=============================================================
epoch: 4, val_acc_label: 0.1274, val_label_loss: 2.0799, 
=============================================================
New best
epoch: 5, [batch: 1 / 438], examples_per_second: 212.8746, train_label_loss: 2.0814, 
epoch: 5, [batch: 88 / 438], examples_per_second: 11868.2994, train_label_loss: 2.0783, 
epoch: 5, [batch: 175 / 438], examples_per_second: 11910.3768, train_label_loss: 2.0853, 
epoch: 5, [batch: 263 / 438], examples_per_second: 11906.9860, train_label_loss: 2.0819, 
epoch: 5, [batch: 350 / 438], examples_per_second: 11806.5040, train_label_loss: 2.0796, 
=============================================================
epoch: 5, val_acc_label: 0.1246, val_label_loss: 2.0805, 
=============================================================
epoch: 6, [batch: 1 / 438], examples_per_second: 218.1119, train_label_loss: 2.0788, 
epoch: 6, [batch: 88 / 438], examples_per_second: 11866.0938, train_label_loss: 2.0753, 
epoch: 6, [batch: 175 / 438], examples_per_second: 11905.7546, train_label_loss: 2.0755, 
epoch: 6, [batch: 263 / 438], examples_per_second: 11895.8421, train_label_loss: 2.0810, 
epoch: 6, [batch: 350 / 438], examples_per_second: 11908.7931, train_label_loss: 2.0804, 
=============================================================
epoch: 6, val_acc_label: 0.1212, val_label_loss: 2.0799, 
=============================================================
epoch: 7, [batch: 1 / 438], examples_per_second: 216.5060, train_label_loss: 2.0844, 
epoch: 7, [batch: 88 / 438], examples_per_second: 11881.6951, train_label_loss: 2.0800, 
epoch: 7, [batch: 175 / 438], examples_per_second: 11894.6486, train_label_loss: 2.0773, 
epoch: 7, [batch: 263 / 438], examples_per_second: 11908.3711, train_label_loss: 2.0847, 
epoch: 7, [batch: 350 / 438], examples_per_second: 11905.3661, train_label_loss: 2.0828, 
=============================================================
epoch: 7, val_acc_label: 0.1269, val_label_loss: 2.0800, 
=============================================================
epoch: 8, [batch: 1 / 438], examples_per_second: 219.0499, train_label_loss: 2.0800, 
epoch: 8, [batch: 88 / 438], examples_per_second: 11893.1857, train_label_loss: 2.0807, 
epoch: 8, [batch: 175 / 438], examples_per_second: 11909.5386, train_label_loss: 2.0817, 
epoch: 8, [batch: 263 / 438], examples_per_second: 11873.2393, train_label_loss: 2.0796, 
epoch: 8, [batch: 350 / 438], examples_per_second: 11881.3793, train_label_loss: 2.0868, 
=============================================================
epoch: 8, val_acc_label: 0.1250, val_label_loss: 2.0800, 
=============================================================
epoch: 9, [batch: 1 / 438], examples_per_second: 218.3607, train_label_loss: 2.0805, 
epoch: 9, [batch: 88 / 438], examples_per_second: 11812.2696, train_label_loss: 2.0739, 
epoch: 9, [batch: 175 / 438], examples_per_second: 11857.8727, train_label_loss: 2.0890, 
epoch: 9, [batch: 263 / 438], examples_per_second: 11875.9598, train_label_loss: 2.0839, 
epoch: 9, [batch: 350 / 438], examples_per_second: 11875.6336, train_label_loss: 2.0803, 
=============================================================
epoch: 9, val_acc_label: 0.1246, val_label_loss: 2.0799, 
=============================================================
epoch: 10, [batch: 1 / 438], examples_per_second: 217.8970, train_label_loss: 2.0825, 
epoch: 10, [batch: 88 / 438], examples_per_second: 11878.3894, train_label_loss: 2.0808, 
epoch: 10, [batch: 175 / 438], examples_per_second: 11909.4414, train_label_loss: 2.0810, 
epoch: 10, [batch: 263 / 438], examples_per_second: 11909.6919, train_label_loss: 2.0769, 
epoch: 10, [batch: 350 / 438], examples_per_second: 11852.2790, train_label_loss: 2.0823, 
=============================================================
epoch: 10, val_acc_label: 0.1246, val_label_loss: 2.0800, 
=============================================================
epoch: 11, [batch: 1 / 438], examples_per_second: 218.9075, train_label_loss: 2.0854, 
epoch: 11, [batch: 88 / 438], examples_per_second: 11889.5649, train_label_loss: 2.0776, 
epoch: 11, [batch: 175 / 438], examples_per_second: 11902.1989, train_label_loss: 2.0803, 
epoch: 11, [batch: 263 / 438], examples_per_second: 11904.6728, train_label_loss: 2.0800, 
epoch: 11, [batch: 350 / 438], examples_per_second: 11838.4844, train_label_loss: 2.0802, 
=============================================================
epoch: 11, val_acc_label: 0.1246, val_label_loss: 2.0796, 
=============================================================
New best
epoch: 12, [batch: 1 / 438], examples_per_second: 217.4617, train_label_loss: 2.0839, 
epoch: 12, [batch: 88 / 438], examples_per_second: 11924.8358, train_label_loss: 2.0833, 
epoch: 12, [batch: 175 / 438], examples_per_second: 11846.8423, train_label_loss: 2.0813, 
epoch: 12, [batch: 263 / 438], examples_per_second: 11910.9500, train_label_loss: 2.0799, 
epoch: 12, [batch: 350 / 438], examples_per_second: 11880.7205, train_label_loss: 2.0786, 
=============================================================
epoch: 12, val_acc_label: 0.1257, val_label_loss: 2.0800, 
=============================================================
epoch: 13, [batch: 1 / 438], examples_per_second: 218.6614, train_label_loss: 2.0824, 
epoch: 13, [batch: 88 / 438], examples_per_second: 11828.8454, train_label_loss: 2.0809, 
epoch: 13, [batch: 175 / 438], examples_per_second: 11905.1841, train_label_loss: 2.0838, 
epoch: 13, [batch: 263 / 438], examples_per_second: 11891.2162, train_label_loss: 2.0796, 
epoch: 13, [batch: 350 / 438], examples_per_second: 11858.4643, train_label_loss: 2.0808, 
=============================================================
epoch: 13, val_acc_label: 0.1269, val_label_loss: 2.0794, 
=============================================================
New best
epoch: 14, [batch: 1 / 438], examples_per_second: 217.4636, train_label_loss: 2.0831, 
epoch: 14, [batch: 88 / 438], examples_per_second: 11857.5205, train_label_loss: 2.0860, 
epoch: 14, [batch: 175 / 438], examples_per_second: 11906.1294, train_label_loss: 2.0796, 
epoch: 14, [batch: 263 / 438], examples_per_second: 11912.3480, train_label_loss: 2.0823, 
epoch: 14, [batch: 350 / 438], examples_per_second: 11785.1655, train_label_loss: 2.0781, 
=============================================================
epoch: 14, val_acc_label: 0.1212, val_label_loss: 2.0805, 
=============================================================
epoch: 15, [batch: 1 / 438], examples_per_second: 217.3085, train_label_loss: 2.0852, 
epoch: 15, [batch: 88 / 438], examples_per_second: 11835.4876, train_label_loss: 2.0759, 
epoch: 15, [batch: 175 / 438], examples_per_second: 11880.0723, train_label_loss: 2.0819, 
epoch: 15, [batch: 263 / 438], examples_per_second: 11887.8590, train_label_loss: 2.0774, 
epoch: 15, [batch: 350 / 438], examples_per_second: 11852.3948, train_label_loss: 2.0807, 
=============================================================
epoch: 15, val_acc_label: 0.1274, val_label_loss: 2.0796, 
=============================================================
epoch: 16, [batch: 1 / 438], examples_per_second: 218.9747, train_label_loss: 2.0804, 
epoch: 16, [batch: 88 / 438], examples_per_second: 11888.7221, train_label_loss: 2.0788, 
epoch: 16, [batch: 175 / 438], examples_per_second: 11890.8922, train_label_loss: 2.0785, 
epoch: 16, [batch: 263 / 438], examples_per_second: 11915.5793, train_label_loss: 2.0797, 
epoch: 16, [batch: 350 / 438], examples_per_second: 11875.0448, train_label_loss: 2.0819, 
=============================================================
epoch: 16, val_acc_label: 0.1246, val_label_loss: 2.0798, 
=============================================================
epoch: 17, [batch: 1 / 438], examples_per_second: 217.8575, train_label_loss: 2.0797, 
epoch: 17, [batch: 88 / 438], examples_per_second: 11884.7728, train_label_loss: 2.0798, 
epoch: 17, [batch: 175 / 438], examples_per_second: 11895.4605, train_label_loss: 2.0824, 
epoch: 17, [batch: 263 / 438], examples_per_second: 11905.1422, train_label_loss: 2.0808, 
epoch: 17, [batch: 350 / 438], examples_per_second: 11910.8870, train_label_loss: 2.0795, 
=============================================================
epoch: 17, val_acc_label: 0.1242, val_label_loss: 2.0797, 
=============================================================
epoch: 18, [batch: 1 / 438], examples_per_second: 218.1025, train_label_loss: 2.0839, 
epoch: 18, [batch: 88 / 438], examples_per_second: 11882.2558, train_label_loss: 2.0784, 
epoch: 18, [batch: 175 / 438], examples_per_second: 11855.2031, train_label_loss: 2.0789, 
epoch: 18, [batch: 263 / 438], examples_per_second: 11893.5556, train_label_loss: 2.0798, 
epoch: 18, [batch: 350 / 438], examples_per_second: 11854.7818, train_label_loss: 2.0799, 
=============================================================
epoch: 18, val_acc_label: 0.1250, val_label_loss: 2.0802, 
=============================================================
epoch: 19, [batch: 1 / 438], examples_per_second: 217.3013, train_label_loss: 2.0808, 
epoch: 19, [batch: 88 / 438], examples_per_second: 11806.7502, train_label_loss: 2.0786, 
epoch: 19, [batch: 175 / 438], examples_per_second: 11899.1970, train_label_loss: 2.0817, 
epoch: 19, [batch: 263 / 438], examples_per_second: 11857.5304, train_label_loss: 2.0824, 
epoch: 19, [batch: 350 / 438], examples_per_second: 11904.9671, train_label_loss: 2.0798, 
=============================================================
epoch: 19, val_acc_label: 0.1269, val_label_loss: 2.0796, 
=============================================================
epoch: 20, [batch: 1 / 438], examples_per_second: 217.9044, train_label_loss: 2.0803, 
epoch: 20, [batch: 88 / 438], examples_per_second: 11889.2502, train_label_loss: 2.0813, 
epoch: 20, [batch: 175 / 438], examples_per_second: 11902.0912, train_label_loss: 2.0788, 
epoch: 20, [batch: 263 / 438], examples_per_second: 11905.3267, train_label_loss: 2.0761, 
epoch: 20, [batch: 350 / 438], examples_per_second: 11904.5044, train_label_loss: 2.0788, 
=============================================================
epoch: 20, val_acc_label: 0.1274, val_label_loss: 2.0797, 
=============================================================
epoch: 21, [batch: 1 / 438], examples_per_second: 217.1359, train_label_loss: 2.0782, 
epoch: 21, [batch: 88 / 438], examples_per_second: 11874.2599, train_label_loss: 2.0805, 
epoch: 21, [batch: 175 / 438], examples_per_second: 11913.3752, train_label_loss: 2.0779, 
epoch: 21, [batch: 263 / 438], examples_per_second: 11897.4433, train_label_loss: 2.0803, 
epoch: 21, [batch: 350 / 438], examples_per_second: 11911.0814, train_label_loss: 2.0853, 
=============================================================
epoch: 21, val_acc_label: 0.1242, val_label_loss: 2.0798, 
=============================================================
epoch: 22, [batch: 1 / 438], examples_per_second: 218.0146, train_label_loss: 2.0801, 
epoch: 22, [batch: 88 / 438], examples_per_second: 11890.6636, train_label_loss: 2.0795, 
epoch: 22, [batch: 175 / 438], examples_per_second: 11909.7041, train_label_loss: 2.0818, 
epoch: 22, [batch: 263 / 438], examples_per_second: 11908.5001, train_label_loss: 2.0776, 
epoch: 22, [batch: 350 / 438], examples_per_second: 11909.3109, train_label_loss: 2.0784, 
=============================================================
epoch: 22, val_acc_label: 0.1269, val_label_loss: 2.0795, 
=============================================================
epoch: 23, [batch: 1 / 438], examples_per_second: 218.0851, train_label_loss: 2.0819, 
epoch: 23, [batch: 88 / 438], examples_per_second: 11895.6952, train_label_loss: 2.0811, 
epoch: 23, [batch: 175 / 438], examples_per_second: 11907.0384, train_label_loss: 2.0802, 
epoch: 23, [batch: 263 / 438], examples_per_second: 11858.9293, train_label_loss: 2.0818, 
epoch: 23, [batch: 350 / 438], examples_per_second: 11895.7149, train_label_loss: 2.0796, 
=============================================================
epoch: 23, val_acc_label: 0.1274, val_label_loss: 2.0795, 
=============================================================
epoch: 24, [batch: 1 / 438], examples_per_second: 216.4726, train_label_loss: 2.0825, 
epoch: 24, [batch: 88 / 438], examples_per_second: 11874.0727, train_label_loss: 2.0803, 
epoch: 24, [batch: 175 / 438], examples_per_second: 11887.8037, train_label_loss: 2.0776, 
epoch: 24, [batch: 263 / 438], examples_per_second: 11874.2271, train_label_loss: 2.0779, 
epoch: 24, [batch: 350 / 438], examples_per_second: 11913.5469, train_label_loss: 2.0794, 
=============================================================
epoch: 24, val_acc_label: 0.1269, val_label_loss: 2.0796, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.12129166666666667 Target Test Label Accuracy: 0.12541666666666668
Source Val Label Accuracy: 0.126875 Target Val Label Accuracy: 0.12473958333333333
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
