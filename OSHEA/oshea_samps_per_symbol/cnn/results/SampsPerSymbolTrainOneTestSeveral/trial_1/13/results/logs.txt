[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 438], examples_per_second: 3150.4383, train_label_loss: 2.7658, 
epoch: 1, [batch: 88 / 438], examples_per_second: 11272.1224, train_label_loss: 2.0971, 
epoch: 1, [batch: 175 / 438], examples_per_second: 11273.8174, train_label_loss: 2.0851, 
epoch: 1, [batch: 263 / 438], examples_per_second: 11259.8846, train_label_loss: 2.0865, 
epoch: 1, [batch: 350 / 438], examples_per_second: 11271.0180, train_label_loss: 2.0878, 
=============================================================
epoch: 1, val_acc_label: 0.1251, val_label_loss: 2.0826, 
=============================================================
New best
epoch: 2, [batch: 1 / 438], examples_per_second: 198.7538, train_label_loss: 2.0894, 
epoch: 2, [batch: 88 / 438], examples_per_second: 11296.0754, train_label_loss: 2.0856, 
epoch: 2, [batch: 175 / 438], examples_per_second: 11263.8002, train_label_loss: 2.0930, 
epoch: 2, [batch: 263 / 438], examples_per_second: 11267.1228, train_label_loss: 2.0830, 
epoch: 2, [batch: 350 / 438], examples_per_second: 11265.4017, train_label_loss: 2.0835, 
=============================================================
epoch: 2, val_acc_label: 0.1223, val_label_loss: 2.0815, 
=============================================================
New best
epoch: 3, [batch: 1 / 438], examples_per_second: 207.1902, train_label_loss: 2.0818, 
epoch: 3, [batch: 88 / 438], examples_per_second: 11260.3203, train_label_loss: 2.0787, 
epoch: 3, [batch: 175 / 438], examples_per_second: 11263.1687, train_label_loss: 2.0801, 
epoch: 3, [batch: 263 / 438], examples_per_second: 11266.9589, train_label_loss: 2.0858, 
epoch: 3, [batch: 350 / 438], examples_per_second: 11268.7543, train_label_loss: 2.0882, 
=============================================================
epoch: 3, val_acc_label: 0.1270, val_label_loss: 2.0808, 
=============================================================
New best
epoch: 4, [batch: 1 / 438], examples_per_second: 206.1900, train_label_loss: 2.0858, 
epoch: 4, [batch: 88 / 438], examples_per_second: 11275.2625, train_label_loss: 2.0784, 
epoch: 4, [batch: 175 / 438], examples_per_second: 11264.3489, train_label_loss: 2.0810, 
epoch: 4, [batch: 263 / 438], examples_per_second: 11258.5778, train_label_loss: 2.0770, 
epoch: 4, [batch: 350 / 438], examples_per_second: 11269.8894, train_label_loss: 2.0838, 
=============================================================
epoch: 4, val_acc_label: 0.1270, val_label_loss: 2.0797, 
=============================================================
New best
epoch: 5, [batch: 1 / 438], examples_per_second: 206.2672, train_label_loss: 2.0771, 
epoch: 5, [batch: 88 / 438], examples_per_second: 11267.8517, train_label_loss: 2.0793, 
epoch: 5, [batch: 175 / 438], examples_per_second: 11268.8725, train_label_loss: 2.0815, 
epoch: 5, [batch: 263 / 438], examples_per_second: 11266.4256, train_label_loss: 2.0788, 
epoch: 5, [batch: 350 / 438], examples_per_second: 11271.9197, train_label_loss: 2.0813, 
=============================================================
epoch: 5, val_acc_label: 0.1251, val_label_loss: 2.0803, 
=============================================================
epoch: 6, [batch: 1 / 438], examples_per_second: 206.8332, train_label_loss: 2.0784, 
epoch: 6, [batch: 88 / 438], examples_per_second: 11280.4786, train_label_loss: 2.0860, 
epoch: 6, [batch: 175 / 438], examples_per_second: 11271.1758, train_label_loss: 2.0794, 
epoch: 6, [batch: 263 / 438], examples_per_second: 11272.9540, train_label_loss: 2.0812, 
epoch: 6, [batch: 350 / 438], examples_per_second: 11274.9658, train_label_loss: 2.0839, 
=============================================================
epoch: 6, val_acc_label: 0.1270, val_label_loss: 2.0802, 
=============================================================
epoch: 7, [batch: 1 / 438], examples_per_second: 207.5621, train_label_loss: 2.0789, 
epoch: 7, [batch: 88 / 438], examples_per_second: 11261.7810, train_label_loss: 2.0860, 
epoch: 7, [batch: 175 / 438], examples_per_second: 11248.6839, train_label_loss: 2.0827, 
epoch: 7, [batch: 263 / 438], examples_per_second: 11263.2830, train_label_loss: 2.0821, 
epoch: 7, [batch: 350 / 438], examples_per_second: 11264.6967, train_label_loss: 2.0799, 
=============================================================
epoch: 7, val_acc_label: 0.1273, val_label_loss: 2.0797, 
=============================================================
epoch: 8, [batch: 1 / 438], examples_per_second: 207.0686, train_label_loss: 2.0797, 
epoch: 8, [batch: 88 / 438], examples_per_second: 11277.1395, train_label_loss: 2.0800, 
epoch: 8, [batch: 175 / 438], examples_per_second: 11277.6324, train_label_loss: 2.0829, 
epoch: 8, [batch: 263 / 438], examples_per_second: 11278.6041, train_label_loss: 2.0797, 
epoch: 8, [batch: 350 / 438], examples_per_second: 11344.5719, train_label_loss: 2.0776, 
=============================================================
epoch: 8, val_acc_label: 0.1251, val_label_loss: 2.0799, 
=============================================================
epoch: 9, [batch: 1 / 438], examples_per_second: 280.9329, train_label_loss: 2.0793, 
epoch: 9, [batch: 88 / 438], examples_per_second: 18147.4812, train_label_loss: 2.0843, 
epoch: 9, [batch: 175 / 438], examples_per_second: 18173.9747, train_label_loss: 2.0815, 
epoch: 9, [batch: 263 / 438], examples_per_second: 18153.9229, train_label_loss: 2.0809, 
epoch: 9, [batch: 350 / 438], examples_per_second: 18158.1378, train_label_loss: 2.0799, 
=============================================================
epoch: 9, val_acc_label: 0.1251, val_label_loss: 2.0799, 
=============================================================
epoch: 10, [batch: 1 / 438], examples_per_second: 351.0967, train_label_loss: 2.0800, 
epoch: 10, [batch: 88 / 438], examples_per_second: 18179.2021, train_label_loss: 2.0730, 
epoch: 10, [batch: 175 / 438], examples_per_second: 18119.3952, train_label_loss: 2.0809, 
epoch: 10, [batch: 263 / 438], examples_per_second: 18302.6042, train_label_loss: 2.0804, 
epoch: 10, [batch: 350 / 438], examples_per_second: 11262.9270, train_label_loss: 2.0842, 
=============================================================
epoch: 10, val_acc_label: 0.1263, val_label_loss: 2.0801, 
=============================================================
epoch: 11, [batch: 1 / 438], examples_per_second: 207.4992, train_label_loss: 2.0826, 
epoch: 11, [batch: 88 / 438], examples_per_second: 11264.9358, train_label_loss: 2.0773, 
epoch: 11, [batch: 175 / 438], examples_per_second: 11262.8374, train_label_loss: 2.0800, 
epoch: 11, [batch: 263 / 438], examples_per_second: 11268.8643, train_label_loss: 2.0777, 
epoch: 11, [batch: 350 / 438], examples_per_second: 11266.1028, train_label_loss: 2.0800, 
=============================================================
epoch: 11, val_acc_label: 0.1251, val_label_loss: 2.0798, 
=============================================================
epoch: 12, [batch: 1 / 438], examples_per_second: 207.5275, train_label_loss: 2.0795, 
epoch: 12, [batch: 88 / 438], examples_per_second: 11268.1575, train_label_loss: 2.0779, 
epoch: 12, [batch: 175 / 438], examples_per_second: 11266.1001, train_label_loss: 2.0787, 
epoch: 12, [batch: 263 / 438], examples_per_second: 11243.9974, train_label_loss: 2.0809, 
epoch: 12, [batch: 350 / 438], examples_per_second: 11255.8525, train_label_loss: 2.0838, 
=============================================================
epoch: 12, val_acc_label: 0.1223, val_label_loss: 2.0797, 
=============================================================
epoch: 13, [batch: 1 / 438], examples_per_second: 207.6692, train_label_loss: 2.0831, 
epoch: 13, [batch: 88 / 438], examples_per_second: 11262.2291, train_label_loss: 2.0788, 
epoch: 13, [batch: 175 / 438], examples_per_second: 11268.9160, train_label_loss: 2.0831, 
epoch: 13, [batch: 263 / 438], examples_per_second: 11264.4955, train_label_loss: 2.0815, 
epoch: 13, [batch: 350 / 438], examples_per_second: 11260.8918, train_label_loss: 2.0824, 
=============================================================
epoch: 13, val_acc_label: 0.1263, val_label_loss: 2.0799, 
=============================================================
epoch: 14, [batch: 1 / 438], examples_per_second: 206.9348, train_label_loss: 2.0762, 
epoch: 14, [batch: 88 / 438], examples_per_second: 11283.9764, train_label_loss: 2.0808, 
epoch: 14, [batch: 175 / 438], examples_per_second: 11283.4749, train_label_loss: 2.0827, 
epoch: 14, [batch: 263 / 438], examples_per_second: 11281.4926, train_label_loss: 2.0787, 
epoch: 14, [batch: 350 / 438], examples_per_second: 11297.9880, train_label_loss: 2.0802, 
=============================================================
epoch: 14, val_acc_label: 0.1251, val_label_loss: 2.0801, 
=============================================================
epoch: 15, [batch: 1 / 438], examples_per_second: 207.1436, train_label_loss: 2.0754, 
epoch: 15, [batch: 88 / 438], examples_per_second: 11273.1072, train_label_loss: 2.0802, 
epoch: 15, [batch: 175 / 438], examples_per_second: 11274.7604, train_label_loss: 2.0800, 
epoch: 15, [batch: 263 / 438], examples_per_second: 11268.9019, train_label_loss: 2.0795, 
epoch: 15, [batch: 350 / 438], examples_per_second: 11272.2013, train_label_loss: 2.0802, 
=============================================================
epoch: 15, val_acc_label: 0.1251, val_label_loss: 2.0798, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.123875 Target Test Label Accuracy: 0.12496875
Source Val Label Accuracy: 0.12695833333333334 Target Val Label Accuracy: 0.12534375
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
