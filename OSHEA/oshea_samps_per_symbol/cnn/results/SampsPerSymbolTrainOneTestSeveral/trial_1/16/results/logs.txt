[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 438], examples_per_second: 3382.0291, train_label_loss: 2.7683, 
epoch: 1, [batch: 88 / 438], examples_per_second: 11267.1504, train_label_loss: 2.0846, 
epoch: 1, [batch: 175 / 438], examples_per_second: 11281.4213, train_label_loss: 2.0815, 
epoch: 1, [batch: 263 / 438], examples_per_second: 11279.3029, train_label_loss: 2.0791, 
epoch: 1, [batch: 350 / 438], examples_per_second: 11276.3813, train_label_loss: 2.0915, 
=============================================================
epoch: 1, val_acc_label: 0.1221, val_label_loss: 2.0811, 
=============================================================
New best
epoch: 2, [batch: 1 / 438], examples_per_second: 201.1558, train_label_loss: 2.0821, 
epoch: 2, [batch: 88 / 438], examples_per_second: 11265.4235, train_label_loss: 2.0856, 
epoch: 2, [batch: 175 / 438], examples_per_second: 11241.2849, train_label_loss: 2.0845, 
epoch: 2, [batch: 263 / 438], examples_per_second: 11284.6076, train_label_loss: 2.0931, 
epoch: 2, [batch: 350 / 438], examples_per_second: 11276.8768, train_label_loss: 2.0848, 
=============================================================
epoch: 2, val_acc_label: 0.1221, val_label_loss: 2.0810, 
=============================================================
New best
epoch: 3, [batch: 1 / 438], examples_per_second: 206.1654, train_label_loss: 2.0856, 
epoch: 3, [batch: 88 / 438], examples_per_second: 11274.0242, train_label_loss: 2.0800, 
epoch: 3, [batch: 175 / 438], examples_per_second: 11275.8137, train_label_loss: 2.0835, 
epoch: 3, [batch: 263 / 438], examples_per_second: 11277.3092, train_label_loss: 2.0761, 
epoch: 3, [batch: 350 / 438], examples_per_second: 11273.3045, train_label_loss: 2.0829, 
=============================================================
epoch: 3, val_acc_label: 0.1221, val_label_loss: 2.0804, 
=============================================================
New best
epoch: 4, [batch: 1 / 438], examples_per_second: 206.9248, train_label_loss: 2.0810, 
epoch: 4, [batch: 88 / 438], examples_per_second: 11275.1591, train_label_loss: 2.0862, 
epoch: 4, [batch: 175 / 438], examples_per_second: 11280.6857, train_label_loss: 2.0840, 
epoch: 4, [batch: 263 / 438], examples_per_second: 11279.7674, train_label_loss: 2.0785, 
epoch: 4, [batch: 350 / 438], examples_per_second: 11271.5620, train_label_loss: 2.0810, 
=============================================================
epoch: 4, val_acc_label: 0.1253, val_label_loss: 2.0809, 
=============================================================
epoch: 5, [batch: 1 / 438], examples_per_second: 206.9452, train_label_loss: 2.0797, 
epoch: 5, [batch: 88 / 438], examples_per_second: 11274.1562, train_label_loss: 2.0827, 
epoch: 5, [batch: 175 / 438], examples_per_second: 11278.9927, train_label_loss: 2.0849, 
epoch: 5, [batch: 263 / 438], examples_per_second: 11286.5378, train_label_loss: 2.0802, 
epoch: 5, [batch: 350 / 438], examples_per_second: 11276.5651, train_label_loss: 2.0820, 
=============================================================
epoch: 5, val_acc_label: 0.1253, val_label_loss: 2.0799, 
=============================================================
New best
epoch: 6, [batch: 1 / 438], examples_per_second: 206.8747, train_label_loss: 2.0855, 
epoch: 6, [batch: 88 / 438], examples_per_second: 11274.2378, train_label_loss: 2.0802, 
epoch: 6, [batch: 175 / 438], examples_per_second: 11273.6296, train_label_loss: 2.0830, 
epoch: 6, [batch: 263 / 438], examples_per_second: 11275.4857, train_label_loss: 2.0762, 
epoch: 6, [batch: 350 / 438], examples_per_second: 11279.1275, train_label_loss: 2.0821, 
=============================================================
epoch: 6, val_acc_label: 0.1276, val_label_loss: 2.0797, 
=============================================================
New best
epoch: 7, [batch: 1 / 438], examples_per_second: 206.9154, train_label_loss: 2.0836, 
epoch: 7, [batch: 88 / 438], examples_per_second: 11275.0584, train_label_loss: 2.0839, 
epoch: 7, [batch: 175 / 438], examples_per_second: 11275.9634, train_label_loss: 2.0787, 
epoch: 7, [batch: 263 / 438], examples_per_second: 11342.1698, train_label_loss: 2.0794, 
epoch: 7, [batch: 350 / 438], examples_per_second: 15610.4159, train_label_loss: 2.0808, 
=============================================================
epoch: 7, val_acc_label: 0.1249, val_label_loss: 2.0807, 
=============================================================
epoch: 8, [batch: 1 / 438], examples_per_second: 351.0340, train_label_loss: 2.0836, 
epoch: 8, [batch: 88 / 438], examples_per_second: 18108.7946, train_label_loss: 2.0886, 
epoch: 8, [batch: 175 / 438], examples_per_second: 18183.0555, train_label_loss: 2.0791, 
epoch: 8, [batch: 263 / 438], examples_per_second: 18174.5246, train_label_loss: 2.0847, 
epoch: 8, [batch: 350 / 438], examples_per_second: 18186.7654, train_label_loss: 2.0806, 
=============================================================
epoch: 8, val_acc_label: 0.1249, val_label_loss: 2.0798, 
=============================================================
epoch: 9, [batch: 1 / 438], examples_per_second: 350.9815, train_label_loss: 2.0816, 
epoch: 9, [batch: 88 / 438], examples_per_second: 18185.6927, train_label_loss: 2.0748, 
epoch: 9, [batch: 175 / 438], examples_per_second: 15734.0655, train_label_loss: 2.0781, 
epoch: 9, [batch: 263 / 438], examples_per_second: 11284.3205, train_label_loss: 2.0768, 
epoch: 9, [batch: 350 / 438], examples_per_second: 11285.1897, train_label_loss: 2.0799, 
=============================================================
epoch: 9, val_acc_label: 0.1276, val_label_loss: 2.0796, 
=============================================================
New best
epoch: 10, [batch: 1 / 438], examples_per_second: 205.7315, train_label_loss: 2.0816, 
epoch: 10, [batch: 88 / 438], examples_per_second: 11261.5244, train_label_loss: 2.0809, 
epoch: 10, [batch: 175 / 438], examples_per_second: 11268.6373, train_label_loss: 2.0767, 
epoch: 10, [batch: 263 / 438], examples_per_second: 11265.2288, train_label_loss: 2.0813, 
epoch: 10, [batch: 350 / 438], examples_per_second: 11263.6114, train_label_loss: 2.0796, 
=============================================================
epoch: 10, val_acc_label: 0.1276, val_label_loss: 2.0800, 
=============================================================
epoch: 11, [batch: 1 / 438], examples_per_second: 207.0641, train_label_loss: 2.0788, 
epoch: 11, [batch: 88 / 438], examples_per_second: 11293.9149, train_label_loss: 2.0789, 
epoch: 11, [batch: 175 / 438], examples_per_second: 11273.5086, train_label_loss: 2.0808, 
epoch: 11, [batch: 263 / 438], examples_per_second: 11264.5009, train_label_loss: 2.0809, 
epoch: 11, [batch: 350 / 438], examples_per_second: 11269.8500, train_label_loss: 2.0775, 
=============================================================
epoch: 11, val_acc_label: 0.1253, val_label_loss: 2.0798, 
=============================================================
epoch: 12, [batch: 1 / 438], examples_per_second: 207.2838, train_label_loss: 2.0819, 
epoch: 12, [batch: 88 / 438], examples_per_second: 11281.8873, train_label_loss: 2.0857, 
epoch: 12, [batch: 175 / 438], examples_per_second: 11281.9800, train_label_loss: 2.0772, 
epoch: 12, [batch: 263 / 438], examples_per_second: 11283.1186, train_label_loss: 2.0816, 
epoch: 12, [batch: 350 / 438], examples_per_second: 11281.4064, train_label_loss: 2.0825, 
=============================================================
epoch: 12, val_acc_label: 0.1221, val_label_loss: 2.0797, 
=============================================================
epoch: 13, [batch: 1 / 438], examples_per_second: 207.0077, train_label_loss: 2.0801, 
epoch: 13, [batch: 88 / 438], examples_per_second: 11286.6091, train_label_loss: 2.0812, 
epoch: 13, [batch: 175 / 438], examples_per_second: 11278.7271, train_label_loss: 2.0830, 
epoch: 13, [batch: 263 / 438], examples_per_second: 11284.6264, train_label_loss: 2.0764, 
epoch: 13, [batch: 350 / 438], examples_per_second: 11279.3263, train_label_loss: 2.0797, 
=============================================================
epoch: 13, val_acc_label: 0.1239, val_label_loss: 2.0801, 
=============================================================
epoch: 14, [batch: 1 / 438], examples_per_second: 206.9852, train_label_loss: 2.0788, 
epoch: 14, [batch: 88 / 438], examples_per_second: 11282.5345, train_label_loss: 2.0810, 
epoch: 14, [batch: 175 / 438], examples_per_second: 11259.4354, train_label_loss: 2.0855, 
epoch: 14, [batch: 263 / 438], examples_per_second: 11275.9647, train_label_loss: 2.0773, 
epoch: 14, [batch: 350 / 438], examples_per_second: 11278.3105, train_label_loss: 2.0803, 
=============================================================
epoch: 14, val_acc_label: 0.1221, val_label_loss: 2.0802, 
=============================================================
epoch: 15, [batch: 1 / 438], examples_per_second: 206.9838, train_label_loss: 2.0806, 
epoch: 15, [batch: 88 / 438], examples_per_second: 11280.3383, train_label_loss: 2.0821, 
epoch: 15, [batch: 175 / 438], examples_per_second: 11274.7930, train_label_loss: 2.0800, 
epoch: 15, [batch: 263 / 438], examples_per_second: 11279.7243, train_label_loss: 2.0775, 
epoch: 15, [batch: 350 / 438], examples_per_second: 11284.1359, train_label_loss: 2.0760, 
=============================================================
epoch: 15, val_acc_label: 0.1253, val_label_loss: 2.0797, 
=============================================================
epoch: 16, [batch: 1 / 438], examples_per_second: 207.5040, train_label_loss: 2.0809, 
epoch: 16, [batch: 88 / 438], examples_per_second: 11270.8725, train_label_loss: 2.0802, 
epoch: 16, [batch: 175 / 438], examples_per_second: 11271.9156, train_label_loss: 2.0782, 
epoch: 16, [batch: 263 / 438], examples_per_second: 11270.8469, train_label_loss: 2.0816, 
epoch: 16, [batch: 350 / 438], examples_per_second: 11274.6597, train_label_loss: 2.0846, 
=============================================================
epoch: 16, val_acc_label: 0.1221, val_label_loss: 2.0797, 
=============================================================
epoch: 17, [batch: 1 / 438], examples_per_second: 207.3664, train_label_loss: 2.0793, 
epoch: 17, [batch: 88 / 438], examples_per_second: 11287.3237, train_label_loss: 2.0798, 
epoch: 17, [batch: 175 / 438], examples_per_second: 11286.9650, train_label_loss: 2.0781, 
epoch: 17, [batch: 263 / 438], examples_per_second: 11280.2347, train_label_loss: 2.0822, 
epoch: 17, [batch: 350 / 438], examples_per_second: 11278.5950, train_label_loss: 2.0772, 
=============================================================
epoch: 17, val_acc_label: 0.1267, val_label_loss: 2.0799, 
=============================================================
epoch: 18, [batch: 1 / 438], examples_per_second: 207.3698, train_label_loss: 2.0815, 
epoch: 18, [batch: 88 / 438], examples_per_second: 11271.4260, train_label_loss: 2.0840, 
epoch: 18, [batch: 175 / 438], examples_per_second: 11273.9072, train_label_loss: 2.0805, 
epoch: 18, [batch: 263 / 438], examples_per_second: 11275.1211, train_label_loss: 2.0791, 
epoch: 18, [batch: 350 / 438], examples_per_second: 11264.9670, train_label_loss: 2.0807, 
=============================================================
epoch: 18, val_acc_label: 0.1221, val_label_loss: 2.0805, 
=============================================================
epoch: 19, [batch: 1 / 438], examples_per_second: 207.8710, train_label_loss: 2.0796, 
epoch: 19, [batch: 88 / 438], examples_per_second: 11268.0868, train_label_loss: 2.0794, 
epoch: 19, [batch: 175 / 438], examples_per_second: 11268.0434, train_label_loss: 2.0807, 
epoch: 19, [batch: 263 / 438], examples_per_second: 11271.5904, train_label_loss: 2.0812, 
epoch: 19, [batch: 350 / 438], examples_per_second: 11276.4834, train_label_loss: 2.0803, 
=============================================================
epoch: 19, val_acc_label: 0.1267, val_label_loss: 2.0796, 
=============================================================
epoch: 20, [batch: 1 / 438], examples_per_second: 208.1335, train_label_loss: 2.0782, 
epoch: 20, [batch: 88 / 438], examples_per_second: 11259.3269, train_label_loss: 2.0823, 
epoch: 20, [batch: 175 / 438], examples_per_second: 11274.4270, train_label_loss: 2.0782, 
epoch: 20, [batch: 263 / 438], examples_per_second: 11272.8720, train_label_loss: 2.0796, 
epoch: 20, [batch: 350 / 438], examples_per_second: 11273.5943, train_label_loss: 2.0778, 
=============================================================
epoch: 20, val_acc_label: 0.1267, val_label_loss: 2.0796, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.124125 Target Test Label Accuracy: 0.12422916666666667
Source Val Label Accuracy: 0.127625 Target Val Label Accuracy: 0.12480208333333333
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
