[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 438], examples_per_second: 3248.2018, train_label_loss: 2.7702, 
epoch: 1, [batch: 88 / 438], examples_per_second: 11288.0234, train_label_loss: 2.0834, 
epoch: 1, [batch: 175 / 438], examples_per_second: 11276.7597, train_label_loss: 2.0777, 
epoch: 1, [batch: 263 / 438], examples_per_second: 11285.4014, train_label_loss: 2.0819, 
epoch: 1, [batch: 350 / 438], examples_per_second: 11280.7266, train_label_loss: 2.0873, 
=============================================================
epoch: 1, val_acc_label: 0.1290, val_label_loss: 2.0823, 
=============================================================
New best
epoch: 2, [batch: 1 / 438], examples_per_second: 201.9808, train_label_loss: 2.0823, 
epoch: 2, [batch: 88 / 438], examples_per_second: 11275.5755, train_label_loss: 2.0795, 
epoch: 2, [batch: 175 / 438], examples_per_second: 11271.5525, train_label_loss: 2.0867, 
epoch: 2, [batch: 263 / 438], examples_per_second: 11277.8866, train_label_loss: 2.0868, 
epoch: 2, [batch: 350 / 438], examples_per_second: 11270.4238, train_label_loss: 2.0879, 
=============================================================
epoch: 2, val_acc_label: 0.1290, val_label_loss: 2.0805, 
=============================================================
New best
epoch: 3, [batch: 1 / 438], examples_per_second: 207.2435, train_label_loss: 2.0930, 
epoch: 3, [batch: 88 / 438], examples_per_second: 11272.3686, train_label_loss: 2.0794, 
epoch: 3, [batch: 175 / 438], examples_per_second: 11269.5849, train_label_loss: 2.0801, 
epoch: 3, [batch: 263 / 438], examples_per_second: 11273.2149, train_label_loss: 2.0778, 
epoch: 3, [batch: 350 / 438], examples_per_second: 11276.9136, train_label_loss: 2.0844, 
=============================================================
epoch: 3, val_acc_label: 0.1264, val_label_loss: 2.0800, 
=============================================================
New best
epoch: 4, [batch: 1 / 438], examples_per_second: 206.1103, train_label_loss: 2.0819, 
epoch: 4, [batch: 88 / 438], examples_per_second: 11282.5168, train_label_loss: 2.0890, 
epoch: 4, [batch: 175 / 438], examples_per_second: 11277.6024, train_label_loss: 2.0887, 
epoch: 4, [batch: 263 / 438], examples_per_second: 11283.6252, train_label_loss: 2.0821, 
epoch: 4, [batch: 350 / 438], examples_per_second: 11282.4310, train_label_loss: 2.0858, 
=============================================================
epoch: 4, val_acc_label: 0.1247, val_label_loss: 2.0809, 
=============================================================
epoch: 5, [batch: 1 / 438], examples_per_second: 207.4084, train_label_loss: 2.0841, 
epoch: 5, [batch: 88 / 438], examples_per_second: 11244.4742, train_label_loss: 2.0783, 
epoch: 5, [batch: 175 / 438], examples_per_second: 11298.0878, train_label_loss: 2.0813, 
epoch: 5, [batch: 263 / 438], examples_per_second: 11256.2119, train_label_loss: 2.0817, 
epoch: 5, [batch: 350 / 438], examples_per_second: 11278.0368, train_label_loss: 2.0839, 
=============================================================
epoch: 5, val_acc_label: 0.1221, val_label_loss: 2.0806, 
=============================================================
epoch: 6, [batch: 1 / 438], examples_per_second: 208.7435, train_label_loss: 2.0787, 
epoch: 6, [batch: 88 / 438], examples_per_second: 11272.8120, train_label_loss: 2.0784, 
epoch: 6, [batch: 175 / 438], examples_per_second: 11242.9233, train_label_loss: 2.0837, 
epoch: 6, [batch: 263 / 438], examples_per_second: 11279.4806, train_label_loss: 2.0814, 
epoch: 6, [batch: 350 / 438], examples_per_second: 11275.4272, train_label_loss: 2.0799, 
=============================================================
epoch: 6, val_acc_label: 0.1264, val_label_loss: 2.0804, 
=============================================================
epoch: 7, [batch: 1 / 438], examples_per_second: 208.0568, train_label_loss: 2.0775, 
epoch: 7, [batch: 88 / 438], examples_per_second: 11286.4686, train_label_loss: 2.0772, 
epoch: 7, [batch: 175 / 438], examples_per_second: 11280.9214, train_label_loss: 2.0875, 
epoch: 7, [batch: 263 / 438], examples_per_second: 11285.8894, train_label_loss: 2.0813, 
epoch: 7, [batch: 350 / 438], examples_per_second: 11286.9568, train_label_loss: 2.0813, 
=============================================================
epoch: 7, val_acc_label: 0.1247, val_label_loss: 2.0804, 
=============================================================
epoch: 8, [batch: 1 / 438], examples_per_second: 207.5946, train_label_loss: 2.0778, 
epoch: 8, [batch: 88 / 438], examples_per_second: 11268.8576, train_label_loss: 2.0808, 
epoch: 8, [batch: 175 / 438], examples_per_second: 11270.7991, train_label_loss: 2.0759, 
epoch: 8, [batch: 263 / 438], examples_per_second: 11272.8478, train_label_loss: 2.0815, 
epoch: 8, [batch: 350 / 438], examples_per_second: 11266.6490, train_label_loss: 2.0808, 
=============================================================
epoch: 8, val_acc_label: 0.1230, val_label_loss: 2.0802, 
=============================================================
epoch: 9, [batch: 1 / 438], examples_per_second: 208.0186, train_label_loss: 2.0796, 
epoch: 9, [batch: 88 / 438], examples_per_second: 11273.1820, train_label_loss: 2.0856, 
epoch: 9, [batch: 175 / 438], examples_per_second: 11273.9018, train_label_loss: 2.0840, 
epoch: 9, [batch: 263 / 438], examples_per_second: 11276.5797, train_label_loss: 2.0771, 
epoch: 9, [batch: 350 / 438], examples_per_second: 11272.3101, train_label_loss: 2.0846, 
=============================================================
epoch: 9, val_acc_label: 0.1247, val_label_loss: 2.0797, 
=============================================================
New best
epoch: 10, [batch: 1 / 438], examples_per_second: 207.0575, train_label_loss: 2.0798, 
epoch: 10, [batch: 88 / 438], examples_per_second: 11293.7496, train_label_loss: 2.0869, 
epoch: 10, [batch: 175 / 438], examples_per_second: 11281.2211, train_label_loss: 2.0773, 
epoch: 10, [batch: 263 / 438], examples_per_second: 11289.1201, train_label_loss: 2.0812, 
epoch: 10, [batch: 350 / 438], examples_per_second: 11286.7673, train_label_loss: 2.0798, 
=============================================================
epoch: 10, val_acc_label: 0.1273, val_label_loss: 2.0802, 
=============================================================
epoch: 11, [batch: 1 / 438], examples_per_second: 207.8450, train_label_loss: 2.0807, 
epoch: 11, [batch: 88 / 438], examples_per_second: 11277.7822, train_label_loss: 2.0788, 
epoch: 11, [batch: 175 / 438], examples_per_second: 11267.1382, train_label_loss: 2.0896, 
epoch: 11, [batch: 263 / 438], examples_per_second: 11281.3808, train_label_loss: 2.0852, 
epoch: 11, [batch: 350 / 438], examples_per_second: 11274.1317, train_label_loss: 2.0787, 
=============================================================
epoch: 11, val_acc_label: 0.1273, val_label_loss: 2.0800, 
=============================================================
epoch: 12, [batch: 1 / 438], examples_per_second: 207.8244, train_label_loss: 2.0786, 
epoch: 12, [batch: 88 / 438], examples_per_second: 11282.7062, train_label_loss: 2.0810, 
epoch: 12, [batch: 175 / 438], examples_per_second: 11276.0356, train_label_loss: 2.0775, 
epoch: 12, [batch: 263 / 438], examples_per_second: 11280.0919, train_label_loss: 2.0855, 
epoch: 12, [batch: 350 / 438], examples_per_second: 11276.8823, train_label_loss: 2.0766, 
=============================================================
epoch: 12, val_acc_label: 0.1247, val_label_loss: 2.0796, 
=============================================================
New best
epoch: 13, [batch: 1 / 438], examples_per_second: 206.6819, train_label_loss: 2.0820, 
epoch: 13, [batch: 88 / 438], examples_per_second: 11265.4873, train_label_loss: 2.0813, 
epoch: 13, [batch: 175 / 438], examples_per_second: 11267.6574, train_label_loss: 2.0773, 
epoch: 13, [batch: 263 / 438], examples_per_second: 11266.3100, train_label_loss: 2.0804, 
epoch: 13, [batch: 350 / 438], examples_per_second: 11267.4793, train_label_loss: 2.0828, 
=============================================================
epoch: 13, val_acc_label: 0.1273, val_label_loss: 2.0802, 
=============================================================
epoch: 14, [batch: 1 / 438], examples_per_second: 208.5619, train_label_loss: 2.0813, 
epoch: 14, [batch: 88 / 438], examples_per_second: 11270.3966, train_label_loss: 2.0812, 
epoch: 14, [batch: 175 / 438], examples_per_second: 11271.1255, train_label_loss: 2.0807, 
epoch: 14, [batch: 263 / 438], examples_per_second: 11271.2368, train_label_loss: 2.0837, 
epoch: 14, [batch: 350 / 438], examples_per_second: 11268.0107, train_label_loss: 2.0810, 
=============================================================
epoch: 14, val_acc_label: 0.1264, val_label_loss: 2.0796, 
=============================================================
epoch: 15, [batch: 1 / 438], examples_per_second: 208.7715, train_label_loss: 2.0815, 
epoch: 15, [batch: 88 / 438], examples_per_second: 11270.4238, train_label_loss: 2.0855, 
epoch: 15, [batch: 175 / 438], examples_per_second: 11273.5875, train_label_loss: 2.0815, 
epoch: 15, [batch: 263 / 438], examples_per_second: 11268.6479, train_label_loss: 2.0795, 
epoch: 15, [batch: 350 / 438], examples_per_second: 11271.3063, train_label_loss: 2.0805, 
=============================================================
epoch: 15, val_acc_label: 0.1247, val_label_loss: 2.0798, 
=============================================================
epoch: 16, [batch: 1 / 438], examples_per_second: 207.9266, train_label_loss: 2.0802, 
epoch: 16, [batch: 88 / 438], examples_per_second: 11267.6410, train_label_loss: 2.0844, 
epoch: 16, [batch: 175 / 438], examples_per_second: 11270.6536, train_label_loss: 2.0831, 
epoch: 16, [batch: 263 / 438], examples_per_second: 11271.8916, train_label_loss: 2.0786, 
epoch: 16, [batch: 350 / 438], examples_per_second: 11275.0543, train_label_loss: 2.0822, 
=============================================================
epoch: 16, val_acc_label: 0.1264, val_label_loss: 2.0798, 
=============================================================
epoch: 17, [batch: 1 / 438], examples_per_second: 207.0620, train_label_loss: 2.0798, 
epoch: 17, [batch: 88 / 438], examples_per_second: 11283.7638, train_label_loss: 2.0803, 
epoch: 17, [batch: 175 / 438], examples_per_second: 11282.0317, train_label_loss: 2.0822, 
epoch: 17, [batch: 263 / 438], examples_per_second: 11268.9207, train_label_loss: 2.0827, 
epoch: 17, [batch: 350 / 438], examples_per_second: 11286.6009, train_label_loss: 2.0812, 
=============================================================
epoch: 17, val_acc_label: 0.1228, val_label_loss: 2.0808, 
=============================================================
epoch: 18, [batch: 1 / 438], examples_per_second: 207.4594, train_label_loss: 2.0854, 
epoch: 18, [batch: 88 / 438], examples_per_second: 11259.7150, train_label_loss: 2.0792, 
epoch: 18, [batch: 175 / 438], examples_per_second: 11282.9924, train_label_loss: 2.0829, 
epoch: 18, [batch: 263 / 438], examples_per_second: 11286.2587, train_label_loss: 2.0804, 
epoch: 18, [batch: 350 / 438], examples_per_second: 11290.3386, train_label_loss: 2.0812, 
=============================================================
epoch: 18, val_acc_label: 0.1230, val_label_loss: 2.0798, 
=============================================================
epoch: 19, [batch: 1 / 438], examples_per_second: 207.6086, train_label_loss: 2.0746, 
epoch: 19, [batch: 88 / 438], examples_per_second: 11271.8708, train_label_loss: 2.0821, 
epoch: 19, [batch: 175 / 438], examples_per_second: 11267.1165, train_label_loss: 2.0790, 
epoch: 19, [batch: 263 / 438], examples_per_second: 11268.7917, train_label_loss: 2.0803, 
epoch: 19, [batch: 350 / 438], examples_per_second: 11268.7665, train_label_loss: 2.0803, 
=============================================================
epoch: 19, val_acc_label: 0.1264, val_label_loss: 2.0798, 
=============================================================
epoch: 20, [batch: 1 / 438], examples_per_second: 207.7599, train_label_loss: 2.0812, 
epoch: 20, [batch: 88 / 438], examples_per_second: 11267.1966, train_label_loss: 2.0839, 
epoch: 20, [batch: 175 / 438], examples_per_second: 11267.9740, train_label_loss: 2.0756, 
epoch: 20, [batch: 263 / 438], examples_per_second: 11270.2043, train_label_loss: 2.0805, 
epoch: 20, [batch: 350 / 438], examples_per_second: 11269.9764, train_label_loss: 2.0800, 
=============================================================
epoch: 20, val_acc_label: 0.1221, val_label_loss: 2.0796, 
=============================================================
New best
epoch: 21, [batch: 1 / 438], examples_per_second: 207.2103, train_label_loss: 2.0819, 
epoch: 21, [batch: 88 / 438], examples_per_second: 11279.1779, train_label_loss: 2.0827, 
epoch: 21, [batch: 175 / 438], examples_per_second: 11283.5553, train_label_loss: 2.0806, 
epoch: 21, [batch: 263 / 438], examples_per_second: 11352.5620, train_label_loss: 2.0812, 
epoch: 21, [batch: 350 / 438], examples_per_second: 15982.5574, train_label_loss: 2.0790, 
=============================================================
epoch: 21, val_acc_label: 0.1221, val_label_loss: 2.0796, 
=============================================================
New best
epoch: 22, [batch: 1 / 438], examples_per_second: 344.5712, train_label_loss: 2.0776, 
epoch: 22, [batch: 88 / 438], examples_per_second: 18150.0481, train_label_loss: 2.0793, 
epoch: 22, [batch: 175 / 438], examples_per_second: 18194.3741, train_label_loss: 2.0840, 
epoch: 22, [batch: 263 / 438], examples_per_second: 18186.1835, train_label_loss: 2.0808, 
epoch: 22, [batch: 350 / 438], examples_per_second: 18186.9566, train_label_loss: 2.0827, 
=============================================================
epoch: 22, val_acc_label: 0.1230, val_label_loss: 2.0796, 
=============================================================
New best
epoch: 23, [batch: 1 / 438], examples_per_second: 347.2747, train_label_loss: 2.0809, 
epoch: 23, [batch: 88 / 438], examples_per_second: 18196.1709, train_label_loss: 2.0803, 
epoch: 23, [batch: 175 / 438], examples_per_second: 14588.1476, train_label_loss: 2.0818, 
epoch: 23, [batch: 263 / 438], examples_per_second: 11263.5408, train_label_loss: 2.0792, 
epoch: 23, [batch: 350 / 438], examples_per_second: 11282.4787, train_label_loss: 2.0792, 
=============================================================
epoch: 23, val_acc_label: 0.1264, val_label_loss: 2.0794, 
=============================================================
New best
epoch: 24, [batch: 1 / 438], examples_per_second: 206.9475, train_label_loss: 2.0809, 
epoch: 24, [batch: 88 / 438], examples_per_second: 11278.0054, train_label_loss: 2.0824, 
epoch: 24, [batch: 175 / 438], examples_per_second: 11281.5589, train_label_loss: 2.0787, 
epoch: 24, [batch: 263 / 438], examples_per_second: 11281.3889, train_label_loss: 2.0799, 
epoch: 24, [batch: 350 / 438], examples_per_second: 11284.6389, train_label_loss: 2.0759, 
=============================================================
epoch: 24, val_acc_label: 0.1247, val_label_loss: 2.0798, 
=============================================================
epoch: 25, [batch: 1 / 438], examples_per_second: 208.4062, train_label_loss: 2.0786, 
epoch: 25, [batch: 88 / 438], examples_per_second: 11261.9154, train_label_loss: 2.0804, 
epoch: 25, [batch: 175 / 438], examples_per_second: 11261.0018, train_label_loss: 2.0820, 
epoch: 25, [batch: 263 / 438], examples_per_second: 11275.5072, train_label_loss: 2.0802, 
epoch: 25, [batch: 350 / 438], examples_per_second: 11268.6700, train_label_loss: 2.0823, 
=============================================================
epoch: 25, val_acc_label: 0.1228, val_label_loss: 2.0800, 
=============================================================
epoch: 26, [batch: 1 / 438], examples_per_second: 207.6068, train_label_loss: 2.0803, 
epoch: 26, [batch: 88 / 438], examples_per_second: 11274.7005, train_label_loss: 2.0797, 
epoch: 26, [batch: 175 / 438], examples_per_second: 11275.4816, train_label_loss: 2.0801, 
epoch: 26, [batch: 263 / 438], examples_per_second: 11272.4457, train_label_loss: 2.0800, 
epoch: 26, [batch: 350 / 438], examples_per_second: 11275.9866, train_label_loss: 2.0773, 
=============================================================
epoch: 26, val_acc_label: 0.1290, val_label_loss: 2.0795, 
=============================================================
epoch: 27, [batch: 1 / 438], examples_per_second: 208.1224, train_label_loss: 2.0768, 
epoch: 27, [batch: 88 / 438], examples_per_second: 11268.6115, train_label_loss: 2.0798, 
epoch: 27, [batch: 175 / 438], examples_per_second: 11269.8595, train_label_loss: 2.0812, 
epoch: 27, [batch: 263 / 438], examples_per_second: 11271.8311, train_label_loss: 2.0777, 
epoch: 27, [batch: 350 / 438], examples_per_second: 11268.8249, train_label_loss: 2.0791, 
=============================================================
epoch: 27, val_acc_label: 0.1264, val_label_loss: 2.0795, 
=============================================================
epoch: 28, [batch: 1 / 438], examples_per_second: 207.6688, train_label_loss: 2.0804, 
epoch: 28, [batch: 88 / 438], examples_per_second: 11271.3567, train_label_loss: 2.0820, 
epoch: 28, [batch: 175 / 438], examples_per_second: 11272.1088, train_label_loss: 2.0784, 
epoch: 28, [batch: 263 / 438], examples_per_second: 11266.4605, train_label_loss: 2.0782, 
epoch: 28, [batch: 350 / 438], examples_per_second: 11271.9469, train_label_loss: 2.0776, 
=============================================================
epoch: 28, val_acc_label: 0.1221, val_label_loss: 2.0796, 
=============================================================
epoch: 29, [batch: 1 / 438], examples_per_second: 207.6768, train_label_loss: 2.0788, 
epoch: 29, [batch: 88 / 438], examples_per_second: 11249.8231, train_label_loss: 2.0794, 
epoch: 29, [batch: 175 / 438], examples_per_second: 11265.2713, train_label_loss: 2.0809, 
epoch: 29, [batch: 263 / 438], examples_per_second: 11269.9933, train_label_loss: 2.0774, 
epoch: 29, [batch: 350 / 438], examples_per_second: 11269.2165, train_label_loss: 2.0805, 
=============================================================
epoch: 29, val_acc_label: 0.1264, val_label_loss: 2.0799, 
=============================================================
epoch: 30, [batch: 1 / 438], examples_per_second: 208.7576, train_label_loss: 2.0803, 
epoch: 30, [batch: 88 / 438], examples_per_second: 11271.6776, train_label_loss: 2.0785, 
epoch: 30, [batch: 175 / 438], examples_per_second: 11264.5907, train_label_loss: 2.0791, 
epoch: 30, [batch: 263 / 438], examples_per_second: 11270.4235, train_label_loss: 2.0793, 
epoch: 30, [batch: 350 / 438], examples_per_second: 11276.0165, train_label_loss: 2.0816, 
=============================================================
epoch: 30, val_acc_label: 0.1230, val_label_loss: 2.0797, 
=============================================================
epoch: 31, [batch: 1 / 438], examples_per_second: 207.3782, train_label_loss: 2.0822, 
epoch: 31, [batch: 88 / 438], examples_per_second: 11282.3996, train_label_loss: 2.0825, 
epoch: 31, [batch: 175 / 438], examples_per_second: 11276.2629, train_label_loss: 2.0803, 
epoch: 31, [batch: 263 / 438], examples_per_second: 11286.5297, train_label_loss: 2.0819, 
epoch: 31, [batch: 350 / 438], examples_per_second: 11290.5965, train_label_loss: 2.0791, 
=============================================================
epoch: 31, val_acc_label: 0.1247, val_label_loss: 2.0798, 
=============================================================
epoch: 32, [batch: 1 / 438], examples_per_second: 207.6744, train_label_loss: 2.0804, 
epoch: 32, [batch: 88 / 438], examples_per_second: 11269.3320, train_label_loss: 2.0820, 
epoch: 32, [batch: 175 / 438], examples_per_second: 11267.6315, train_label_loss: 2.0802, 
epoch: 32, [batch: 263 / 438], examples_per_second: 11268.3590, train_label_loss: 2.0766, 
epoch: 32, [batch: 350 / 438], examples_per_second: 11266.4724, train_label_loss: 2.0805, 
=============================================================
epoch: 32, val_acc_label: 0.1290, val_label_loss: 2.0795, 
=============================================================
epoch: 33, [batch: 1 / 438], examples_per_second: 207.1926, train_label_loss: 2.0796, 
epoch: 33, [batch: 88 / 438], examples_per_second: 11276.0778, train_label_loss: 2.0808, 
epoch: 33, [batch: 175 / 438], examples_per_second: 11277.1368, train_label_loss: 2.0800, 
epoch: 33, [batch: 263 / 438], examples_per_second: 11281.1505, train_label_loss: 2.0814, 
epoch: 33, [batch: 350 / 438], examples_per_second: 11274.6229, train_label_loss: 2.0819, 
=============================================================
epoch: 33, val_acc_label: 0.1247, val_label_loss: 2.0798, 
=============================================================
epoch: 34, [batch: 1 / 438], examples_per_second: 207.7203, train_label_loss: 2.0809, 
epoch: 34, [batch: 88 / 438], examples_per_second: 11270.8412, train_label_loss: 2.0798, 
epoch: 34, [batch: 175 / 438], examples_per_second: 11270.1423, train_label_loss: 2.0791, 
epoch: 34, [batch: 263 / 438], examples_per_second: 11269.0215, train_label_loss: 2.0784, 
epoch: 34, [batch: 350 / 438], examples_per_second: 11270.3449, train_label_loss: 2.0815, 
=============================================================
epoch: 34, val_acc_label: 0.1221, val_label_loss: 2.0796, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.12304166666666666 Target Test Label Accuracy: 0.12353125
Source Val Label Accuracy: 0.126375 Target Val Label Accuracy: 0.12698958333333332
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
