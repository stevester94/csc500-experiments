[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 438], examples_per_second: 3144.6578, train_label_loss: 2.7664, 
epoch: 1, [batch: 88 / 438], examples_per_second: 11275.5225, train_label_loss: 2.0929, 
epoch: 1, [batch: 175 / 438], examples_per_second: 11280.3451, train_label_loss: 2.0851, 
epoch: 1, [batch: 263 / 438], examples_per_second: 11279.4873, train_label_loss: 2.0925, 
epoch: 1, [batch: 350 / 438], examples_per_second: 11274.8692, train_label_loss: 2.0875, 
=============================================================
epoch: 1, val_acc_label: 0.1247, val_label_loss: 2.0848, 
=============================================================
New best
epoch: 2, [batch: 1 / 438], examples_per_second: 201.3501, train_label_loss: 2.0912, 
epoch: 2, [batch: 88 / 438], examples_per_second: 11274.0623, train_label_loss: 2.0830, 
epoch: 2, [batch: 175 / 438], examples_per_second: 11278.6196, train_label_loss: 2.0791, 
epoch: 2, [batch: 263 / 438], examples_per_second: 11275.5153, train_label_loss: 2.0866, 
epoch: 2, [batch: 350 / 438], examples_per_second: 11263.8301, train_label_loss: 2.0741, 
=============================================================
epoch: 2, val_acc_label: 0.1232, val_label_loss: 2.0812, 
=============================================================
New best
epoch: 3, [batch: 1 / 438], examples_per_second: 208.4854, train_label_loss: 2.0910, 
epoch: 3, [batch: 88 / 438], examples_per_second: 11266.2740, train_label_loss: 2.0738, 
epoch: 3, [batch: 175 / 438], examples_per_second: 11264.8638, train_label_loss: 2.0798, 
epoch: 3, [batch: 263 / 438], examples_per_second: 11264.1303, train_label_loss: 2.0822, 
epoch: 3, [batch: 350 / 438], examples_per_second: 11262.9732, train_label_loss: 2.0833, 
=============================================================
epoch: 3, val_acc_label: 0.1232, val_label_loss: 2.0807, 
=============================================================
New best
epoch: 4, [batch: 1 / 438], examples_per_second: 205.2559, train_label_loss: 2.0828, 
epoch: 4, [batch: 88 / 438], examples_per_second: 11277.6596, train_label_loss: 2.0918, 
epoch: 4, [batch: 175 / 438], examples_per_second: 11287.0523, train_label_loss: 2.0809, 
epoch: 4, [batch: 263 / 438], examples_per_second: 11285.4324, train_label_loss: 2.0778, 
epoch: 4, [batch: 350 / 438], examples_per_second: 11284.2818, train_label_loss: 2.0777, 
=============================================================
epoch: 4, val_acc_label: 0.1232, val_label_loss: 2.0820, 
=============================================================
epoch: 5, [batch: 1 / 438], examples_per_second: 207.3852, train_label_loss: 2.0729, 
epoch: 5, [batch: 88 / 438], examples_per_second: 11268.4321, train_label_loss: 2.0812, 
epoch: 5, [batch: 175 / 438], examples_per_second: 11272.2693, train_label_loss: 2.0821, 
epoch: 5, [batch: 263 / 438], examples_per_second: 11272.0369, train_label_loss: 2.0789, 
epoch: 5, [batch: 350 / 438], examples_per_second: 11273.4419, train_label_loss: 2.0806, 
=============================================================
epoch: 5, val_acc_label: 0.1238, val_label_loss: 2.0819, 
=============================================================
epoch: 6, [batch: 1 / 438], examples_per_second: 208.7703, train_label_loss: 2.0826, 
epoch: 6, [batch: 88 / 438], examples_per_second: 11266.7740, train_label_loss: 2.0839, 
epoch: 6, [batch: 175 / 438], examples_per_second: 11256.3543, train_label_loss: 2.0918, 
epoch: 6, [batch: 263 / 438], examples_per_second: 11272.1175, train_label_loss: 2.0826, 
epoch: 6, [batch: 350 / 438], examples_per_second: 11266.9602, train_label_loss: 2.0837, 
=============================================================
epoch: 6, val_acc_label: 0.1233, val_label_loss: 2.0821, 
=============================================================
epoch: 7, [batch: 1 / 438], examples_per_second: 208.0844, train_label_loss: 2.0845, 
epoch: 7, [batch: 88 / 438], examples_per_second: 11278.7966, train_label_loss: 2.0780, 
epoch: 7, [batch: 175 / 438], examples_per_second: 11282.0086, train_label_loss: 2.0825, 
epoch: 7, [batch: 263 / 438], examples_per_second: 11278.2904, train_label_loss: 2.0841, 
epoch: 7, [batch: 350 / 438], examples_per_second: 11276.3609, train_label_loss: 2.0845, 
=============================================================
epoch: 7, val_acc_label: 0.1232, val_label_loss: 2.0802, 
=============================================================
New best
epoch: 8, [batch: 1 / 438], examples_per_second: 205.8613, train_label_loss: 2.0782, 
epoch: 8, [batch: 88 / 438], examples_per_second: 11272.2924, train_label_loss: 2.0874, 
epoch: 8, [batch: 175 / 438], examples_per_second: 11273.4691, train_label_loss: 2.0815, 
epoch: 8, [batch: 263 / 438], examples_per_second: 11268.2824, train_label_loss: 2.0826, 
epoch: 8, [batch: 350 / 438], examples_per_second: 11270.9868, train_label_loss: 2.0765, 
=============================================================
epoch: 8, val_acc_label: 0.1233, val_label_loss: 2.0796, 
=============================================================
New best
epoch: 9, [batch: 1 / 438], examples_per_second: 205.7226, train_label_loss: 2.0817, 
epoch: 9, [batch: 88 / 438], examples_per_second: 11261.3398, train_label_loss: 2.0796, 
epoch: 9, [batch: 175 / 438], examples_per_second: 11265.6925, train_label_loss: 2.0790, 
epoch: 9, [batch: 263 / 438], examples_per_second: 11263.3676, train_label_loss: 2.0797, 
epoch: 9, [batch: 350 / 438], examples_per_second: 11262.0580, train_label_loss: 2.0786, 
=============================================================
epoch: 9, val_acc_label: 0.1232, val_label_loss: 2.0803, 
=============================================================
epoch: 10, [batch: 1 / 438], examples_per_second: 207.6824, train_label_loss: 2.0786, 
epoch: 10, [batch: 88 / 438], examples_per_second: 11263.8220, train_label_loss: 2.0787, 
epoch: 10, [batch: 175 / 438], examples_per_second: 11265.8854, train_label_loss: 2.0781, 
epoch: 10, [batch: 263 / 438], examples_per_second: 11266.9374, train_label_loss: 2.0823, 
epoch: 10, [batch: 350 / 438], examples_per_second: 11268.2323, train_label_loss: 2.0828, 
=============================================================
epoch: 10, val_acc_label: 0.1253, val_label_loss: 2.0802, 
=============================================================
epoch: 11, [batch: 1 / 438], examples_per_second: 207.4642, train_label_loss: 2.0823, 
epoch: 11, [batch: 88 / 438], examples_per_second: 11269.9941, train_label_loss: 2.0748, 
epoch: 11, [batch: 175 / 438], examples_per_second: 11268.3505, train_label_loss: 2.0807, 
epoch: 11, [batch: 263 / 438], examples_per_second: 11271.4977, train_label_loss: 2.0809, 
epoch: 11, [batch: 350 / 438], examples_per_second: 11268.3098, train_label_loss: 2.0892, 
=============================================================
epoch: 11, val_acc_label: 0.1265, val_label_loss: 2.0800, 
=============================================================
epoch: 12, [batch: 1 / 438], examples_per_second: 207.4913, train_label_loss: 2.0770, 
epoch: 12, [batch: 88 / 438], examples_per_second: 11245.3270, train_label_loss: 2.0822, 
epoch: 12, [batch: 175 / 438], examples_per_second: 11262.2195, train_label_loss: 2.0823, 
epoch: 12, [batch: 263 / 438], examples_per_second: 11267.9223, train_label_loss: 2.0877, 
epoch: 12, [batch: 350 / 438], examples_per_second: 11261.1986, train_label_loss: 2.0829, 
=============================================================
epoch: 12, val_acc_label: 0.1233, val_label_loss: 2.0800, 
=============================================================
epoch: 13, [batch: 1 / 438], examples_per_second: 209.6811, train_label_loss: 2.0855, 
epoch: 13, [batch: 88 / 438], examples_per_second: 17204.3460, train_label_loss: 2.0810, 
epoch: 13, [batch: 175 / 438], examples_per_second: 18149.7766, train_label_loss: 2.0785, 
epoch: 13, [batch: 263 / 438], examples_per_second: 18168.4090, train_label_loss: 2.0823, 
epoch: 13, [batch: 350 / 438], examples_per_second: 18185.1333, train_label_loss: 2.0794, 
=============================================================
epoch: 13, val_acc_label: 0.1288, val_label_loss: 2.0794, 
=============================================================
New best
epoch: 14, [batch: 1 / 438], examples_per_second: 351.2343, train_label_loss: 2.0805, 
epoch: 14, [batch: 88 / 438], examples_per_second: 18155.1664, train_label_loss: 2.0790, 
epoch: 14, [batch: 175 / 438], examples_per_second: 18180.5182, train_label_loss: 2.0795, 
epoch: 14, [batch: 263 / 438], examples_per_second: 18169.7401, train_label_loss: 2.0817, 
epoch: 14, [batch: 350 / 438], examples_per_second: 18386.9998, train_label_loss: 2.0799, 
=============================================================
epoch: 14, val_acc_label: 0.1247, val_label_loss: 2.0800, 
=============================================================
epoch: 15, [batch: 1 / 438], examples_per_second: 212.5064, train_label_loss: 2.0808, 
epoch: 15, [batch: 88 / 438], examples_per_second: 11261.8665, train_label_loss: 2.0805, 
epoch: 15, [batch: 175 / 438], examples_per_second: 11264.3082, train_label_loss: 2.0806, 
epoch: 15, [batch: 263 / 438], examples_per_second: 11267.6764, train_label_loss: 2.0774, 
epoch: 15, [batch: 350 / 438], examples_per_second: 11265.0567, train_label_loss: 2.0789, 
=============================================================
epoch: 15, val_acc_label: 0.1244, val_label_loss: 2.0797, 
=============================================================
epoch: 16, [batch: 1 / 438], examples_per_second: 207.7124, train_label_loss: 2.0807, 
epoch: 16, [batch: 88 / 438], examples_per_second: 11259.2441, train_label_loss: 2.0778, 
epoch: 16, [batch: 175 / 438], examples_per_second: 11262.6636, train_label_loss: 2.0781, 
epoch: 16, [batch: 263 / 438], examples_per_second: 11261.2534, train_label_loss: 2.0783, 
epoch: 16, [batch: 350 / 438], examples_per_second: 11267.0078, train_label_loss: 2.0825, 
=============================================================
epoch: 16, val_acc_label: 0.1233, val_label_loss: 2.0798, 
=============================================================
epoch: 17, [batch: 1 / 438], examples_per_second: 207.1394, train_label_loss: 2.0814, 
epoch: 17, [batch: 88 / 438], examples_per_second: 11280.3261, train_label_loss: 2.0798, 
epoch: 17, [batch: 175 / 438], examples_per_second: 11281.6339, train_label_loss: 2.0799, 
epoch: 17, [batch: 263 / 438], examples_per_second: 11275.1278, train_label_loss: 2.0828, 
epoch: 17, [batch: 350 / 438], examples_per_second: 11281.2265, train_label_loss: 2.0801, 
=============================================================
epoch: 17, val_acc_label: 0.1288, val_label_loss: 2.0794, 
=============================================================
epoch: 18, [batch: 1 / 438], examples_per_second: 207.5416, train_label_loss: 2.0812, 
epoch: 18, [batch: 88 / 438], examples_per_second: 11261.5393, train_label_loss: 2.0845, 
epoch: 18, [batch: 175 / 438], examples_per_second: 11264.2593, train_label_loss: 2.0843, 
epoch: 18, [batch: 263 / 438], examples_per_second: 11248.8926, train_label_loss: 2.0837, 
epoch: 18, [batch: 350 / 438], examples_per_second: 11267.0336, train_label_loss: 2.0814, 
=============================================================
epoch: 18, val_acc_label: 0.1253, val_label_loss: 2.0799, 
=============================================================
epoch: 19, [batch: 1 / 438], examples_per_second: 207.5885, train_label_loss: 2.0801, 
epoch: 19, [batch: 88 / 438], examples_per_second: 11272.5250, train_label_loss: 2.0793, 
epoch: 19, [batch: 175 / 438], examples_per_second: 11273.3480, train_label_loss: 2.0777, 
epoch: 19, [batch: 263 / 438], examples_per_second: 11274.1323, train_label_loss: 2.0758, 
epoch: 19, [batch: 350 / 438], examples_per_second: 11273.0583, train_label_loss: 2.0808, 
=============================================================
epoch: 19, val_acc_label: 0.1253, val_label_loss: 2.0797, 
=============================================================
epoch: 20, [batch: 1 / 438], examples_per_second: 207.3114, train_label_loss: 2.0776, 
epoch: 20, [batch: 88 / 438], examples_per_second: 11277.7495, train_label_loss: 2.0808, 
epoch: 20, [batch: 175 / 438], examples_per_second: 11269.4720, train_label_loss: 2.0780, 
epoch: 20, [batch: 263 / 438], examples_per_second: 11290.3314, train_label_loss: 2.0794, 
epoch: 20, [batch: 350 / 438], examples_per_second: 11272.3536, train_label_loss: 2.0797, 
=============================================================
epoch: 20, val_acc_label: 0.1247, val_label_loss: 2.0796, 
=============================================================
epoch: 21, [batch: 1 / 438], examples_per_second: 207.3241, train_label_loss: 2.0802, 
epoch: 21, [batch: 88 / 438], examples_per_second: 11279.1003, train_label_loss: 2.0840, 
epoch: 21, [batch: 175 / 438], examples_per_second: 11283.4817, train_label_loss: 2.0784, 
epoch: 21, [batch: 263 / 438], examples_per_second: 11278.1060, train_label_loss: 2.0784, 
epoch: 21, [batch: 350 / 438], examples_per_second: 11281.9949, train_label_loss: 2.0759, 
=============================================================
epoch: 21, val_acc_label: 0.1288, val_label_loss: 2.0798, 
=============================================================
epoch: 22, [batch: 1 / 438], examples_per_second: 207.3956, train_label_loss: 2.0793, 
epoch: 22, [batch: 88 / 438], examples_per_second: 11272.3006, train_label_loss: 2.0784, 
epoch: 22, [batch: 175 / 438], examples_per_second: 11273.5535, train_label_loss: 2.0803, 
epoch: 22, [batch: 263 / 438], examples_per_second: 11272.5438, train_label_loss: 2.0790, 
epoch: 22, [batch: 350 / 438], examples_per_second: 11268.8413, train_label_loss: 2.0814, 
=============================================================
epoch: 22, val_acc_label: 0.1247, val_label_loss: 2.0797, 
=============================================================
epoch: 23, [batch: 1 / 438], examples_per_second: 207.1960, train_label_loss: 2.0775, 
epoch: 23, [batch: 88 / 438], examples_per_second: 11273.6065, train_label_loss: 2.0800, 
epoch: 23, [batch: 175 / 438], examples_per_second: 11273.4514, train_label_loss: 2.0799, 
epoch: 23, [batch: 263 / 438], examples_per_second: 11276.0872, train_label_loss: 2.0782, 
epoch: 23, [batch: 350 / 438], examples_per_second: 11268.7828, train_label_loss: 2.0808, 
=============================================================
epoch: 23, val_acc_label: 0.1253, val_label_loss: 2.0797, 
=============================================================
epoch: 24, [batch: 1 / 438], examples_per_second: 207.6098, train_label_loss: 2.0771, 
epoch: 24, [batch: 88 / 438], examples_per_second: 11269.1526, train_label_loss: 2.0786, 
epoch: 24, [batch: 175 / 438], examples_per_second: 11250.0670, train_label_loss: 2.0826, 
epoch: 24, [batch: 263 / 438], examples_per_second: 11260.4710, train_label_loss: 2.0793, 
epoch: 24, [batch: 350 / 438], examples_per_second: 11261.0275, train_label_loss: 2.0836, 
=============================================================
epoch: 24, val_acc_label: 0.1232, val_label_loss: 2.0796, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.12616666666666668 Target Test Label Accuracy: 0.12392708333333333
Source Val Label Accuracy: 0.12883333333333333 Target Val Label Accuracy: 0.1259375
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
