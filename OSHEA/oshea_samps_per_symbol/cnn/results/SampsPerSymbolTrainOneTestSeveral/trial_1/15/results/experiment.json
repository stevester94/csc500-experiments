{
  "experiment_name": "CNN SampsPerSymbol Train One Test Several Trial 1",
  "parameters": {
    "experiment_name": "CNN SampsPerSymbol Train One Test Several Trial 1",
    "lr": 0.001,
    "n_epoch": 1000,
    "batch_size": 256,
    "patience": 10,
    "device": "cuda",
    "source_domains": [
      8
    ],
    "target_domains": [
      2,
      6,
      10,
      12
    ],
    "x_net": [
      {
        "class": "Conv1d",
        "kargs": {
          "in_channels": 2,
          "out_channels": 50,
          "kernel_size": 7,
          "stride": 1,
          "padding": 0
        }
      },
      {
        "class": "ReLU",
        "kargs": {
          "inplace": true
        }
      },
      {
        "class": "Conv1d",
        "kargs": {
          "in_channels": 50,
          "out_channels": 50,
          "kernel_size": 7,
          "stride": 1,
          "padding": 0
        }
      },
      {
        "class": "ReLU",
        "kargs": {
          "inplace": true
        }
      },
      {
        "class": "Dropout",
        "kargs": {
          "p": 0.5
        }
      },
      {
        "class": "Flatten",
        "kargs": {}
      },
      {
        "class": "Linear",
        "kargs": {
          "in_features": 5800,
          "out_features": 256
        }
      },
      {
        "class": "ReLU",
        "kargs": {
          "inplace": true
        }
      },
      {
        "class": "Dropout",
        "kargs": {
          "p": 0.5
        }
      },
      {
        "class": "Linear",
        "kargs": {
          "in_features": 256,
          "out_features": 80
        }
      },
      {
        "class": "ReLU",
        "kargs": {
          "inplace": true
        }
      },
      {
        "class": "Dropout",
        "kargs": {
          "p": 0.5
        }
      },
      {
        "class": "Linear",
        "kargs": {
          "in_features": 80,
          "out_features": 16
        }
      }
    ],
    "seed": 12698
  },
  "results": {
    "source_test_label_accuracy": 0.12616666666666668,
    "source_test_label_loss": 2.079583315139121,
    "target_test_label_accuracy": 0.12392708333333333,
    "target_test_label_loss": 2.079717876434326,
    "source_val_label_accuracy": 0.12883333333333333,
    "source_val_label_loss": 2.0794251041209444,
    "target_val_label_accuracy": 0.1259375,
    "target_val_label_loss": 2.0796029891967773,
    "total_epochs_trained": 24,
    "total_experiment_time_secs": 279.04935240745544,
    "confusion": {
      "6": {
        "3": {
          "4": 3017
        },
        "4": {
          "4": 2937
        },
        "0": {
          "4": 2999
        },
        "6": {
          "4": 2971
        },
        "7": {
          "4": 3011
        },
        "2": {
          "4": 3020
        },
        "1": {
          "4": 2921
        },
        "5": {
          "4": 2954
        }
      },
      "12": {
        "0": {
          "4": 3058
        },
        "1": {
          "4": 2942
        },
        "5": {
          "4": 2984
        },
        "6": {
          "4": 3014
        },
        "2": {
          "4": 2925
        },
        "7": {
          "4": 2936
        },
        "3": {
          "4": 3025
        },
        "4": {
          "4": 3044
        }
      },
      "10": {
        "0": {
          "4": 3022
        },
        "4": {
          "4": 3013
        },
        "3": {
          "4": 3049
        },
        "2": {
          "4": 2958
        },
        "5": {
          "4": 3042
        },
        "7": {
          "4": 2968
        },
        "6": {
          "4": 2959
        },
        "1": {
          "4": 2998
        }
      },
      "2": {
        "6": {
          "4": 3030
        },
        "1": {
          "4": 3005
        },
        "4": {
          "4": 3096
        },
        "0": {
          "4": 3031
        },
        "3": {
          "4": 2950
        },
        "7": {
          "4": 3028
        },
        "2": {
          "4": 3021
        },
        "5": {
          "4": 3072
        }
      },
      "8": {
        "5": {
          "4": 3035
        },
        "1": {
          "4": 2986
        },
        "6": {
          "4": 2971
        },
        "7": {
          "4": 2960
        },
        "3": {
          "4": 3006
        },
        "0": {
          "4": 2992
        },
        "4": {
          "4": 3092
        },
        "2": {
          "4": 2958
        }
      }
    },
    "per_domain_accuracy": {
      "6": {
        "accuracy": 0.12324800671422577,
        "source?": false
      },
      "12": {
        "accuracy": 0.12721497826813774,
        "source?": false
      },
      "10": {
        "accuracy": 0.12549460618934566,
        "source?": false
      },
      "2": {
        "accuracy": 0.12775966657037924,
        "source?": false
      },
      "8": {
        "accuracy": 0.12883333333333333,
        "source?": true
      }
    }
  },
  "history": {
    "epoch_indices": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24
    ],
    "train_label_loss": [
      2.1008616250399585,
      2.0839851882359754,
      2.082918789288769,
      2.0823298159255286,
      2.08189616029121,
      2.081422448158264,
      2.0814835818390867,
      2.0810842546698165,
      2.0807576163174355,
      2.0809550900437515,
      2.0807682624146273,
      2.080486165878435,
      2.080581222494988,
      2.080429569226966,
      2.080522223150349,
      2.080383247980788,
      2.0803260710685767,
      2.0801659152932364,
      2.0801774589982753,
      2.080048923078737,
      2.079984128203022,
      2.080080899473739,
      2.0800065629558477,
      2.0798494315038534
    ],
    "val_label_loss": [
      2.0847555196031613,
      2.081239091589096,
      2.080676487151613,
      2.0820058990032115,
      2.081908885468828,
      2.0821464112464416,
      2.080182461028403,
      2.079641735300105,
      2.080267183324124,
      2.080240787343776,
      2.079982853950338,
      2.0800412994750004,
      2.0794204930041698,
      2.0799939175869557,
      2.07966739827014,
      2.0797901990565846,
      2.0794448269174453,
      2.0798590589076915,
      2.0796961251725543,
      2.0796199453637954,
      2.0797781563819724,
      2.0796553251591137,
      2.0796801638095936,
      2.0795898133135857
    ]
  }
}