[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 438], examples_per_second: 3104.9692, train_label_loss: 2.7690, 
epoch: 1, [batch: 88 / 438], examples_per_second: 11779.5644, train_label_loss: 2.1046, 
epoch: 1, [batch: 175 / 438], examples_per_second: 11780.6444, train_label_loss: 2.0848, 
epoch: 1, [batch: 263 / 438], examples_per_second: 11761.7109, train_label_loss: 2.0904, 
epoch: 1, [batch: 350 / 438], examples_per_second: 11771.6467, train_label_loss: 2.0831, 
=============================================================
epoch: 1, val_acc_label: 0.1234, val_label_loss: 2.0813, 
=============================================================
New best
epoch: 2, [batch: 1 / 438], examples_per_second: 206.8877, train_label_loss: 2.0783, 
epoch: 2, [batch: 88 / 438], examples_per_second: 11762.3310, train_label_loss: 2.0834, 
epoch: 2, [batch: 175 / 438], examples_per_second: 11769.2916, train_label_loss: 2.0766, 
epoch: 2, [batch: 263 / 438], examples_per_second: 11770.3992, train_label_loss: 2.0910, 
epoch: 2, [batch: 350 / 438], examples_per_second: 11773.7639, train_label_loss: 2.0829, 
=============================================================
epoch: 2, val_acc_label: 0.1239, val_label_loss: 2.0807, 
=============================================================
New best
epoch: 3, [batch: 1 / 438], examples_per_second: 214.6835, train_label_loss: 2.0782, 
epoch: 3, [batch: 88 / 438], examples_per_second: 11800.4682, train_label_loss: 2.0830, 
epoch: 3, [batch: 175 / 438], examples_per_second: 11802.7672, train_label_loss: 2.0787, 
epoch: 3, [batch: 263 / 438], examples_per_second: 11798.7198, train_label_loss: 2.0823, 
epoch: 3, [batch: 350 / 438], examples_per_second: 11802.3959, train_label_loss: 2.0866, 
=============================================================
epoch: 3, val_acc_label: 0.1260, val_label_loss: 2.0810, 
=============================================================
epoch: 4, [batch: 1 / 438], examples_per_second: 216.6275, train_label_loss: 2.0925, 
epoch: 4, [batch: 88 / 438], examples_per_second: 11781.2134, train_label_loss: 2.0776, 
epoch: 4, [batch: 175 / 438], examples_per_second: 11786.4012, train_label_loss: 2.0815, 
epoch: 4, [batch: 263 / 438], examples_per_second: 11768.3952, train_label_loss: 2.0866, 
epoch: 4, [batch: 350 / 438], examples_per_second: 11755.9630, train_label_loss: 2.0785, 
=============================================================
epoch: 4, val_acc_label: 0.1280, val_label_loss: 2.0801, 
=============================================================
New best
epoch: 5, [batch: 1 / 438], examples_per_second: 215.1470, train_label_loss: 2.0810, 
epoch: 5, [batch: 88 / 438], examples_per_second: 11792.5804, train_label_loss: 2.0831, 
epoch: 5, [batch: 175 / 438], examples_per_second: 11760.3053, train_label_loss: 2.0797, 
epoch: 5, [batch: 263 / 438], examples_per_second: 11762.3961, train_label_loss: 2.0851, 
epoch: 5, [batch: 350 / 438], examples_per_second: 11768.0017, train_label_loss: 2.0788, 
=============================================================
epoch: 5, val_acc_label: 0.1239, val_label_loss: 2.0809, 
=============================================================
epoch: 6, [batch: 1 / 438], examples_per_second: 216.2635, train_label_loss: 2.0825, 
epoch: 6, [batch: 88 / 438], examples_per_second: 11804.7777, train_label_loss: 2.0837, 
epoch: 6, [batch: 175 / 438], examples_per_second: 11764.1070, train_label_loss: 2.0857, 
epoch: 6, [batch: 263 / 438], examples_per_second: 11766.3128, train_label_loss: 2.0861, 
epoch: 6, [batch: 350 / 438], examples_per_second: 11800.8066, train_label_loss: 2.0872, 
=============================================================
epoch: 6, val_acc_label: 0.1259, val_label_loss: 2.0805, 
=============================================================
epoch: 7, [batch: 1 / 438], examples_per_second: 319.0811, train_label_loss: 2.0772, 
epoch: 7, [batch: 88 / 438], examples_per_second: 18918.4916, train_label_loss: 2.0820, 
epoch: 7, [batch: 175 / 438], examples_per_second: 19045.0125, train_label_loss: 2.0807, 
epoch: 7, [batch: 263 / 438], examples_per_second: 18979.6966, train_label_loss: 2.0750, 
epoch: 7, [batch: 350 / 438], examples_per_second: 18997.7948, train_label_loss: 2.0818, 
=============================================================
epoch: 7, val_acc_label: 0.1225, val_label_loss: 2.0801, 
=============================================================
epoch: 8, [batch: 1 / 438], examples_per_second: 362.8362, train_label_loss: 2.0803, 
epoch: 8, [batch: 88 / 438], examples_per_second: 19031.2773, train_label_loss: 2.0822, 
epoch: 8, [batch: 175 / 438], examples_per_second: 19021.7016, train_label_loss: 2.0827, 
epoch: 8, [batch: 263 / 438], examples_per_second: 17120.6473, train_label_loss: 2.0897, 
epoch: 8, [batch: 350 / 438], examples_per_second: 11765.8377, train_label_loss: 2.0794, 
=============================================================
epoch: 8, val_acc_label: 0.1239, val_label_loss: 2.0801, 
=============================================================
epoch: 9, [batch: 1 / 438], examples_per_second: 216.0011, train_label_loss: 2.0760, 
epoch: 9, [batch: 88 / 438], examples_per_second: 11761.3402, train_label_loss: 2.0802, 
epoch: 9, [batch: 175 / 438], examples_per_second: 11762.8227, train_label_loss: 2.0758, 
epoch: 9, [batch: 263 / 438], examples_per_second: 11757.8134, train_label_loss: 2.0775, 
epoch: 9, [batch: 350 / 438], examples_per_second: 11759.3015, train_label_loss: 2.0808, 
=============================================================
epoch: 9, val_acc_label: 0.1225, val_label_loss: 2.0798, 
=============================================================
New best
epoch: 10, [batch: 1 / 438], examples_per_second: 213.9445, train_label_loss: 2.0758, 
epoch: 10, [batch: 88 / 438], examples_per_second: 11749.1452, train_label_loss: 2.0820, 
epoch: 10, [batch: 175 / 438], examples_per_second: 11749.5487, train_label_loss: 2.0794, 
epoch: 10, [batch: 263 / 438], examples_per_second: 11754.0866, train_label_loss: 2.0803, 
epoch: 10, [batch: 350 / 438], examples_per_second: 11750.0497, train_label_loss: 2.0842, 
=============================================================
epoch: 10, val_acc_label: 0.1237, val_label_loss: 2.0799, 
=============================================================
epoch: 11, [batch: 1 / 438], examples_per_second: 216.4008, train_label_loss: 2.0793, 
epoch: 11, [batch: 88 / 438], examples_per_second: 11787.0050, train_label_loss: 2.0797, 
epoch: 11, [batch: 175 / 438], examples_per_second: 11781.9163, train_label_loss: 2.0803, 
epoch: 11, [batch: 263 / 438], examples_per_second: 11780.0622, train_label_loss: 2.0806, 
epoch: 11, [batch: 350 / 438], examples_per_second: 11780.9297, train_label_loss: 2.0843, 
=============================================================
epoch: 11, val_acc_label: 0.1239, val_label_loss: 2.0805, 
=============================================================
epoch: 12, [batch: 1 / 438], examples_per_second: 216.3906, train_label_loss: 2.0808, 
epoch: 12, [batch: 88 / 438], examples_per_second: 11782.6043, train_label_loss: 2.0791, 
epoch: 12, [batch: 175 / 438], examples_per_second: 11758.0434, train_label_loss: 2.0803, 
epoch: 12, [batch: 263 / 438], examples_per_second: 11755.2916, train_label_loss: 2.0774, 
epoch: 12, [batch: 350 / 438], examples_per_second: 11743.4322, train_label_loss: 2.0788, 
=============================================================
epoch: 12, val_acc_label: 0.1280, val_label_loss: 2.0795, 
=============================================================
New best
epoch: 13, [batch: 1 / 438], examples_per_second: 214.3685, train_label_loss: 2.0780, 
epoch: 13, [batch: 88 / 438], examples_per_second: 11767.6311, train_label_loss: 2.0828, 
epoch: 13, [batch: 175 / 438], examples_per_second: 11770.0656, train_label_loss: 2.0817, 
epoch: 13, [batch: 263 / 438], examples_per_second: 11758.9137, train_label_loss: 2.0819, 
epoch: 13, [batch: 350 / 438], examples_per_second: 11759.3386, train_label_loss: 2.0823, 
=============================================================
epoch: 13, val_acc_label: 0.1267, val_label_loss: 2.0798, 
=============================================================
epoch: 14, [batch: 1 / 438], examples_per_second: 215.5696, train_label_loss: 2.0792, 
epoch: 14, [batch: 88 / 438], examples_per_second: 11765.3546, train_label_loss: 2.0843, 
epoch: 14, [batch: 175 / 438], examples_per_second: 11763.5426, train_label_loss: 2.0806, 
epoch: 14, [batch: 263 / 438], examples_per_second: 11754.0355, train_label_loss: 2.0844, 
epoch: 14, [batch: 350 / 438], examples_per_second: 11766.8039, train_label_loss: 2.0794, 
=============================================================
epoch: 14, val_acc_label: 0.1260, val_label_loss: 2.0798, 
=============================================================
epoch: 15, [batch: 1 / 438], examples_per_second: 216.1408, train_label_loss: 2.0790, 
epoch: 15, [batch: 88 / 438], examples_per_second: 11757.3523, train_label_loss: 2.0823, 
epoch: 15, [batch: 175 / 438], examples_per_second: 11760.1631, train_label_loss: 2.0830, 
epoch: 15, [batch: 263 / 438], examples_per_second: 11760.1094, train_label_loss: 2.0807, 
epoch: 15, [batch: 350 / 438], examples_per_second: 11759.5221, train_label_loss: 2.0810, 
=============================================================
epoch: 15, val_acc_label: 0.1237, val_label_loss: 2.0802, 
=============================================================
epoch: 16, [batch: 1 / 438], examples_per_second: 216.1163, train_label_loss: 2.0820, 
epoch: 16, [batch: 88 / 438], examples_per_second: 11759.8123, train_label_loss: 2.0771, 
epoch: 16, [batch: 175 / 438], examples_per_second: 11760.4814, train_label_loss: 2.0779, 
epoch: 16, [batch: 263 / 438], examples_per_second: 11751.1557, train_label_loss: 2.0802, 
epoch: 16, [batch: 350 / 438], examples_per_second: 11762.6213, train_label_loss: 2.0798, 
=============================================================
epoch: 16, val_acc_label: 0.1260, val_label_loss: 2.0801, 
=============================================================
epoch: 17, [batch: 1 / 438], examples_per_second: 216.9729, train_label_loss: 2.0825, 
epoch: 17, [batch: 88 / 438], examples_per_second: 11743.1104, train_label_loss: 2.0809, 
epoch: 17, [batch: 175 / 438], examples_per_second: 11752.4016, train_label_loss: 2.0816, 
epoch: 17, [batch: 263 / 438], examples_per_second: 11753.3307, train_label_loss: 2.0787, 
epoch: 17, [batch: 350 / 438], examples_per_second: 11752.6544, train_label_loss: 2.0811, 
=============================================================
epoch: 17, val_acc_label: 0.1239, val_label_loss: 2.0797, 
=============================================================
epoch: 18, [batch: 1 / 438], examples_per_second: 216.7157, train_label_loss: 2.0800, 
epoch: 18, [batch: 88 / 438], examples_per_second: 11746.9822, train_label_loss: 2.0782, 
epoch: 18, [batch: 175 / 438], examples_per_second: 11737.2616, train_label_loss: 2.0794, 
epoch: 18, [batch: 263 / 438], examples_per_second: 11754.7227, train_label_loss: 2.0799, 
epoch: 18, [batch: 350 / 438], examples_per_second: 11752.0778, train_label_loss: 2.0763, 
=============================================================
epoch: 18, val_acc_label: 0.1237, val_label_loss: 2.0797, 
=============================================================
epoch: 19, [batch: 1 / 438], examples_per_second: 217.3649, train_label_loss: 2.0803, 
epoch: 19, [batch: 88 / 438], examples_per_second: 11784.2571, train_label_loss: 2.0795, 
epoch: 19, [batch: 175 / 438], examples_per_second: 11784.6689, train_label_loss: 2.0791, 
epoch: 19, [batch: 263 / 438], examples_per_second: 11780.2722, train_label_loss: 2.0802, 
epoch: 19, [batch: 350 / 438], examples_per_second: 11773.7743, train_label_loss: 2.0815, 
=============================================================
epoch: 19, val_acc_label: 0.1267, val_label_loss: 2.0802, 
=============================================================
epoch: 20, [batch: 1 / 438], examples_per_second: 217.1389, train_label_loss: 2.0834, 
epoch: 20, [batch: 88 / 438], examples_per_second: 11753.2311, train_label_loss: 2.0812, 
epoch: 20, [batch: 175 / 438], examples_per_second: 11745.1626, train_label_loss: 2.0825, 
epoch: 20, [batch: 263 / 438], examples_per_second: 11756.4178, train_label_loss: 2.0799, 
epoch: 20, [batch: 350 / 438], examples_per_second: 11756.5311, train_label_loss: 2.0798, 
=============================================================
epoch: 20, val_acc_label: 0.1225, val_label_loss: 2.0802, 
=============================================================
epoch: 21, [batch: 1 / 438], examples_per_second: 216.3395, train_label_loss: 2.0790, 
epoch: 21, [batch: 88 / 438], examples_per_second: 11772.1095, train_label_loss: 2.0805, 
epoch: 21, [batch: 175 / 438], examples_per_second: 11762.3206, train_label_loss: 2.0784, 
epoch: 21, [batch: 263 / 438], examples_per_second: 11770.7672, train_label_loss: 2.0817, 
epoch: 21, [batch: 350 / 438], examples_per_second: 11756.3536, train_label_loss: 2.0798, 
=============================================================
epoch: 21, val_acc_label: 0.1225, val_label_loss: 2.0799, 
=============================================================
epoch: 22, [batch: 1 / 438], examples_per_second: 216.9653, train_label_loss: 2.0810, 
epoch: 22, [batch: 88 / 438], examples_per_second: 11751.5603, train_label_loss: 2.0782, 
epoch: 22, [batch: 175 / 438], examples_per_second: 11752.5820, train_label_loss: 2.0786, 
epoch: 22, [batch: 263 / 438], examples_per_second: 11748.4191, train_label_loss: 2.0769, 
epoch: 22, [batch: 350 / 438], examples_per_second: 11761.2781, train_label_loss: 2.0804, 
=============================================================
epoch: 22, val_acc_label: 0.1239, val_label_loss: 2.0797, 
=============================================================
epoch: 23, [batch: 1 / 438], examples_per_second: 216.3296, train_label_loss: 2.0799, 
epoch: 23, [batch: 88 / 438], examples_per_second: 11769.2011, train_label_loss: 2.0843, 
epoch: 23, [batch: 175 / 438], examples_per_second: 11792.3705, train_label_loss: 2.0801, 
epoch: 23, [batch: 263 / 438], examples_per_second: 11773.0918, train_label_loss: 2.0798, 
epoch: 23, [batch: 350 / 438], examples_per_second: 11782.3933, train_label_loss: 2.0788, 
=============================================================
epoch: 23, val_acc_label: 0.1237, val_label_loss: 2.0797, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.12329166666666666 Target Test Label Accuracy: 0.12584375
Source Val Label Accuracy: 0.12795833333333334 Target Val Label Accuracy: 0.12488541666666667
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
