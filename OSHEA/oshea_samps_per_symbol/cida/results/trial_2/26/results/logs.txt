[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 5250], examples_per_second: 1479.1523, train_label_loss: 2.1969, train_domain_loss: 0.4870
epoch: 1, [batch: 1050 / 5250], examples_per_second: 12618.5716, train_label_loss: 2.0875, train_domain_loss: 0.4809
epoch: 1, [batch: 2100 / 5250], examples_per_second: 12577.1630, train_label_loss: 2.0891, train_domain_loss: 0.4722
epoch: 1, [batch: 3150 / 5250], examples_per_second: 12566.4135, train_label_loss: 1.9738, train_domain_loss: 0.5161
epoch: 1, [batch: 4200 / 5250], examples_per_second: 12568.3140, train_label_loss: 1.7031, train_domain_loss: 0.4650
=============================================================
epoch: 1, source_val_acc_label: 0.3506, target_val_acc_label: 0.3061, source_val_label_loss: 1.5014, target_val_label_loss: 1.5771, source_and_target_val_domain_loss: 0.9906
=============================================================
New best
epoch: 2, [batch: 1 / 5250], examples_per_second: 18.5599, train_label_loss: 1.5317, train_domain_loss: 0.4931
epoch: 2, [batch: 1050 / 5250], examples_per_second: 12670.1785, train_label_loss: 1.6336, train_domain_loss: 0.5209
epoch: 2, [batch: 2100 / 5250], examples_per_second: 12658.6531, train_label_loss: 1.3380, train_domain_loss: 0.4957
epoch: 2, [batch: 3150 / 5250], examples_per_second: 12633.3557, train_label_loss: 1.3381, train_domain_loss: 0.4975
epoch: 2, [batch: 4200 / 5250], examples_per_second: 12607.4808, train_label_loss: 1.2641, train_domain_loss: 0.4811
=============================================================
epoch: 2, source_val_acc_label: 0.5213, target_val_acc_label: 0.4632, source_val_label_loss: 1.1053, target_val_label_loss: 1.3721, source_and_target_val_domain_loss: 0.9900
=============================================================
New best
epoch: 3, [batch: 1 / 5250], examples_per_second: 18.9301, train_label_loss: 1.3610, train_domain_loss: 0.5105
epoch: 3, [batch: 1050 / 5250], examples_per_second: 12508.6717, train_label_loss: 1.0116, train_domain_loss: 0.4644
epoch: 3, [batch: 2100 / 5250], examples_per_second: 12674.4518, train_label_loss: 1.0825, train_domain_loss: 0.4982
epoch: 3, [batch: 3150 / 5250], examples_per_second: 12563.8136, train_label_loss: 1.2072, train_domain_loss: 0.4530
epoch: 3, [batch: 4200 / 5250], examples_per_second: 12647.5475, train_label_loss: 1.1670, train_domain_loss: 0.5048
=============================================================
epoch: 3, source_val_acc_label: 0.5561, target_val_acc_label: 0.4825, source_val_label_loss: 1.0358, target_val_label_loss: 1.2889, source_and_target_val_domain_loss: 0.9900
=============================================================
New best
epoch: 4, [batch: 1 / 5250], examples_per_second: 19.0488, train_label_loss: 1.4923, train_domain_loss: 0.4885
epoch: 4, [batch: 1050 / 5250], examples_per_second: 12629.1982, train_label_loss: 1.4386, train_domain_loss: 0.5065
epoch: 4, [batch: 2100 / 5250], examples_per_second: 12711.6765, train_label_loss: 0.9017, train_domain_loss: 0.5072
epoch: 4, [batch: 3150 / 5250], examples_per_second: 12694.9252, train_label_loss: 1.2841, train_domain_loss: 0.5375
epoch: 4, [batch: 4200 / 5250], examples_per_second: 12657.1703, train_label_loss: 1.2145, train_domain_loss: 0.5208
=============================================================
epoch: 4, source_val_acc_label: 0.5778, target_val_acc_label: 0.4991, source_val_label_loss: 0.9799, target_val_label_loss: 1.3295, source_and_target_val_domain_loss: 0.9896
=============================================================
New best
epoch: 5, [batch: 1 / 5250], examples_per_second: 18.9435, train_label_loss: 1.5137, train_domain_loss: 0.4688
epoch: 5, [batch: 1050 / 5250], examples_per_second: 12632.6795, train_label_loss: 1.2347, train_domain_loss: 0.5353
epoch: 5, [batch: 2100 / 5250], examples_per_second: 12554.3495, train_label_loss: 1.0087, train_domain_loss: 0.5077
epoch: 5, [batch: 3150 / 5250], examples_per_second: 12653.7527, train_label_loss: 0.9808, train_domain_loss: 0.5090
epoch: 5, [batch: 4200 / 5250], examples_per_second: 12641.6148, train_label_loss: 1.0552, train_domain_loss: 0.5240
=============================================================
epoch: 5, source_val_acc_label: 0.5842, target_val_acc_label: 0.5173, source_val_label_loss: 0.9592, target_val_label_loss: 1.2289, source_and_target_val_domain_loss: 0.9896
=============================================================
New best
epoch: 6, [batch: 1 / 5250], examples_per_second: 19.1973, train_label_loss: 1.2318, train_domain_loss: 0.5271
epoch: 6, [batch: 1050 / 5250], examples_per_second: 12678.7860, train_label_loss: 1.1083, train_domain_loss: 0.4776
epoch: 6, [batch: 2100 / 5250], examples_per_second: 12673.4440, train_label_loss: 1.1478, train_domain_loss: 0.5085
epoch: 6, [batch: 3150 / 5250], examples_per_second: 12665.6185, train_label_loss: 1.0318, train_domain_loss: 0.4762
epoch: 6, [batch: 4200 / 5250], examples_per_second: 12729.5565, train_label_loss: 1.0571, train_domain_loss: 0.4871
=============================================================
epoch: 6, source_val_acc_label: 0.5794, target_val_acc_label: 0.4899, source_val_label_loss: 0.9792, target_val_label_loss: 1.2603, source_and_target_val_domain_loss: 0.9897
=============================================================
epoch: 7, [batch: 1 / 5250], examples_per_second: 19.0961, train_label_loss: 0.8645, train_domain_loss: 0.5057
epoch: 7, [batch: 1050 / 5250], examples_per_second: 12610.2616, train_label_loss: 1.1392, train_domain_loss: 0.4938
epoch: 7, [batch: 2100 / 5250], examples_per_second: 12653.7348, train_label_loss: 0.9414, train_domain_loss: 0.5184
epoch: 7, [batch: 3150 / 5250], examples_per_second: 12656.4951, train_label_loss: 1.1135, train_domain_loss: 0.4939
epoch: 7, [batch: 4200 / 5250], examples_per_second: 12656.9194, train_label_loss: 1.1066, train_domain_loss: 0.5495
=============================================================
epoch: 7, source_val_acc_label: 0.5919, target_val_acc_label: 0.5331, source_val_label_loss: 0.9367, target_val_label_loss: 1.1516, source_and_target_val_domain_loss: 0.9900
=============================================================
New best
epoch: 8, [batch: 1 / 5250], examples_per_second: 19.0801, train_label_loss: 1.0273, train_domain_loss: 0.4439
epoch: 8, [batch: 1050 / 5250], examples_per_second: 12627.1303, train_label_loss: 1.1128, train_domain_loss: 0.4641
epoch: 8, [batch: 2100 / 5250], examples_per_second: 12673.8149, train_label_loss: 1.3184, train_domain_loss: 0.4729
epoch: 8, [batch: 3150 / 5250], examples_per_second: 12656.6193, train_label_loss: 1.0348, train_domain_loss: 0.4397
epoch: 8, [batch: 4200 / 5250], examples_per_second: 12658.4499, train_label_loss: 1.0196, train_domain_loss: 0.4803
=============================================================
epoch: 8, source_val_acc_label: 0.6043, target_val_acc_label: 0.5440, source_val_label_loss: 0.9102, target_val_label_loss: 1.1366, source_and_target_val_domain_loss: 0.9899
=============================================================
New best
epoch: 9, [batch: 1 / 5250], examples_per_second: 19.1664, train_label_loss: 0.9159, train_domain_loss: 0.4871
epoch: 9, [batch: 1050 / 5250], examples_per_second: 12608.3238, train_label_loss: 1.1758, train_domain_loss: 0.5104
epoch: 9, [batch: 2100 / 5250], examples_per_second: 12690.0160, train_label_loss: 0.9451, train_domain_loss: 0.5175
epoch: 9, [batch: 3150 / 5250], examples_per_second: 12506.2054, train_label_loss: 1.3684, train_domain_loss: 0.4671
epoch: 9, [batch: 4200 / 5250], examples_per_second: 12549.7700, train_label_loss: 1.0756, train_domain_loss: 0.5083
=============================================================
epoch: 9, source_val_acc_label: 0.5812, target_val_acc_label: 0.5554, source_val_label_loss: 0.9556, target_val_label_loss: 1.1236, source_and_target_val_domain_loss: 0.9899
=============================================================
epoch: 10, [batch: 1 / 5250], examples_per_second: 19.0454, train_label_loss: 1.1518, train_domain_loss: 0.5128
epoch: 10, [batch: 1050 / 5250], examples_per_second: 12630.3535, train_label_loss: 1.4689, train_domain_loss: 0.4903
epoch: 10, [batch: 2100 / 5250], examples_per_second: 12677.3195, train_label_loss: 0.9091, train_domain_loss: 0.5485
epoch: 10, [batch: 3150 / 5250], examples_per_second: 12688.6681, train_label_loss: 0.9993, train_domain_loss: 0.4659
epoch: 10, [batch: 4200 / 5250], examples_per_second: 12665.4754, train_label_loss: 0.8232, train_domain_loss: 0.4951
=============================================================
epoch: 10, source_val_acc_label: 0.6095, target_val_acc_label: 0.5691, source_val_label_loss: 0.9018, target_val_label_loss: 1.0936, source_and_target_val_domain_loss: 0.9901
=============================================================
New best
epoch: 11, [batch: 1 / 5250], examples_per_second: 19.0710, train_label_loss: 0.9717, train_domain_loss: 0.5195
epoch: 11, [batch: 1050 / 5250], examples_per_second: 12600.6258, train_label_loss: 0.8534, train_domain_loss: 0.4880
epoch: 11, [batch: 2100 / 5250], examples_per_second: 12739.6527, train_label_loss: 1.2499, train_domain_loss: 0.5282
epoch: 11, [batch: 3150 / 5250], examples_per_second: 12711.8456, train_label_loss: 0.7970, train_domain_loss: 0.4927
epoch: 11, [batch: 4200 / 5250], examples_per_second: 12661.5584, train_label_loss: 1.1660, train_domain_loss: 0.5292
=============================================================
epoch: 11, source_val_acc_label: 0.6142, target_val_acc_label: 0.5643, source_val_label_loss: 0.8914, target_val_label_loss: 1.1095, source_and_target_val_domain_loss: 0.9900
=============================================================
epoch: 12, [batch: 1 / 5250], examples_per_second: 18.9728, train_label_loss: 1.1297, train_domain_loss: 0.4676
epoch: 12, [batch: 1050 / 5250], examples_per_second: 12643.8602, train_label_loss: 1.0270, train_domain_loss: 0.4220
epoch: 12, [batch: 2100 / 5250], examples_per_second: 12678.6229, train_label_loss: 1.0675, train_domain_loss: 0.4771
epoch: 12, [batch: 3150 / 5250], examples_per_second: 12659.2760, train_label_loss: 0.8838, train_domain_loss: 0.4259
epoch: 12, [batch: 4200 / 5250], examples_per_second: 12554.7252, train_label_loss: 1.0750, train_domain_loss: 0.5180
=============================================================
epoch: 12, source_val_acc_label: 0.6149, target_val_acc_label: 0.5713, source_val_label_loss: 0.8805, target_val_label_loss: 1.0725, source_and_target_val_domain_loss: 0.9902
=============================================================
New best
epoch: 13, [batch: 1 / 5250], examples_per_second: 18.9729, train_label_loss: 0.9880, train_domain_loss: 0.4820
epoch: 13, [batch: 1050 / 5250], examples_per_second: 12612.8960, train_label_loss: 1.1184, train_domain_loss: 0.4899
epoch: 13, [batch: 2100 / 5250], examples_per_second: 12632.1897, train_label_loss: 1.3349, train_domain_loss: 0.4981
epoch: 13, [batch: 3150 / 5250], examples_per_second: 12673.3063, train_label_loss: 1.1592, train_domain_loss: 0.5008
epoch: 13, [batch: 4200 / 5250], examples_per_second: 12644.0465, train_label_loss: 0.9986, train_domain_loss: 0.5198
=============================================================
epoch: 13, source_val_acc_label: 0.6195, target_val_acc_label: 0.5625, source_val_label_loss: 0.8798, target_val_label_loss: 1.1578, source_and_target_val_domain_loss: 0.9904
=============================================================
epoch: 14, [batch: 1 / 5250], examples_per_second: 19.0470, train_label_loss: 1.1065, train_domain_loss: 0.4925
epoch: 14, [batch: 1050 / 5250], examples_per_second: 12666.2922, train_label_loss: 0.8291, train_domain_loss: 0.4799
epoch: 14, [batch: 2100 / 5250], examples_per_second: 12642.2541, train_label_loss: 0.6593, train_domain_loss: 0.4955
epoch: 14, [batch: 3150 / 5250], examples_per_second: 12699.1603, train_label_loss: 1.0106, train_domain_loss: 0.4868
epoch: 14, [batch: 4200 / 5250], examples_per_second: 12657.4204, train_label_loss: 1.0169, train_domain_loss: 0.5072
=============================================================
epoch: 14, source_val_acc_label: 0.6295, target_val_acc_label: 0.5801, source_val_label_loss: 0.8567, target_val_label_loss: 1.1008, source_and_target_val_domain_loss: 0.9903
=============================================================
epoch: 15, [batch: 1 / 5250], examples_per_second: 19.0522, train_label_loss: 1.1231, train_domain_loss: 0.5158
epoch: 15, [batch: 1050 / 5250], examples_per_second: 12630.7153, train_label_loss: 1.0144, train_domain_loss: 0.5055
epoch: 15, [batch: 2100 / 5250], examples_per_second: 12671.1467, train_label_loss: 1.0759, train_domain_loss: 0.5198
epoch: 15, [batch: 3150 / 5250], examples_per_second: 12682.1173, train_label_loss: 0.7640, train_domain_loss: 0.5096
epoch: 15, [batch: 4200 / 5250], examples_per_second: 12656.4903, train_label_loss: 0.9077, train_domain_loss: 0.4636
=============================================================
epoch: 15, source_val_acc_label: 0.6172, target_val_acc_label: 0.5579, source_val_label_loss: 0.8832, target_val_label_loss: 1.1862, source_and_target_val_domain_loss: 0.9905
=============================================================
epoch: 16, [batch: 1 / 5250], examples_per_second: 19.0529, train_label_loss: 0.8890, train_domain_loss: 0.4768
epoch: 16, [batch: 1050 / 5250], examples_per_second: 12656.6332, train_label_loss: 1.0852, train_domain_loss: 0.5087
epoch: 16, [batch: 2100 / 5250], examples_per_second: 12651.7159, train_label_loss: 0.8591, train_domain_loss: 0.5206
epoch: 16, [batch: 3150 / 5250], examples_per_second: 12656.2760, train_label_loss: 1.2108, train_domain_loss: 0.4701
epoch: 16, [batch: 4200 / 5250], examples_per_second: 12668.9708, train_label_loss: 0.7174, train_domain_loss: 0.4434
=============================================================
epoch: 16, source_val_acc_label: 0.6247, target_val_acc_label: 0.5710, source_val_label_loss: 0.8709, target_val_label_loss: 1.0695, source_and_target_val_domain_loss: 0.9902
=============================================================
New best
epoch: 17, [batch: 1 / 5250], examples_per_second: 19.1242, train_label_loss: 0.6321, train_domain_loss: 0.4807
epoch: 17, [batch: 1050 / 5250], examples_per_second: 12600.9920, train_label_loss: 0.9300, train_domain_loss: 0.4915
epoch: 17, [batch: 2100 / 5250], examples_per_second: 12684.0660, train_label_loss: 0.9472, train_domain_loss: 0.5289
epoch: 17, [batch: 3150 / 5250], examples_per_second: 12674.9719, train_label_loss: 1.0599, train_domain_loss: 0.4815
epoch: 17, [batch: 4200 / 5250], examples_per_second: 12581.6917, train_label_loss: 1.2511, train_domain_loss: 0.4729
=============================================================
epoch: 17, source_val_acc_label: 0.6304, target_val_acc_label: 0.5648, source_val_label_loss: 0.8526, target_val_label_loss: 1.1547, source_and_target_val_domain_loss: 0.9904
=============================================================
epoch: 18, [batch: 1 / 5250], examples_per_second: 18.9858, train_label_loss: 0.8462, train_domain_loss: 0.5270
epoch: 18, [batch: 1050 / 5250], examples_per_second: 12633.8255, train_label_loss: 0.8862, train_domain_loss: 0.5038
epoch: 18, [batch: 2100 / 5250], examples_per_second: 12673.5776, train_label_loss: 0.8198, train_domain_loss: 0.5104
epoch: 18, [batch: 3150 / 5250], examples_per_second: 12725.5802, train_label_loss: 1.0192, train_domain_loss: 0.4976
epoch: 18, [batch: 4200 / 5250], examples_per_second: 12688.2620, train_label_loss: 1.0136, train_domain_loss: 0.5275
=============================================================
epoch: 18, source_val_acc_label: 0.6337, target_val_acc_label: 0.5699, source_val_label_loss: 0.8503, target_val_label_loss: 1.1211, source_and_target_val_domain_loss: 0.9904
=============================================================
epoch: 19, [batch: 1 / 5250], examples_per_second: 19.0452, train_label_loss: 1.1790, train_domain_loss: 0.5160
epoch: 19, [batch: 1050 / 5250], examples_per_second: 12537.0173, train_label_loss: 0.9376, train_domain_loss: 0.5041
epoch: 19, [batch: 2100 / 5250], examples_per_second: 12682.2434, train_label_loss: 1.0511, train_domain_loss: 0.4788
epoch: 19, [batch: 3150 / 5250], examples_per_second: 12668.1790, train_label_loss: 1.0182, train_domain_loss: 0.5265
epoch: 19, [batch: 4200 / 5250], examples_per_second: 12687.3247, train_label_loss: 1.1477, train_domain_loss: 0.5297
=============================================================
epoch: 19, source_val_acc_label: 0.6385, target_val_acc_label: 0.5787, source_val_label_loss: 0.8389, target_val_label_loss: 1.1123, source_and_target_val_domain_loss: 0.9904
=============================================================
epoch: 20, [batch: 1 / 5250], examples_per_second: 19.0405, train_label_loss: 1.0209, train_domain_loss: 0.5277
epoch: 20, [batch: 1050 / 5250], examples_per_second: 12623.0185, train_label_loss: 1.1551, train_domain_loss: 0.4776
epoch: 20, [batch: 2100 / 5250], examples_per_second: 12660.7618, train_label_loss: 0.9612, train_domain_loss: 0.5322
epoch: 20, [batch: 3150 / 5250], examples_per_second: 12678.4478, train_label_loss: 1.0004, train_domain_loss: 0.5142
epoch: 20, [batch: 4200 / 5250], examples_per_second: 12673.9064, train_label_loss: 0.7617, train_domain_loss: 0.5292
=============================================================
epoch: 20, source_val_acc_label: 0.6392, target_val_acc_label: 0.5716, source_val_label_loss: 0.8422, target_val_label_loss: 1.2672, source_and_target_val_domain_loss: 0.9905
=============================================================
epoch: 21, [batch: 1 / 5250], examples_per_second: 19.1060, train_label_loss: 0.7875, train_domain_loss: 0.5085
epoch: 21, [batch: 1050 / 5250], examples_per_second: 12619.3316, train_label_loss: 0.8996, train_domain_loss: 0.5059
epoch: 21, [batch: 2100 / 5250], examples_per_second: 12675.5807, train_label_loss: 1.1788, train_domain_loss: 0.5002
epoch: 21, [batch: 3150 / 5250], examples_per_second: 12681.9204, train_label_loss: 1.0495, train_domain_loss: 0.4827
epoch: 21, [batch: 4200 / 5250], examples_per_second: 12664.3725, train_label_loss: 1.1669, train_domain_loss: 0.5118
=============================================================
epoch: 21, source_val_acc_label: 0.6407, target_val_acc_label: 0.5805, source_val_label_loss: 0.8365, target_val_label_loss: 1.0985, source_and_target_val_domain_loss: 0.9903
=============================================================
New best
epoch: 22, [batch: 1 / 5250], examples_per_second: 19.1196, train_label_loss: 0.9846, train_domain_loss: 0.4787
epoch: 22, [batch: 1050 / 5250], examples_per_second: 12659.7716, train_label_loss: 0.9230, train_domain_loss: 0.5145
epoch: 22, [batch: 2100 / 5250], examples_per_second: 12683.1496, train_label_loss: 0.8325, train_domain_loss: 0.4916
epoch: 22, [batch: 3150 / 5250], examples_per_second: 12695.0392, train_label_loss: 0.8870, train_domain_loss: 0.5131
epoch: 22, [batch: 4200 / 5250], examples_per_second: 12694.1842, train_label_loss: 0.8993, train_domain_loss: 0.4790
=============================================================
epoch: 22, source_val_acc_label: 0.6413, target_val_acc_label: 0.5704, source_val_label_loss: 0.8326, target_val_label_loss: 1.2372, source_and_target_val_domain_loss: 0.9905
=============================================================
epoch: 23, [batch: 1 / 5250], examples_per_second: 19.1838, train_label_loss: 1.0952, train_domain_loss: 0.5193
epoch: 23, [batch: 1050 / 5250], examples_per_second: 12631.5538, train_label_loss: 0.8191, train_domain_loss: 0.4894
epoch: 23, [batch: 2100 / 5250], examples_per_second: 12675.2432, train_label_loss: 1.2689, train_domain_loss: 0.4965
epoch: 23, [batch: 3150 / 5250], examples_per_second: 12702.6964, train_label_loss: 1.1309, train_domain_loss: 0.4891
epoch: 23, [batch: 4200 / 5250], examples_per_second: 12688.3905, train_label_loss: 1.1713, train_domain_loss: 0.5368
=============================================================
epoch: 23, source_val_acc_label: 0.6404, target_val_acc_label: 0.5829, source_val_label_loss: 0.8378, target_val_label_loss: 1.1382, source_and_target_val_domain_loss: 0.9903
=============================================================
epoch: 24, [batch: 1 / 5250], examples_per_second: 18.9962, train_label_loss: 1.1174, train_domain_loss: 0.4310
epoch: 24, [batch: 1050 / 5250], examples_per_second: 12444.4444, train_label_loss: 0.9105, train_domain_loss: 0.4989
epoch: 24, [batch: 2100 / 5250], examples_per_second: 12615.8136, train_label_loss: 0.9710, train_domain_loss: 0.4854
epoch: 24, [batch: 3150 / 5250], examples_per_second: 12631.1772, train_label_loss: 0.8755, train_domain_loss: 0.5052
epoch: 24, [batch: 4200 / 5250], examples_per_second: 12629.1301, train_label_loss: 1.1067, train_domain_loss: 0.4382
=============================================================
epoch: 24, source_val_acc_label: 0.6373, target_val_acc_label: 0.5793, source_val_label_loss: 0.8300, target_val_label_loss: 1.1642, source_and_target_val_domain_loss: 0.9906
=============================================================
epoch: 25, [batch: 1 / 5250], examples_per_second: 19.0937, train_label_loss: 0.8556, train_domain_loss: 0.4702
epoch: 25, [batch: 1050 / 5250], examples_per_second: 12652.2344, train_label_loss: 0.8820, train_domain_loss: 0.5116
epoch: 25, [batch: 2100 / 5250], examples_per_second: 12611.9648, train_label_loss: 0.9961, train_domain_loss: 0.4871
epoch: 25, [batch: 3150 / 5250], examples_per_second: 12625.5910, train_label_loss: 0.6867, train_domain_loss: 0.5478
epoch: 25, [batch: 4200 / 5250], examples_per_second: 12606.4371, train_label_loss: 0.8320, train_domain_loss: 0.4801
=============================================================
epoch: 25, source_val_acc_label: 0.6459, target_val_acc_label: 0.5683, source_val_label_loss: 0.8246, target_val_label_loss: 1.1679, source_and_target_val_domain_loss: 0.9905
=============================================================
epoch: 26, [batch: 1 / 5250], examples_per_second: 19.1647, train_label_loss: 0.9153, train_domain_loss: 0.5042
epoch: 26, [batch: 1050 / 5250], examples_per_second: 12658.2530, train_label_loss: 0.9783, train_domain_loss: 0.4657
epoch: 26, [batch: 2100 / 5250], examples_per_second: 12703.9586, train_label_loss: 0.9545, train_domain_loss: 0.5258
epoch: 26, [batch: 3150 / 5250], examples_per_second: 12699.2010, train_label_loss: 0.9583, train_domain_loss: 0.4939
epoch: 26, [batch: 4200 / 5250], examples_per_second: 12552.1911, train_label_loss: 0.9009, train_domain_loss: 0.4755
=============================================================
epoch: 26, source_val_acc_label: 0.6442, target_val_acc_label: 0.5788, source_val_label_loss: 0.8290, target_val_label_loss: 1.1231, source_and_target_val_domain_loss: 0.9904
=============================================================
epoch: 27, [batch: 1 / 5250], examples_per_second: 18.8793, train_label_loss: 1.0912, train_domain_loss: 0.4923
epoch: 27, [batch: 1050 / 5250], examples_per_second: 12568.3846, train_label_loss: 0.9591, train_domain_loss: 0.4996
epoch: 27, [batch: 2100 / 5250], examples_per_second: 12671.6398, train_label_loss: 0.8002, train_domain_loss: 0.4489
epoch: 27, [batch: 3150 / 5250], examples_per_second: 12608.7258, train_label_loss: 0.9590, train_domain_loss: 0.4656
epoch: 27, [batch: 4200 / 5250], examples_per_second: 12528.3137, train_label_loss: 1.3382, train_domain_loss: 0.4858
=============================================================
epoch: 27, source_val_acc_label: 0.6349, target_val_acc_label: 0.5676, source_val_label_loss: 0.8431, target_val_label_loss: 1.1428, source_and_target_val_domain_loss: 0.9905
=============================================================
epoch: 28, [batch: 1 / 5250], examples_per_second: 18.9166, train_label_loss: 1.0645, train_domain_loss: 0.5315
epoch: 28, [batch: 1050 / 5250], examples_per_second: 12623.8461, train_label_loss: 1.0814, train_domain_loss: 0.4316
epoch: 28, [batch: 2100 / 5250], examples_per_second: 12681.2426, train_label_loss: 0.9882, train_domain_loss: 0.5218
epoch: 28, [batch: 3150 / 5250], examples_per_second: 12667.8320, train_label_loss: 0.8755, train_domain_loss: 0.5498
epoch: 28, [batch: 4200 / 5250], examples_per_second: 12677.0812, train_label_loss: 1.1174, train_domain_loss: 0.4700
=============================================================
epoch: 28, source_val_acc_label: 0.6452, target_val_acc_label: 0.5849, source_val_label_loss: 0.8270, target_val_label_loss: 1.0864, source_and_target_val_domain_loss: 0.9905
=============================================================
New best
epoch: 29, [batch: 1 / 5250], examples_per_second: 18.9004, train_label_loss: 1.1011, train_domain_loss: 0.4951
epoch: 29, [batch: 1050 / 5250], examples_per_second: 12577.9880, train_label_loss: 1.2394, train_domain_loss: 0.5398
epoch: 29, [batch: 2100 / 5250], examples_per_second: 12653.5689, train_label_loss: 0.9887, train_domain_loss: 0.4700
epoch: 29, [batch: 3150 / 5250], examples_per_second: 12484.9425, train_label_loss: 0.9160, train_domain_loss: 0.5425
epoch: 29, [batch: 4200 / 5250], examples_per_second: 12585.4541, train_label_loss: 0.9515, train_domain_loss: 0.5394
=============================================================
epoch: 29, source_val_acc_label: 0.6273, target_val_acc_label: 0.5699, source_val_label_loss: 0.8572, target_val_label_loss: 1.0788, source_and_target_val_domain_loss: 1.1326
=============================================================
epoch: 30, [batch: 1 / 5250], examples_per_second: 19.1303, train_label_loss: 1.0754, train_domain_loss: 0.5277
epoch: 30, [batch: 1050 / 5250], examples_per_second: 12555.6513, train_label_loss: 1.0750, train_domain_loss: 0.5446
epoch: 30, [batch: 2100 / 5250], examples_per_second: 12708.5233, train_label_loss: 1.0634, train_domain_loss: 0.6202
epoch: 30, [batch: 3150 / 5250], examples_per_second: 12674.0181, train_label_loss: 0.9775, train_domain_loss: 0.5920
epoch: 30, [batch: 4200 / 5250], examples_per_second: 12672.9550, train_label_loss: 0.7522, train_domain_loss: 0.5544
=============================================================
epoch: 30, source_val_acc_label: 0.6393, target_val_acc_label: 0.5604, source_val_label_loss: 0.8275, target_val_label_loss: 1.1656, source_and_target_val_domain_loss: 1.3705
=============================================================
epoch: 31, [batch: 1 / 5250], examples_per_second: 18.9096, train_label_loss: 1.2010, train_domain_loss: 0.6158
epoch: 31, [batch: 1050 / 5250], examples_per_second: 12636.1917, train_label_loss: 0.9378, train_domain_loss: 0.5943
epoch: 31, [batch: 2100 / 5250], examples_per_second: 12664.3241, train_label_loss: 0.9264, train_domain_loss: 0.6303
epoch: 31, [batch: 3150 / 5250], examples_per_second: 12697.6060, train_label_loss: 1.1893, train_domain_loss: 0.7008
epoch: 31, [batch: 4200 / 5250], examples_per_second: 12696.2367, train_label_loss: 1.0277, train_domain_loss: 0.7147
=============================================================
epoch: 31, source_val_acc_label: 0.6504, target_val_acc_label: 0.5623, source_val_label_loss: 0.8187, target_val_label_loss: 1.3515, source_and_target_val_domain_loss: 1.4458
=============================================================
epoch: 32, [batch: 1 / 5250], examples_per_second: 19.1066, train_label_loss: 1.0141, train_domain_loss: 0.6751
epoch: 32, [batch: 1050 / 5250], examples_per_second: 12644.0070, train_label_loss: 1.0548, train_domain_loss: 0.6777
epoch: 32, [batch: 2100 / 5250], examples_per_second: 12670.0469, train_label_loss: 0.7033, train_domain_loss: 0.6413
epoch: 32, [batch: 3150 / 5250], examples_per_second: 12699.4573, train_label_loss: 1.0972, train_domain_loss: 0.6933
epoch: 32, [batch: 4200 / 5250], examples_per_second: 12713.9649, train_label_loss: 1.1655, train_domain_loss: 0.6970
=============================================================
epoch: 32, source_val_acc_label: 0.6448, target_val_acc_label: 0.5703, source_val_label_loss: 0.8155, target_val_label_loss: 1.2521, source_and_target_val_domain_loss: 1.4724
=============================================================
epoch: 33, [batch: 1 / 5250], examples_per_second: 18.9349, train_label_loss: 0.5509, train_domain_loss: 0.7110
epoch: 33, [batch: 1050 / 5250], examples_per_second: 12666.7887, train_label_loss: 0.8095, train_domain_loss: 0.6790
epoch: 33, [batch: 2100 / 5250], examples_per_second: 12710.8831, train_label_loss: 1.0062, train_domain_loss: 0.6999
epoch: 33, [batch: 3150 / 5250], examples_per_second: 12660.3535, train_label_loss: 0.9958, train_domain_loss: 0.7014
epoch: 33, [batch: 4200 / 5250], examples_per_second: 12638.7334, train_label_loss: 0.8115, train_domain_loss: 0.6911
=============================================================
epoch: 33, source_val_acc_label: 0.6460, target_val_acc_label: 0.5731, source_val_label_loss: 0.8171, target_val_label_loss: 1.2473, source_and_target_val_domain_loss: 1.4880
=============================================================
epoch: 34, [batch: 1 / 5250], examples_per_second: 18.9068, train_label_loss: 0.8518, train_domain_loss: 0.7231
epoch: 34, [batch: 1050 / 5250], examples_per_second: 12472.9983, train_label_loss: 1.1331, train_domain_loss: 0.6747
epoch: 34, [batch: 2100 / 5250], examples_per_second: 12637.9321, train_label_loss: 0.8672, train_domain_loss: 0.7248
epoch: 34, [batch: 3150 / 5250], examples_per_second: 12661.6013, train_label_loss: 0.8761, train_domain_loss: 0.7001
epoch: 34, [batch: 4200 / 5250], examples_per_second: 12663.7722, train_label_loss: 0.7196, train_domain_loss: 0.7106
=============================================================
epoch: 34, source_val_acc_label: 0.6478, target_val_acc_label: 0.5728, source_val_label_loss: 0.8119, target_val_label_loss: 1.1732, source_and_target_val_domain_loss: 1.5016
=============================================================
epoch: 35, [batch: 1 / 5250], examples_per_second: 19.0386, train_label_loss: 1.0182, train_domain_loss: 0.7135
epoch: 35, [batch: 1050 / 5250], examples_per_second: 12661.9391, train_label_loss: 0.6572, train_domain_loss: 0.6842
epoch: 35, [batch: 2100 / 5250], examples_per_second: 12680.1809, train_label_loss: 0.8834, train_domain_loss: 0.7092
epoch: 35, [batch: 3150 / 5250], examples_per_second: 12693.6774, train_label_loss: 1.1399, train_domain_loss: 0.6993
epoch: 35, [batch: 4200 / 5250], examples_per_second: 12659.1048, train_label_loss: 0.9473, train_domain_loss: 0.7436
=============================================================
epoch: 35, source_val_acc_label: 0.6515, target_val_acc_label: 0.5764, source_val_label_loss: 0.8005, target_val_label_loss: 1.2185, source_and_target_val_domain_loss: 1.5253
=============================================================
epoch: 36, [batch: 1 / 5250], examples_per_second: 19.1204, train_label_loss: 1.0209, train_domain_loss: 0.7082
epoch: 36, [batch: 1050 / 5250], examples_per_second: 12624.8111, train_label_loss: 0.9620, train_domain_loss: 0.7270
epoch: 36, [batch: 2100 / 5250], examples_per_second: 12653.0642, train_label_loss: 0.9450, train_domain_loss: 0.7177
epoch: 36, [batch: 3150 / 5250], examples_per_second: 12620.5989, train_label_loss: 0.8725, train_domain_loss: 0.7464
epoch: 36, [batch: 4200 / 5250], examples_per_second: 12647.6891, train_label_loss: 0.8748, train_domain_loss: 0.7371
=============================================================
epoch: 36, source_val_acc_label: 0.6454, target_val_acc_label: 0.5600, source_val_label_loss: 0.8077, target_val_label_loss: 1.2618, source_and_target_val_domain_loss: 1.5344
=============================================================
epoch: 37, [batch: 1 / 5250], examples_per_second: 19.1135, train_label_loss: 1.0530, train_domain_loss: 0.7510
epoch: 37, [batch: 1050 / 5250], examples_per_second: 12645.7150, train_label_loss: 0.9347, train_domain_loss: 0.7110
epoch: 37, [batch: 2100 / 5250], examples_per_second: 12689.2396, train_label_loss: 0.7542, train_domain_loss: 0.7107
epoch: 37, [batch: 3150 / 5250], examples_per_second: 12676.0840, train_label_loss: 0.8732, train_domain_loss: 0.6992
epoch: 37, [batch: 4200 / 5250], examples_per_second: 12684.4567, train_label_loss: 0.9161, train_domain_loss: 0.7187
=============================================================
epoch: 37, source_val_acc_label: 0.6448, target_val_acc_label: 0.5533, source_val_label_loss: 0.8153, target_val_label_loss: 1.2838, source_and_target_val_domain_loss: 1.5450
=============================================================
epoch: 38, [batch: 1 / 5250], examples_per_second: 19.1021, train_label_loss: 1.1901, train_domain_loss: 0.7325
epoch: 38, [batch: 1050 / 5250], examples_per_second: 12623.8914, train_label_loss: 0.9598, train_domain_loss: 0.7467
epoch: 38, [batch: 2100 / 5250], examples_per_second: 12685.7187, train_label_loss: 0.8335, train_domain_loss: 0.7046
epoch: 38, [batch: 3150 / 5250], examples_per_second: 12658.1099, train_label_loss: 1.1465, train_domain_loss: 0.7740
epoch: 38, [batch: 4200 / 5250], examples_per_second: 12662.6070, train_label_loss: 1.2101, train_domain_loss: 0.7273
=============================================================
epoch: 38, source_val_acc_label: 0.6533, target_val_acc_label: 0.5692, source_val_label_loss: 0.8046, target_val_label_loss: 1.1782, source_and_target_val_domain_loss: 1.5508
=============================================================
epoch: 39, [batch: 1 / 5250], examples_per_second: 19.0538, train_label_loss: 0.9999, train_domain_loss: 0.7361
epoch: 39, [batch: 1050 / 5250], examples_per_second: 12633.1451, train_label_loss: 0.7861, train_domain_loss: 0.7446
epoch: 39, [batch: 2100 / 5250], examples_per_second: 12667.5727, train_label_loss: 0.9828, train_domain_loss: 0.7442
epoch: 39, [batch: 3150 / 5250], examples_per_second: 12673.7847, train_label_loss: 0.9494, train_domain_loss: 0.7680
epoch: 39, [batch: 4200 / 5250], examples_per_second: 12663.7963, train_label_loss: 1.0022, train_domain_loss: 0.7476
=============================================================
epoch: 39, source_val_acc_label: 0.6483, target_val_acc_label: 0.5576, source_val_label_loss: 0.8066, target_val_label_loss: 1.1586, source_and_target_val_domain_loss: 1.5535
=============================================================
Patience (10) exhausted
Source Val Label Accuracy: 0.6451851851851852 Target Val Label Accuracy: 0.5848809523809524
Source Test Label Accuracy: 0.6447916666666667 Target Test Label Accuracy: 0.588644953919108
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
