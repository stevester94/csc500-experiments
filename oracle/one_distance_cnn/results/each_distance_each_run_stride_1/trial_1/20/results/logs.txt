[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1898.4858, train_label_loss: 2.7726, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 24070.1592, train_label_loss: 2.7725, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 24028.6880, train_label_loss: 2.7725, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 24017.4920, train_label_loss: 2.7727, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 24002.3828, train_label_loss: 2.7726, 
=============================================================
epoch: 1, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 16.8665, train_label_loss: 2.7726, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 23861.1418, train_label_loss: 2.7726, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 23868.7703, train_label_loss: 2.7726, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 23877.6068, train_label_loss: 2.7727, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 23860.2992, train_label_loss: 2.7727, 
=============================================================
epoch: 2, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 3, [batch: 1 / 11375], examples_per_second: 17.1826, train_label_loss: 2.7726, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 23866.7425, train_label_loss: 2.7727, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 23873.2645, train_label_loss: 2.7727, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 23867.1154, train_label_loss: 2.7725, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 23876.9087, train_label_loss: 2.7729, 
=============================================================
epoch: 3, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 4, [batch: 1 / 11375], examples_per_second: 17.2168, train_label_loss: 2.7725, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 23887.2750, train_label_loss: 2.7724, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 23859.8564, train_label_loss: 2.7726, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 23859.1859, train_label_loss: 2.7724, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 23856.7952, train_label_loss: 2.7729, 
=============================================================
epoch: 4, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 5, [batch: 1 / 11375], examples_per_second: 17.1832, train_label_loss: 2.7726, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 23886.8050, train_label_loss: 2.7725, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 23861.9464, train_label_loss: 2.7726, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 23860.5749, train_label_loss: 2.7723, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 23872.1271, train_label_loss: 2.7729, 
=============================================================
epoch: 5, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 17.2114, train_label_loss: 2.7727, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 23852.8006, train_label_loss: 2.7724, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 23861.7357, train_label_loss: 2.7723, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 23883.9282, train_label_loss: 2.7729, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 23866.4478, train_label_loss: 2.7722, 
=============================================================
epoch: 6, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 7, [batch: 1 / 11375], examples_per_second: 17.0291, train_label_loss: 2.7727, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 23859.7916, train_label_loss: 2.7729, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 23858.3072, train_label_loss: 2.7728, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 23864.3636, train_label_loss: 2.7726, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 23863.3611, train_label_loss: 2.7727, 
=============================================================
epoch: 7, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 17.2615, train_label_loss: 2.7723, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 23883.2179, train_label_loss: 2.7727, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 23867.8651, train_label_loss: 2.7725, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 23829.8746, train_label_loss: 2.7728, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 23866.2843, train_label_loss: 2.7723, 
=============================================================
epoch: 8, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 9, [batch: 1 / 11375], examples_per_second: 17.2358, train_label_loss: 2.7729, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 23911.0459, train_label_loss: 2.7725, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 23889.3589, train_label_loss: 2.7726, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 23873.3977, train_label_loss: 2.7724, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 23843.7468, train_label_loss: 2.7726, 
=============================================================
epoch: 9, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 17.2910, train_label_loss: 2.7725, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 23879.3391, train_label_loss: 2.7724, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 23859.1570, train_label_loss: 2.7723, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 23876.8233, train_label_loss: 2.7726, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 23877.9270, train_label_loss: 2.7726, 
=============================================================
epoch: 10, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 11, [batch: 1 / 11375], examples_per_second: 17.1677, train_label_loss: 2.7729, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 23857.3230, train_label_loss: 2.7728, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 23867.3062, train_label_loss: 2.7725, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 23845.1414, train_label_loss: 2.7725, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 23844.3149, train_label_loss: 2.7727, 
=============================================================
epoch: 11, val_acc_label: 0.0620, val_label_loss: 2.7726, 
=============================================================
epoch: 12, [batch: 1 / 11375], examples_per_second: 17.2614, train_label_loss: 2.7725, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 23869.8693, train_label_loss: 2.7724, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 23894.9603, train_label_loss: 2.7724, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 23882.6000, train_label_loss: 2.7730, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 23882.0097, train_label_loss: 2.7725, 
=============================================================
epoch: 12, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.062400641025641024 Target Test Label Accuracy: 0.062400641025641024
Source Val Label Accuracy: 0.0625801282051282 Target Val Label Accuracy: 0.0625801282051282
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
