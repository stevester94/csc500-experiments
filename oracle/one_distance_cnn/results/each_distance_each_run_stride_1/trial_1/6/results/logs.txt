[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1801.7223, train_label_loss: 2.7726, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 34934.1454, train_label_loss: 2.7725, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 34884.2971, train_label_loss: 2.7724, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 34905.1710, train_label_loss: 2.7727, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 34916.7972, train_label_loss: 2.7728, 
=============================================================
epoch: 1, val_acc_label: 0.0619, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 22.5141, train_label_loss: 2.7723, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 34898.1803, train_label_loss: 2.7725, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 34899.8764, train_label_loss: 2.7724, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 34896.5495, train_label_loss: 2.7723, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 34902.9442, train_label_loss: 2.7728, 
=============================================================
epoch: 2, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 3, [batch: 1 / 11375], examples_per_second: 23.3427, train_label_loss: 2.7726, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 34876.3052, train_label_loss: 2.7728, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 34889.2187, train_label_loss: 2.7727, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 34887.9979, train_label_loss: 2.7728, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 34893.6996, train_label_loss: 2.7725, 
=============================================================
epoch: 3, val_acc_label: 0.0619, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 4, [batch: 1 / 11375], examples_per_second: 23.4082, train_label_loss: 2.7725, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 34876.0382, train_label_loss: 2.7726, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 34912.4875, train_label_loss: 2.7726, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 34901.4935, train_label_loss: 2.7726, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 34932.8401, train_label_loss: 2.7725, 
=============================================================
epoch: 4, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 5, [batch: 1 / 11375], examples_per_second: 23.3492, train_label_loss: 2.7724, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 34895.1733, train_label_loss: 2.7724, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 34896.1262, train_label_loss: 2.7725, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 34892.2258, train_label_loss: 2.7724, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 34894.3212, train_label_loss: 2.7724, 
=============================================================
epoch: 5, val_acc_label: 0.0619, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 23.2665, train_label_loss: 2.7727, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 34874.3804, train_label_loss: 2.7724, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 34861.8684, train_label_loss: 2.7727, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 34868.3858, train_label_loss: 2.7726, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 34877.3958, train_label_loss: 2.7725, 
=============================================================
epoch: 6, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 7, [batch: 1 / 11375], examples_per_second: 22.8630, train_label_loss: 2.7726, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 34896.9922, train_label_loss: 2.7726, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 34894.8461, train_label_loss: 2.7728, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 34879.1229, train_label_loss: 2.7727, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 34891.8745, train_label_loss: 2.7727, 
=============================================================
epoch: 7, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 23.3290, train_label_loss: 2.7728, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 34865.7434, train_label_loss: 2.7727, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 34895.8047, train_label_loss: 2.7728, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 34888.6522, train_label_loss: 2.7728, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 34885.8151, train_label_loss: 2.7725, 
=============================================================
epoch: 8, val_acc_label: 0.0628, val_label_loss: 2.7726, 
=============================================================
epoch: 9, [batch: 1 / 11375], examples_per_second: 23.3545, train_label_loss: 2.7726, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 34871.7367, train_label_loss: 2.7722, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 34898.7102, train_label_loss: 2.7725, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 34889.7280, train_label_loss: 2.7725, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 34879.7813, train_label_loss: 2.7725, 
=============================================================
epoch: 9, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 23.3286, train_label_loss: 2.7727, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 34895.4192, train_label_loss: 2.7726, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 34898.4065, train_label_loss: 2.7728, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 34923.7925, train_label_loss: 2.7723, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 34878.7409, train_label_loss: 2.7723, 
=============================================================
epoch: 10, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 11, [batch: 1 / 11375], examples_per_second: 23.2145, train_label_loss: 2.7727, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 34872.9225, train_label_loss: 2.7725, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 34908.3774, train_label_loss: 2.7727, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 34912.2006, train_label_loss: 2.7722, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 34909.3233, train_label_loss: 2.7728, 
=============================================================
epoch: 11, val_acc_label: 0.0629, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 12, [batch: 1 / 11375], examples_per_second: 23.3223, train_label_loss: 2.7726, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 34914.0724, train_label_loss: 2.7727, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 34896.2907, train_label_loss: 2.7727, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 34894.8466, train_label_loss: 2.7725, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 34892.2383, train_label_loss: 2.7722, 
=============================================================
epoch: 12, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 13, [batch: 1 / 11375], examples_per_second: 23.3007, train_label_loss: 2.7728, 
epoch: 13, [batch: 2275 / 11375], examples_per_second: 34876.5583, train_label_loss: 2.7731, 
epoch: 13, [batch: 4550 / 11375], examples_per_second: 34914.4111, train_label_loss: 2.7728, 
epoch: 13, [batch: 6825 / 11375], examples_per_second: 34907.4775, train_label_loss: 2.7726, 
epoch: 13, [batch: 9100 / 11375], examples_per_second: 34883.0871, train_label_loss: 2.7725, 
=============================================================
epoch: 13, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 14, [batch: 1 / 11375], examples_per_second: 23.3058, train_label_loss: 2.7724, 
epoch: 14, [batch: 2275 / 11375], examples_per_second: 34894.7913, train_label_loss: 2.7725, 
epoch: 14, [batch: 4550 / 11375], examples_per_second: 34891.2789, train_label_loss: 2.7725, 
epoch: 14, [batch: 6825 / 11375], examples_per_second: 34904.0633, train_label_loss: 2.7726, 
epoch: 14, [batch: 9100 / 11375], examples_per_second: 34872.5452, train_label_loss: 2.7727, 
=============================================================
epoch: 14, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 15, [batch: 1 / 11375], examples_per_second: 23.3019, train_label_loss: 2.7727, 
epoch: 15, [batch: 2275 / 11375], examples_per_second: 34919.9894, train_label_loss: 2.7724, 
epoch: 15, [batch: 4550 / 11375], examples_per_second: 34880.5328, train_label_loss: 2.7726, 
epoch: 15, [batch: 6825 / 11375], examples_per_second: 34894.1253, train_label_loss: 2.7727, 
epoch: 15, [batch: 9100 / 11375], examples_per_second: 34912.3418, train_label_loss: 2.7726, 
=============================================================
epoch: 15, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 16, [batch: 1 / 11375], examples_per_second: 23.3295, train_label_loss: 2.7728, 
epoch: 16, [batch: 2275 / 11375], examples_per_second: 34899.5031, train_label_loss: 2.7728, 
epoch: 16, [batch: 4550 / 11375], examples_per_second: 34891.3377, train_label_loss: 2.7727, 
epoch: 16, [batch: 6825 / 11375], examples_per_second: 34901.3858, train_label_loss: 2.7727, 
epoch: 16, [batch: 9100 / 11375], examples_per_second: 34901.7563, train_label_loss: 2.7725, 
=============================================================
epoch: 16, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 17, [batch: 1 / 11375], examples_per_second: 23.3369, train_label_loss: 2.7725, 
epoch: 17, [batch: 2275 / 11375], examples_per_second: 34886.2175, train_label_loss: 2.7727, 
epoch: 17, [batch: 4550 / 11375], examples_per_second: 34888.6063, train_label_loss: 2.7726, 
epoch: 17, [batch: 6825 / 11375], examples_per_second: 34905.4833, train_label_loss: 2.7729, 
epoch: 17, [batch: 9100 / 11375], examples_per_second: 34926.2127, train_label_loss: 2.7725, 
=============================================================
epoch: 17, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 18, [batch: 1 / 11375], examples_per_second: 23.2913, train_label_loss: 2.7726, 
epoch: 18, [batch: 2275 / 11375], examples_per_second: 34867.1629, train_label_loss: 2.7722, 
epoch: 18, [batch: 4550 / 11375], examples_per_second: 34892.6425, train_label_loss: 2.7726, 
epoch: 18, [batch: 6825 / 11375], examples_per_second: 34731.0365, train_label_loss: 2.7730, 
epoch: 18, [batch: 9100 / 11375], examples_per_second: 34877.9780, train_label_loss: 2.7729, 
=============================================================
epoch: 18, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 19, [batch: 1 / 11375], examples_per_second: 22.9428, train_label_loss: 2.7725, 
epoch: 19, [batch: 2275 / 11375], examples_per_second: 34874.3336, train_label_loss: 2.7727, 
epoch: 19, [batch: 4550 / 11375], examples_per_second: 34888.7354, train_label_loss: 2.7725, 
epoch: 19, [batch: 6825 / 11375], examples_per_second: 34894.9368, train_label_loss: 2.7725, 
epoch: 19, [batch: 9100 / 11375], examples_per_second: 34883.8951, train_label_loss: 2.7725, 
=============================================================
epoch: 19, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 20, [batch: 1 / 11375], examples_per_second: 23.2951, train_label_loss: 2.7725, 
epoch: 20, [batch: 2275 / 11375], examples_per_second: 34852.2735, train_label_loss: 2.7726, 
epoch: 20, [batch: 4550 / 11375], examples_per_second: 34859.3680, train_label_loss: 2.7725, 
epoch: 20, [batch: 6825 / 11375], examples_per_second: 34905.2508, train_label_loss: 2.7724, 
epoch: 20, [batch: 9100 / 11375], examples_per_second: 34895.9856, train_label_loss: 2.7726, 
=============================================================
epoch: 20, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 21, [batch: 1 / 11375], examples_per_second: 23.3694, train_label_loss: 2.7727, 
epoch: 21, [batch: 2275 / 11375], examples_per_second: 34885.2396, train_label_loss: 2.7730, 
epoch: 21, [batch: 4550 / 11375], examples_per_second: 34919.7376, train_label_loss: 2.7726, 
epoch: 21, [batch: 6825 / 11375], examples_per_second: 34898.0241, train_label_loss: 2.7726, 
epoch: 21, [batch: 9100 / 11375], examples_per_second: 34904.7695, train_label_loss: 2.7726, 
=============================================================
epoch: 21, val_acc_label: 0.0619, val_label_loss: 2.7726, 
=============================================================
epoch: 22, [batch: 1 / 11375], examples_per_second: 23.4288, train_label_loss: 2.7726, 
epoch: 22, [batch: 2275 / 11375], examples_per_second: 34882.8189, train_label_loss: 2.7727, 
epoch: 22, [batch: 4550 / 11375], examples_per_second: 34895.3047, train_label_loss: 2.7724, 
epoch: 22, [batch: 6825 / 11375], examples_per_second: 34901.4347, train_label_loss: 2.7724, 
epoch: 22, [batch: 9100 / 11375], examples_per_second: 34896.8595, train_label_loss: 2.7730, 
=============================================================
epoch: 22, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.06253205128205128 Target Test Label Accuracy: 0.06253205128205128
Source Val Label Accuracy: 0.06289262820512821 Target Val Label Accuracy: 0.06289262820512821
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
