[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1453.1498, train_label_loss: 2.7726, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 23162.0694, train_label_loss: 2.7725, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 23144.1345, train_label_loss: 2.7724, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 23087.2443, train_label_loss: 2.7727, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 23087.8776, train_label_loss: 2.7726, 
=============================================================
epoch: 1, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 16.3506, train_label_loss: 2.7726, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 23078.8662, train_label_loss: 2.7726, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 23070.9482, train_label_loss: 2.7727, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 23112.6855, train_label_loss: 2.7727, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 23078.0326, train_label_loss: 2.7727, 
=============================================================
epoch: 2, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 3, [batch: 1 / 11375], examples_per_second: 16.7915, train_label_loss: 2.7726, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 23123.9708, train_label_loss: 2.7727, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 23131.5516, train_label_loss: 2.7727, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 23095.4683, train_label_loss: 2.7725, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 23105.5179, train_label_loss: 2.7729, 
=============================================================
epoch: 3, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 4, [batch: 1 / 11375], examples_per_second: 16.7688, train_label_loss: 2.7725, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 23070.3712, train_label_loss: 2.7724, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 23074.8958, train_label_loss: 2.7726, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 23082.5304, train_label_loss: 2.7724, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 23096.0863, train_label_loss: 2.7729, 
=============================================================
epoch: 4, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 5, [batch: 1 / 11375], examples_per_second: 16.7536, train_label_loss: 2.7726, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 23072.5782, train_label_loss: 2.7725, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 23068.7644, train_label_loss: 2.7726, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 23060.3354, train_label_loss: 2.7723, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 23080.5917, train_label_loss: 2.7729, 
=============================================================
epoch: 5, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 16.7861, train_label_loss: 2.7727, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 23083.5229, train_label_loss: 2.7724, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 23089.9884, train_label_loss: 2.7723, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 23069.2300, train_label_loss: 2.7729, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 23064.4911, train_label_loss: 2.7722, 
=============================================================
epoch: 6, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 7, [batch: 1 / 11375], examples_per_second: 16.5766, train_label_loss: 2.7727, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 23086.5785, train_label_loss: 2.7729, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 23094.2043, train_label_loss: 2.7728, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 23076.7644, train_label_loss: 2.7726, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 23112.1077, train_label_loss: 2.7727, 
=============================================================
epoch: 7, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 16.7355, train_label_loss: 2.7723, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 23083.3392, train_label_loss: 2.7727, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 23110.6125, train_label_loss: 2.7725, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 23077.4642, train_label_loss: 2.7728, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 23074.4736, train_label_loss: 2.7723, 
=============================================================
epoch: 8, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 9, [batch: 1 / 11375], examples_per_second: 16.7061, train_label_loss: 2.7729, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 23056.0885, train_label_loss: 2.7725, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 23071.0992, train_label_loss: 2.7726, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 23065.4160, train_label_loss: 2.7724, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 23079.6115, train_label_loss: 2.7726, 
=============================================================
epoch: 9, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 16.7322, train_label_loss: 2.7725, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 23062.3605, train_label_loss: 2.7724, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 23103.6951, train_label_loss: 2.7723, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 23080.7882, train_label_loss: 2.7726, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 23098.9358, train_label_loss: 2.7726, 
=============================================================
epoch: 10, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 11, [batch: 1 / 11375], examples_per_second: 16.7564, train_label_loss: 2.7729, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 23084.4116, train_label_loss: 2.7728, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 23072.8599, train_label_loss: 2.7725, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 23070.3864, train_label_loss: 2.7725, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 23092.9800, train_label_loss: 2.7727, 
=============================================================
epoch: 11, val_acc_label: 0.0620, val_label_loss: 2.7726, 
=============================================================
epoch: 12, [batch: 1 / 11375], examples_per_second: 16.7761, train_label_loss: 2.7725, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 23116.2903, train_label_loss: 2.7724, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 23082.5696, train_label_loss: 2.7724, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 23079.5157, train_label_loss: 2.7730, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 23051.9306, train_label_loss: 2.7725, 
=============================================================
epoch: 12, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.062400641025641024 Target Test Label Accuracy: 0.062400641025641024
Source Val Label Accuracy: 0.0625801282051282 Target Val Label Accuracy: 0.0625801282051282
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
