[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1843.6818, train_label_loss: 2.7727, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 34836.6593, train_label_loss: 2.7725, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 34889.8975, train_label_loss: 2.7729, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 34924.6458, train_label_loss: 2.7729, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 34920.4155, train_label_loss: 2.7725, 
=============================================================
epoch: 1, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 22.6355, train_label_loss: 2.7725, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 34917.7896, train_label_loss: 2.7725, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 34946.5804, train_label_loss: 2.7727, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 34921.2108, train_label_loss: 2.7727, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 34821.2938, train_label_loss: 2.7728, 
=============================================================
epoch: 2, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 3, [batch: 1 / 11375], examples_per_second: 23.2843, train_label_loss: 2.7726, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 34757.1365, train_label_loss: 2.7727, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 34752.0235, train_label_loss: 2.7728, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 34737.2897, train_label_loss: 2.7726, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 34757.1002, train_label_loss: 2.7725, 
=============================================================
epoch: 3, val_acc_label: 0.0620, val_label_loss: 2.7726, 
=============================================================
epoch: 4, [batch: 1 / 11375], examples_per_second: 23.2058, train_label_loss: 2.7728, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 34746.9726, train_label_loss: 2.7730, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 34780.9611, train_label_loss: 2.7728, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 34766.1582, train_label_loss: 2.7726, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 34737.5268, train_label_loss: 2.7728, 
=============================================================
epoch: 4, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 5, [batch: 1 / 11375], examples_per_second: 23.1585, train_label_loss: 2.7726, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 34748.6816, train_label_loss: 2.7724, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 34766.9469, train_label_loss: 2.7725, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 34749.6387, train_label_loss: 2.7724, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 34656.7902, train_label_loss: 2.7727, 
=============================================================
epoch: 5, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 22.9079, train_label_loss: 2.7724, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 34719.9607, train_label_loss: 2.7726, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 34759.9471, train_label_loss: 2.7725, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 34709.2340, train_label_loss: 2.7726, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 34733.0247, train_label_loss: 2.7725, 
=============================================================
epoch: 6, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 7, [batch: 1 / 11375], examples_per_second: 23.2687, train_label_loss: 2.7729, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 34768.6470, train_label_loss: 2.7724, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 34769.3346, train_label_loss: 2.7720, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 34747.1583, train_label_loss: 2.7724, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 34726.3272, train_label_loss: 2.7725, 
=============================================================
epoch: 7, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 23.2066, train_label_loss: 2.7727, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 34720.1957, train_label_loss: 2.7727, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 34756.8876, train_label_loss: 2.7727, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 34726.8812, train_label_loss: 2.7726, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 34755.6048, train_label_loss: 2.7722, 
=============================================================
epoch: 8, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 9, [batch: 1 / 11375], examples_per_second: 23.1729, train_label_loss: 2.7729, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 34757.4190, train_label_loss: 2.7723, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 34737.3628, train_label_loss: 2.7725, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 34767.8307, train_label_loss: 2.7725, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 34749.5195, train_label_loss: 2.7726, 
=============================================================
epoch: 9, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 23.1681, train_label_loss: 2.7722, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 34715.9448, train_label_loss: 2.7728, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 34705.3831, train_label_loss: 2.7726, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 34734.4451, train_label_loss: 2.7725, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 34745.8233, train_label_loss: 2.7726, 
=============================================================
epoch: 10, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 11, [batch: 1 / 11375], examples_per_second: 23.1805, train_label_loss: 2.7729, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 34727.9181, train_label_loss: 2.7725, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 34752.5456, train_label_loss: 2.7722, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 34749.8077, train_label_loss: 2.7723, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 34745.4551, train_label_loss: 2.7724, 
=============================================================
epoch: 11, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 12, [batch: 1 / 11375], examples_per_second: 23.2542, train_label_loss: 2.7726, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 34712.2482, train_label_loss: 2.7727, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 34749.9120, train_label_loss: 2.7729, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 34736.3225, train_label_loss: 2.7724, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 34753.9799, train_label_loss: 2.7724, 
=============================================================
epoch: 12, val_acc_label: 0.0620, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.06236858974358974 Target Test Label Accuracy: 0.06236858974358974
Source Val Label Accuracy: 0.06268429487179487 Target Val Label Accuracy: 0.06268429487179487
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
