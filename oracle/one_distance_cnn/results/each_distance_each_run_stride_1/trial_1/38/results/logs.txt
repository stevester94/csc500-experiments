[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1748.4092, train_label_loss: 2.7726, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 34893.3268, train_label_loss: 2.7725, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 34977.2268, train_label_loss: 2.7725, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 34864.4921, train_label_loss: 2.7727, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 34870.2369, train_label_loss: 2.7728, 
=============================================================
epoch: 1, val_acc_label: 0.0619, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 22.4718, train_label_loss: 2.7723, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 34847.3005, train_label_loss: 2.7725, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 34869.3843, train_label_loss: 2.7723, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 34763.0670, train_label_loss: 2.7723, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 34703.2512, train_label_loss: 2.7728, 
=============================================================
epoch: 2, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 3, [batch: 1 / 11375], examples_per_second: 23.1088, train_label_loss: 2.7726, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 34679.7244, train_label_loss: 2.7728, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 34695.7748, train_label_loss: 2.7727, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 34676.5913, train_label_loss: 2.7728, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 34695.2041, train_label_loss: 2.7725, 
=============================================================
epoch: 3, val_acc_label: 0.0619, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 4, [batch: 1 / 11375], examples_per_second: 23.1968, train_label_loss: 2.7725, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 34683.0377, train_label_loss: 2.7726, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 34688.7153, train_label_loss: 2.7726, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 34699.7369, train_label_loss: 2.7726, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 34708.7314, train_label_loss: 2.7725, 
=============================================================
epoch: 4, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 5, [batch: 1 / 11375], examples_per_second: 23.2112, train_label_loss: 2.7724, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 34682.5268, train_label_loss: 2.7724, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 34692.7946, train_label_loss: 2.7725, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 34688.0021, train_label_loss: 2.7724, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 34711.0707, train_label_loss: 2.7724, 
=============================================================
epoch: 5, val_acc_label: 0.0619, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 23.0642, train_label_loss: 2.7727, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 34653.4878, train_label_loss: 2.7724, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 34648.3696, train_label_loss: 2.7727, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 34672.9534, train_label_loss: 2.7726, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 34673.1414, train_label_loss: 2.7725, 
=============================================================
epoch: 6, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 7, [batch: 1 / 11375], examples_per_second: 22.7476, train_label_loss: 2.7726, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 34680.4081, train_label_loss: 2.7726, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 34688.3277, train_label_loss: 2.7728, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 34711.9960, train_label_loss: 2.7727, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 34698.6993, train_label_loss: 2.7727, 
=============================================================
epoch: 7, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 23.0841, train_label_loss: 2.7728, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 34667.7416, train_label_loss: 2.7727, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 34701.7145, train_label_loss: 2.7728, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 34700.8031, train_label_loss: 2.7728, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 34667.8087, train_label_loss: 2.7725, 
=============================================================
epoch: 8, val_acc_label: 0.0628, val_label_loss: 2.7726, 
=============================================================
epoch: 9, [batch: 1 / 11375], examples_per_second: 23.1036, train_label_loss: 2.7726, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 34657.3657, train_label_loss: 2.7722, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 34673.2314, train_label_loss: 2.7725, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 34683.7723, train_label_loss: 2.7725, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 34711.0746, train_label_loss: 2.7725, 
=============================================================
epoch: 9, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 23.1781, train_label_loss: 2.7727, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 34667.8233, train_label_loss: 2.7726, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 34694.3955, train_label_loss: 2.7728, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 34689.1341, train_label_loss: 2.7723, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 34692.4369, train_label_loss: 2.7723, 
=============================================================
epoch: 10, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 11, [batch: 1 / 11375], examples_per_second: 23.1555, train_label_loss: 2.7727, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 34671.9206, train_label_loss: 2.7725, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 34694.0501, train_label_loss: 2.7727, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 34679.3959, train_label_loss: 2.7722, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 34711.7020, train_label_loss: 2.7728, 
=============================================================
epoch: 11, val_acc_label: 0.0629, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 12, [batch: 1 / 11375], examples_per_second: 23.1290, train_label_loss: 2.7726, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 34645.3270, train_label_loss: 2.7727, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 34685.4083, train_label_loss: 2.7727, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 34687.3425, train_label_loss: 2.7725, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 34678.8420, train_label_loss: 2.7722, 
=============================================================
epoch: 12, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 13, [batch: 1 / 11375], examples_per_second: 23.1471, train_label_loss: 2.7728, 
epoch: 13, [batch: 2275 / 11375], examples_per_second: 34667.5511, train_label_loss: 2.7731, 
epoch: 13, [batch: 4550 / 11375], examples_per_second: 34696.6283, train_label_loss: 2.7728, 
epoch: 13, [batch: 6825 / 11375], examples_per_second: 34690.8785, train_label_loss: 2.7726, 
epoch: 13, [batch: 9100 / 11375], examples_per_second: 34669.7020, train_label_loss: 2.7725, 
=============================================================
epoch: 13, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 14, [batch: 1 / 11375], examples_per_second: 23.1269, train_label_loss: 2.7724, 
epoch: 14, [batch: 2275 / 11375], examples_per_second: 34685.8781, train_label_loss: 2.7725, 
epoch: 14, [batch: 4550 / 11375], examples_per_second: 34674.8493, train_label_loss: 2.7725, 
epoch: 14, [batch: 6825 / 11375], examples_per_second: 34666.0090, train_label_loss: 2.7726, 
epoch: 14, [batch: 9100 / 11375], examples_per_second: 34677.3267, train_label_loss: 2.7727, 
=============================================================
epoch: 14, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 15, [batch: 1 / 11375], examples_per_second: 23.1101, train_label_loss: 2.7727, 
epoch: 15, [batch: 2275 / 11375], examples_per_second: 34657.3637, train_label_loss: 2.7724, 
epoch: 15, [batch: 4550 / 11375], examples_per_second: 34681.1295, train_label_loss: 2.7726, 
epoch: 15, [batch: 6825 / 11375], examples_per_second: 34684.5465, train_label_loss: 2.7727, 
epoch: 15, [batch: 9100 / 11375], examples_per_second: 34676.1527, train_label_loss: 2.7726, 
=============================================================
epoch: 15, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 16, [batch: 1 / 11375], examples_per_second: 23.0489, train_label_loss: 2.7728, 
epoch: 16, [batch: 2275 / 11375], examples_per_second: 34662.2724, train_label_loss: 2.7728, 
epoch: 16, [batch: 4550 / 11375], examples_per_second: 34670.2905, train_label_loss: 2.7727, 
epoch: 16, [batch: 6825 / 11375], examples_per_second: 34647.8884, train_label_loss: 2.7727, 
epoch: 16, [batch: 9100 / 11375], examples_per_second: 34656.8011, train_label_loss: 2.7725, 
=============================================================
epoch: 16, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 17, [batch: 1 / 11375], examples_per_second: 23.1260, train_label_loss: 2.7725, 
epoch: 17, [batch: 2275 / 11375], examples_per_second: 34684.5310, train_label_loss: 2.7727, 
epoch: 17, [batch: 4550 / 11375], examples_per_second: 34690.0228, train_label_loss: 2.7726, 
epoch: 17, [batch: 6825 / 11375], examples_per_second: 34668.0193, train_label_loss: 2.7729, 
epoch: 17, [batch: 9100 / 11375], examples_per_second: 34682.7963, train_label_loss: 2.7725, 
=============================================================
epoch: 17, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 18, [batch: 1 / 11375], examples_per_second: 23.1429, train_label_loss: 2.7726, 
epoch: 18, [batch: 2275 / 11375], examples_per_second: 34655.9893, train_label_loss: 2.7722, 
epoch: 18, [batch: 4550 / 11375], examples_per_second: 34676.2989, train_label_loss: 2.7726, 
epoch: 18, [batch: 6825 / 11375], examples_per_second: 34678.7554, train_label_loss: 2.7730, 
epoch: 18, [batch: 9100 / 11375], examples_per_second: 34673.5612, train_label_loss: 2.7729, 
=============================================================
epoch: 18, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 19, [batch: 1 / 11375], examples_per_second: 23.1456, train_label_loss: 2.7725, 
epoch: 19, [batch: 2275 / 11375], examples_per_second: 34691.2104, train_label_loss: 2.7727, 
epoch: 19, [batch: 4550 / 11375], examples_per_second: 34727.3502, train_label_loss: 2.7725, 
epoch: 19, [batch: 6825 / 11375], examples_per_second: 34664.7177, train_label_loss: 2.7725, 
epoch: 19, [batch: 9100 / 11375], examples_per_second: 34686.3668, train_label_loss: 2.7725, 
=============================================================
epoch: 19, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 20, [batch: 1 / 11375], examples_per_second: 23.0751, train_label_loss: 2.7725, 
epoch: 20, [batch: 2275 / 11375], examples_per_second: 34682.2111, train_label_loss: 2.7726, 
epoch: 20, [batch: 4550 / 11375], examples_per_second: 34703.7166, train_label_loss: 2.7725, 
epoch: 20, [batch: 6825 / 11375], examples_per_second: 34673.1985, train_label_loss: 2.7724, 
epoch: 20, [batch: 9100 / 11375], examples_per_second: 34685.9821, train_label_loss: 2.7726, 
=============================================================
epoch: 20, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 21, [batch: 1 / 11375], examples_per_second: 22.7497, train_label_loss: 2.7727, 
epoch: 21, [batch: 2275 / 11375], examples_per_second: 34677.5273, train_label_loss: 2.7730, 
epoch: 21, [batch: 4550 / 11375], examples_per_second: 34665.5540, train_label_loss: 2.7726, 
epoch: 21, [batch: 6825 / 11375], examples_per_second: 34659.0320, train_label_loss: 2.7726, 
epoch: 21, [batch: 9100 / 11375], examples_per_second: 34661.8830, train_label_loss: 2.7726, 
=============================================================
epoch: 21, val_acc_label: 0.0619, val_label_loss: 2.7726, 
=============================================================
epoch: 22, [batch: 1 / 11375], examples_per_second: 23.1962, train_label_loss: 2.7726, 
epoch: 22, [batch: 2275 / 11375], examples_per_second: 34671.7610, train_label_loss: 2.7727, 
epoch: 22, [batch: 4550 / 11375], examples_per_second: 34635.4638, train_label_loss: 2.7724, 
epoch: 22, [batch: 6825 / 11375], examples_per_second: 34667.8515, train_label_loss: 2.7724, 
epoch: 22, [batch: 9100 / 11375], examples_per_second: 34680.4209, train_label_loss: 2.7730, 
=============================================================
epoch: 22, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.06253205128205128 Target Test Label Accuracy: 0.06253205128205128
Source Val Label Accuracy: 0.06289262820512821 Target Val Label Accuracy: 0.06289262820512821
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
