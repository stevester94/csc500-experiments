[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1351.5749, train_label_loss: 2.7725, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 34934.5143, train_label_loss: 2.7725, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 34949.2428, train_label_loss: 2.7724, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 34850.8606, train_label_loss: 2.7728, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 34849.0995, train_label_loss: 2.7724, 
=============================================================
epoch: 1, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 22.4067, train_label_loss: 2.7725, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 34828.2098, train_label_loss: 2.7730, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 34717.1973, train_label_loss: 2.7728, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 34680.9729, train_label_loss: 2.7725, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 34664.0354, train_label_loss: 2.7728, 
=============================================================
epoch: 2, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 3, [batch: 1 / 11375], examples_per_second: 23.1584, train_label_loss: 2.7729, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 34669.4472, train_label_loss: 2.7725, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 34695.4387, train_label_loss: 2.7726, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 34678.7042, train_label_loss: 2.7725, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 34698.8866, train_label_loss: 2.7728, 
=============================================================
epoch: 3, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 4, [batch: 1 / 11375], examples_per_second: 23.1298, train_label_loss: 2.7724, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 34677.7937, train_label_loss: 2.7727, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 34687.4228, train_label_loss: 2.7725, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 34682.5737, train_label_loss: 2.7727, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 34670.4514, train_label_loss: 2.7725, 
=============================================================
epoch: 4, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 5, [batch: 1 / 11375], examples_per_second: 23.1400, train_label_loss: 2.7727, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 34686.6591, train_label_loss: 2.7725, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 34673.5843, train_label_loss: 2.7728, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 34677.3882, train_label_loss: 2.7728, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 34671.2944, train_label_loss: 2.7730, 
=============================================================
epoch: 5, val_acc_label: 0.0628, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 23.1166, train_label_loss: 2.7725, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 34657.1011, train_label_loss: 2.7724, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 34659.8626, train_label_loss: 2.7723, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 34674.8015, train_label_loss: 2.7726, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 34649.7324, train_label_loss: 2.7728, 
=============================================================
epoch: 6, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 7, [batch: 1 / 11375], examples_per_second: 22.7537, train_label_loss: 2.7723, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 34664.6852, train_label_loss: 2.7722, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 34681.4549, train_label_loss: 2.7725, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 34645.8107, train_label_loss: 2.7726, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 34670.5828, train_label_loss: 2.7726, 
=============================================================
epoch: 7, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 23.1217, train_label_loss: 2.7727, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 34658.4844, train_label_loss: 2.7725, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 34658.3313, train_label_loss: 2.7725, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 34651.3126, train_label_loss: 2.7728, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 34692.8823, train_label_loss: 2.7723, 
=============================================================
epoch: 8, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 9, [batch: 1 / 11375], examples_per_second: 23.1318, train_label_loss: 2.7728, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 34683.1924, train_label_loss: 2.7729, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 34698.6909, train_label_loss: 2.7726, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 34672.8180, train_label_loss: 2.7727, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 34678.9395, train_label_loss: 2.7726, 
=============================================================
epoch: 9, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 23.2007, train_label_loss: 2.7726, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 34651.4238, train_label_loss: 2.7725, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 34679.1325, train_label_loss: 2.7730, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 34684.4371, train_label_loss: 2.7726, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 34652.2997, train_label_loss: 2.7727, 
=============================================================
epoch: 10, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 11, [batch: 1 / 11375], examples_per_second: 23.0971, train_label_loss: 2.7727, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 34665.0395, train_label_loss: 2.7725, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 34677.6496, train_label_loss: 2.7728, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 34687.7799, train_label_loss: 2.7724, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 34651.7649, train_label_loss: 2.7725, 
=============================================================
epoch: 11, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 12, [batch: 1 / 11375], examples_per_second: 23.0842, train_label_loss: 2.7728, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 34643.6139, train_label_loss: 2.7726, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 34652.7854, train_label_loss: 2.7726, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 34670.2153, train_label_loss: 2.7727, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 34675.8928, train_label_loss: 2.7723, 
=============================================================
epoch: 12, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 13, [batch: 1 / 11375], examples_per_second: 23.2966, train_label_loss: 2.7726, 
epoch: 13, [batch: 2275 / 11375], examples_per_second: 34682.2017, train_label_loss: 2.7724, 
epoch: 13, [batch: 4550 / 11375], examples_per_second: 34669.6351, train_label_loss: 2.7726, 
epoch: 13, [batch: 6825 / 11375], examples_per_second: 34674.2507, train_label_loss: 2.7723, 
epoch: 13, [batch: 9100 / 11375], examples_per_second: 34667.0544, train_label_loss: 2.7726, 
=============================================================
epoch: 13, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 14, [batch: 1 / 11375], examples_per_second: 23.1012, train_label_loss: 2.7728, 
epoch: 14, [batch: 2275 / 11375], examples_per_second: 34660.8445, train_label_loss: 2.7725, 
epoch: 14, [batch: 4550 / 11375], examples_per_second: 34679.3314, train_label_loss: 2.7727, 
epoch: 14, [batch: 6825 / 11375], examples_per_second: 34664.2887, train_label_loss: 2.7727, 
epoch: 14, [batch: 9100 / 11375], examples_per_second: 34682.6653, train_label_loss: 2.7727, 
=============================================================
epoch: 14, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 15, [batch: 1 / 11375], examples_per_second: 23.1335, train_label_loss: 2.7723, 
epoch: 15, [batch: 2275 / 11375], examples_per_second: 34672.1987, train_label_loss: 2.7724, 
epoch: 15, [batch: 4550 / 11375], examples_per_second: 34669.5613, train_label_loss: 2.7729, 
epoch: 15, [batch: 6825 / 11375], examples_per_second: 34690.7972, train_label_loss: 2.7725, 
epoch: 15, [batch: 9100 / 11375], examples_per_second: 34678.7391, train_label_loss: 2.7724, 
=============================================================
epoch: 15, val_acc_label: 0.0628, val_label_loss: 2.7726, 
=============================================================
epoch: 16, [batch: 1 / 11375], examples_per_second: 23.1666, train_label_loss: 2.7726, 
epoch: 16, [batch: 2275 / 11375], examples_per_second: 34682.6032, train_label_loss: 2.7727, 
epoch: 16, [batch: 4550 / 11375], examples_per_second: 34657.9541, train_label_loss: 2.7726, 
epoch: 16, [batch: 6825 / 11375], examples_per_second: 34666.2058, train_label_loss: 2.7725, 
epoch: 16, [batch: 9100 / 11375], examples_per_second: 34666.7780, train_label_loss: 2.7724, 
=============================================================
epoch: 16, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 17, [batch: 1 / 11375], examples_per_second: 23.2292, train_label_loss: 2.7726, 
epoch: 17, [batch: 2275 / 11375], examples_per_second: 34640.1824, train_label_loss: 2.7730, 
epoch: 17, [batch: 4550 / 11375], examples_per_second: 34675.4562, train_label_loss: 2.7719, 
epoch: 17, [batch: 6825 / 11375], examples_per_second: 34666.0385, train_label_loss: 2.7723, 
epoch: 17, [batch: 9100 / 11375], examples_per_second: 34653.6628, train_label_loss: 2.7727, 
=============================================================
epoch: 17, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 18, [batch: 1 / 11375], examples_per_second: 23.1385, train_label_loss: 2.7726, 
epoch: 18, [batch: 2275 / 11375], examples_per_second: 34653.6324, train_label_loss: 2.7725, 
epoch: 18, [batch: 4550 / 11375], examples_per_second: 34675.2548, train_label_loss: 2.7724, 
epoch: 18, [batch: 6825 / 11375], examples_per_second: 34667.9956, train_label_loss: 2.7726, 
epoch: 18, [batch: 9100 / 11375], examples_per_second: 34651.7673, train_label_loss: 2.7725, 
=============================================================
epoch: 18, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 19, [batch: 1 / 11375], examples_per_second: 22.7690, train_label_loss: 2.7726, 
epoch: 19, [batch: 2275 / 11375], examples_per_second: 34682.9678, train_label_loss: 2.7724, 
epoch: 19, [batch: 4550 / 11375], examples_per_second: 34660.3205, train_label_loss: 2.7727, 
epoch: 19, [batch: 6825 / 11375], examples_per_second: 34687.3755, train_label_loss: 2.7726, 
epoch: 19, [batch: 9100 / 11375], examples_per_second: 34695.6723, train_label_loss: 2.7729, 
=============================================================
epoch: 19, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 20, [batch: 1 / 11375], examples_per_second: 23.1570, train_label_loss: 2.7727, 
epoch: 20, [batch: 2275 / 11375], examples_per_second: 34670.3038, train_label_loss: 2.7725, 
epoch: 20, [batch: 4550 / 11375], examples_per_second: 34660.2315, train_label_loss: 2.7726, 
epoch: 20, [batch: 6825 / 11375], examples_per_second: 34697.1502, train_label_loss: 2.7728, 
epoch: 20, [batch: 9100 / 11375], examples_per_second: 34670.3762, train_label_loss: 2.7725, 
=============================================================
epoch: 20, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 21, [batch: 1 / 11375], examples_per_second: 23.1098, train_label_loss: 2.7726, 
epoch: 21, [batch: 2275 / 11375], examples_per_second: 34631.7498, train_label_loss: 2.7724, 
epoch: 21, [batch: 4550 / 11375], examples_per_second: 34672.0252, train_label_loss: 2.7730, 
epoch: 21, [batch: 6825 / 11375], examples_per_second: 34689.4045, train_label_loss: 2.7725, 
epoch: 21, [batch: 9100 / 11375], examples_per_second: 34683.8624, train_label_loss: 2.7726, 
=============================================================
epoch: 21, val_acc_label: 0.0628, val_label_loss: 2.7726, 
=============================================================
epoch: 22, [batch: 1 / 11375], examples_per_second: 23.1474, train_label_loss: 2.7724, 
epoch: 22, [batch: 2275 / 11375], examples_per_second: 34654.7725, train_label_loss: 2.7724, 
epoch: 22, [batch: 4550 / 11375], examples_per_second: 34685.8496, train_label_loss: 2.7728, 
epoch: 22, [batch: 6825 / 11375], examples_per_second: 34649.0473, train_label_loss: 2.7726, 
epoch: 22, [batch: 9100 / 11375], examples_per_second: 34665.7635, train_label_loss: 2.7724, 
=============================================================
epoch: 22, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 23, [batch: 1 / 11375], examples_per_second: 23.1451, train_label_loss: 2.7728, 
epoch: 23, [batch: 2275 / 11375], examples_per_second: 34646.1239, train_label_loss: 2.7725, 
epoch: 23, [batch: 4550 / 11375], examples_per_second: 34682.3137, train_label_loss: 2.7728, 
epoch: 23, [batch: 6825 / 11375], examples_per_second: 34666.4660, train_label_loss: 2.7728, 
epoch: 23, [batch: 9100 / 11375], examples_per_second: 34662.4702, train_label_loss: 2.7723, 
=============================================================
epoch: 23, val_acc_label: 0.0631, val_label_loss: 2.7726, 
=============================================================
epoch: 24, [batch: 1 / 11375], examples_per_second: 23.1472, train_label_loss: 2.7725, 
epoch: 24, [batch: 2275 / 11375], examples_per_second: 34642.6250, train_label_loss: 2.7725, 
epoch: 24, [batch: 4550 / 11375], examples_per_second: 34672.4248, train_label_loss: 2.7725, 
epoch: 24, [batch: 6825 / 11375], examples_per_second: 34654.1702, train_label_loss: 2.7725, 
epoch: 24, [batch: 9100 / 11375], examples_per_second: 34658.1631, train_label_loss: 2.7727, 
=============================================================
epoch: 24, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 25, [batch: 1 / 11375], examples_per_second: 23.1660, train_label_loss: 2.7725, 
epoch: 25, [batch: 2275 / 11375], examples_per_second: 34652.9483, train_label_loss: 2.7726, 
epoch: 25, [batch: 4550 / 11375], examples_per_second: 34635.0042, train_label_loss: 2.7727, 
epoch: 25, [batch: 6825 / 11375], examples_per_second: 34680.8729, train_label_loss: 2.7728, 
epoch: 25, [batch: 9100 / 11375], examples_per_second: 34680.2018, train_label_loss: 2.7725, 
=============================================================
epoch: 25, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 26, [batch: 1 / 11375], examples_per_second: 23.1384, train_label_loss: 2.7726, 
epoch: 26, [batch: 2275 / 11375], examples_per_second: 34654.1749, train_label_loss: 2.7727, 
epoch: 26, [batch: 4550 / 11375], examples_per_second: 34658.4291, train_label_loss: 2.7725, 
epoch: 26, [batch: 6825 / 11375], examples_per_second: 34676.0665, train_label_loss: 2.7726, 
epoch: 26, [batch: 9100 / 11375], examples_per_second: 34657.6399, train_label_loss: 2.7725, 
=============================================================
epoch: 26, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 27, [batch: 1 / 11375], examples_per_second: 23.1954, train_label_loss: 2.7726, 
epoch: 27, [batch: 2275 / 11375], examples_per_second: 34660.3003, train_label_loss: 2.7725, 
epoch: 27, [batch: 4550 / 11375], examples_per_second: 34661.2692, train_label_loss: 2.7725, 
epoch: 27, [batch: 6825 / 11375], examples_per_second: 34623.0933, train_label_loss: 2.7725, 
epoch: 27, [batch: 9100 / 11375], examples_per_second: 34663.7348, train_label_loss: 2.7724, 
=============================================================
epoch: 27, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 28, [batch: 1 / 11375], examples_per_second: 23.1727, train_label_loss: 2.7727, 
epoch: 28, [batch: 2275 / 11375], examples_per_second: 34653.0963, train_label_loss: 2.7720, 
epoch: 28, [batch: 4550 / 11375], examples_per_second: 34649.3648, train_label_loss: 2.7731, 
epoch: 28, [batch: 6825 / 11375], examples_per_second: 34671.1266, train_label_loss: 2.7724, 
epoch: 28, [batch: 9100 / 11375], examples_per_second: 34651.5461, train_label_loss: 2.7727, 
=============================================================
epoch: 28, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.06226442307692308 Target Test Label Accuracy: 0.06226442307692308
Source Val Label Accuracy: 0.06252564102564102 Target Val Label Accuracy: 0.06252564102564102
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
