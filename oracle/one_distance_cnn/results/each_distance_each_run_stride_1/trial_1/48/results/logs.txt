[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1428.3088, train_label_loss: 2.7725, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 34978.4522, train_label_loss: 2.7725, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 35023.0425, train_label_loss: 2.7724, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 34927.0242, train_label_loss: 2.7728, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 34944.5897, train_label_loss: 2.7724, 
=============================================================
epoch: 1, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 22.5446, train_label_loss: 2.7725, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 34931.0528, train_label_loss: 2.7730, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 34884.3484, train_label_loss: 2.7728, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 34755.8778, train_label_loss: 2.7725, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 34726.1949, train_label_loss: 2.7728, 
=============================================================
epoch: 2, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 3, [batch: 1 / 11375], examples_per_second: 23.0666, train_label_loss: 2.7729, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 34726.0091, train_label_loss: 2.7725, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 34739.4179, train_label_loss: 2.7726, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 34737.7669, train_label_loss: 2.7725, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 34765.5580, train_label_loss: 2.7728, 
=============================================================
epoch: 3, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 4, [batch: 1 / 11375], examples_per_second: 23.1498, train_label_loss: 2.7724, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 34729.6301, train_label_loss: 2.7727, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 34771.1856, train_label_loss: 2.7725, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 34754.8062, train_label_loss: 2.7727, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 34737.7664, train_label_loss: 2.7725, 
=============================================================
epoch: 4, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 5, [batch: 1 / 11375], examples_per_second: 23.1598, train_label_loss: 2.7727, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 34750.0722, train_label_loss: 2.7725, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 34750.9551, train_label_loss: 2.7728, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 34730.1827, train_label_loss: 2.7728, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 34744.0823, train_label_loss: 2.7730, 
=============================================================
epoch: 5, val_acc_label: 0.0628, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 23.2488, train_label_loss: 2.7725, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 34744.4153, train_label_loss: 2.7724, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 34721.7491, train_label_loss: 2.7723, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 34723.3309, train_label_loss: 2.7726, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 34755.3640, train_label_loss: 2.7728, 
=============================================================
epoch: 6, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 7, [batch: 1 / 11375], examples_per_second: 22.8562, train_label_loss: 2.7723, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 34735.0386, train_label_loss: 2.7722, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 34748.9960, train_label_loss: 2.7725, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 34738.0499, train_label_loss: 2.7726, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 34752.5115, train_label_loss: 2.7726, 
=============================================================
epoch: 7, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 23.1676, train_label_loss: 2.7727, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 34756.5571, train_label_loss: 2.7725, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 34760.2617, train_label_loss: 2.7725, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 34735.6769, train_label_loss: 2.7728, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 34746.2414, train_label_loss: 2.7723, 
=============================================================
epoch: 8, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 9, [batch: 1 / 11375], examples_per_second: 23.1378, train_label_loss: 2.7728, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 34718.9461, train_label_loss: 2.7729, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 34748.4671, train_label_loss: 2.7726, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 34768.9828, train_label_loss: 2.7727, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 34760.2315, train_label_loss: 2.7726, 
=============================================================
epoch: 9, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 23.2294, train_label_loss: 2.7726, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 34749.9436, train_label_loss: 2.7725, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 34756.7620, train_label_loss: 2.7730, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 34721.6242, train_label_loss: 2.7726, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 34749.5349, train_label_loss: 2.7727, 
=============================================================
epoch: 10, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 11, [batch: 1 / 11375], examples_per_second: 23.1494, train_label_loss: 2.7727, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 34756.9010, train_label_loss: 2.7725, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 34755.1301, train_label_loss: 2.7728, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 34737.3430, train_label_loss: 2.7724, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 34761.8446, train_label_loss: 2.7725, 
=============================================================
epoch: 11, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 12, [batch: 1 / 11375], examples_per_second: 23.1899, train_label_loss: 2.7728, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 34749.2943, train_label_loss: 2.7726, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 34775.0189, train_label_loss: 2.7726, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 34755.2013, train_label_loss: 2.7727, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 34748.4874, train_label_loss: 2.7723, 
=============================================================
epoch: 12, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 13, [batch: 1 / 11375], examples_per_second: 23.1654, train_label_loss: 2.7726, 
epoch: 13, [batch: 2275 / 11375], examples_per_second: 34741.9598, train_label_loss: 2.7724, 
epoch: 13, [batch: 4550 / 11375], examples_per_second: 34749.3104, train_label_loss: 2.7726, 
epoch: 13, [batch: 6825 / 11375], examples_per_second: 34757.8144, train_label_loss: 2.7723, 
epoch: 13, [batch: 9100 / 11375], examples_per_second: 34742.4145, train_label_loss: 2.7726, 
=============================================================
epoch: 13, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 14, [batch: 1 / 11375], examples_per_second: 23.1423, train_label_loss: 2.7728, 
epoch: 14, [batch: 2275 / 11375], examples_per_second: 34751.1232, train_label_loss: 2.7725, 
epoch: 14, [batch: 4550 / 11375], examples_per_second: 34769.4257, train_label_loss: 2.7727, 
epoch: 14, [batch: 6825 / 11375], examples_per_second: 34765.5046, train_label_loss: 2.7727, 
epoch: 14, [batch: 9100 / 11375], examples_per_second: 34723.3531, train_label_loss: 2.7727, 
=============================================================
epoch: 14, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 15, [batch: 1 / 11375], examples_per_second: 23.1561, train_label_loss: 2.7723, 
epoch: 15, [batch: 2275 / 11375], examples_per_second: 34733.2222, train_label_loss: 2.7724, 
epoch: 15, [batch: 4550 / 11375], examples_per_second: 34754.5031, train_label_loss: 2.7729, 
epoch: 15, [batch: 6825 / 11375], examples_per_second: 34753.8286, train_label_loss: 2.7725, 
epoch: 15, [batch: 9100 / 11375], examples_per_second: 34762.8864, train_label_loss: 2.7724, 
=============================================================
epoch: 15, val_acc_label: 0.0628, val_label_loss: 2.7726, 
=============================================================
epoch: 16, [batch: 1 / 11375], examples_per_second: 23.2132, train_label_loss: 2.7726, 
epoch: 16, [batch: 2275 / 11375], examples_per_second: 34756.1836, train_label_loss: 2.7727, 
epoch: 16, [batch: 4550 / 11375], examples_per_second: 34746.4139, train_label_loss: 2.7726, 
epoch: 16, [batch: 6825 / 11375], examples_per_second: 34771.8113, train_label_loss: 2.7725, 
epoch: 16, [batch: 9100 / 11375], examples_per_second: 34758.5093, train_label_loss: 2.7724, 
=============================================================
epoch: 16, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 17, [batch: 1 / 11375], examples_per_second: 23.1909, train_label_loss: 2.7726, 
epoch: 17, [batch: 2275 / 11375], examples_per_second: 34738.5379, train_label_loss: 2.7730, 
epoch: 17, [batch: 4550 / 11375], examples_per_second: 34762.2591, train_label_loss: 2.7719, 
epoch: 17, [batch: 6825 / 11375], examples_per_second: 34746.3423, train_label_loss: 2.7723, 
epoch: 17, [batch: 9100 / 11375], examples_per_second: 34753.2037, train_label_loss: 2.7727, 
=============================================================
epoch: 17, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 18, [batch: 1 / 11375], examples_per_second: 23.1424, train_label_loss: 2.7726, 
epoch: 18, [batch: 2275 / 11375], examples_per_second: 34742.4018, train_label_loss: 2.7725, 
epoch: 18, [batch: 4550 / 11375], examples_per_second: 34749.9966, train_label_loss: 2.7724, 
epoch: 18, [batch: 6825 / 11375], examples_per_second: 34744.4850, train_label_loss: 2.7726, 
epoch: 18, [batch: 9100 / 11375], examples_per_second: 34750.0356, train_label_loss: 2.7725, 
=============================================================
epoch: 18, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 19, [batch: 1 / 11375], examples_per_second: 22.7279, train_label_loss: 2.7726, 
epoch: 19, [batch: 2275 / 11375], examples_per_second: 34746.3817, train_label_loss: 2.7724, 
epoch: 19, [batch: 4550 / 11375], examples_per_second: 34727.8389, train_label_loss: 2.7727, 
epoch: 19, [batch: 6825 / 11375], examples_per_second: 34748.7860, train_label_loss: 2.7726, 
epoch: 19, [batch: 9100 / 11375], examples_per_second: 34749.3618, train_label_loss: 2.7729, 
=============================================================
epoch: 19, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 20, [batch: 1 / 11375], examples_per_second: 23.0761, train_label_loss: 2.7727, 
epoch: 20, [batch: 2275 / 11375], examples_per_second: 34748.3344, train_label_loss: 2.7725, 
epoch: 20, [batch: 4550 / 11375], examples_per_second: 34776.1328, train_label_loss: 2.7726, 
epoch: 20, [batch: 6825 / 11375], examples_per_second: 34760.7692, train_label_loss: 2.7728, 
epoch: 20, [batch: 9100 / 11375], examples_per_second: 34767.3616, train_label_loss: 2.7725, 
=============================================================
epoch: 20, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 21, [batch: 1 / 11375], examples_per_second: 23.1482, train_label_loss: 2.7726, 
epoch: 21, [batch: 2275 / 11375], examples_per_second: 34743.6480, train_label_loss: 2.7724, 
epoch: 21, [batch: 4550 / 11375], examples_per_second: 34713.3471, train_label_loss: 2.7730, 
epoch: 21, [batch: 6825 / 11375], examples_per_second: 34733.4237, train_label_loss: 2.7725, 
epoch: 21, [batch: 9100 / 11375], examples_per_second: 34756.7021, train_label_loss: 2.7726, 
=============================================================
epoch: 21, val_acc_label: 0.0628, val_label_loss: 2.7726, 
=============================================================
epoch: 22, [batch: 1 / 11375], examples_per_second: 23.1304, train_label_loss: 2.7724, 
epoch: 22, [batch: 2275 / 11375], examples_per_second: 34753.5102, train_label_loss: 2.7724, 
epoch: 22, [batch: 4550 / 11375], examples_per_second: 34735.5539, train_label_loss: 2.7728, 
epoch: 22, [batch: 6825 / 11375], examples_per_second: 34749.7178, train_label_loss: 2.7726, 
epoch: 22, [batch: 9100 / 11375], examples_per_second: 34764.7214, train_label_loss: 2.7724, 
=============================================================
epoch: 22, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 23, [batch: 1 / 11375], examples_per_second: 23.2528, train_label_loss: 2.7728, 
epoch: 23, [batch: 2275 / 11375], examples_per_second: 34743.2723, train_label_loss: 2.7725, 
epoch: 23, [batch: 4550 / 11375], examples_per_second: 34747.7638, train_label_loss: 2.7728, 
epoch: 23, [batch: 6825 / 11375], examples_per_second: 34781.5910, train_label_loss: 2.7728, 
epoch: 23, [batch: 9100 / 11375], examples_per_second: 34771.5648, train_label_loss: 2.7723, 
=============================================================
epoch: 23, val_acc_label: 0.0631, val_label_loss: 2.7726, 
=============================================================
epoch: 24, [batch: 1 / 11375], examples_per_second: 23.0822, train_label_loss: 2.7725, 
epoch: 24, [batch: 2275 / 11375], examples_per_second: 34755.9892, train_label_loss: 2.7725, 
epoch: 24, [batch: 4550 / 11375], examples_per_second: 34742.5553, train_label_loss: 2.7725, 
epoch: 24, [batch: 6825 / 11375], examples_per_second: 34750.7233, train_label_loss: 2.7725, 
epoch: 24, [batch: 9100 / 11375], examples_per_second: 34744.0462, train_label_loss: 2.7727, 
=============================================================
epoch: 24, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 25, [batch: 1 / 11375], examples_per_second: 23.1443, train_label_loss: 2.7725, 
epoch: 25, [batch: 2275 / 11375], examples_per_second: 34747.8537, train_label_loss: 2.7726, 
epoch: 25, [batch: 4550 / 11375], examples_per_second: 34769.6430, train_label_loss: 2.7727, 
epoch: 25, [batch: 6825 / 11375], examples_per_second: 34737.6710, train_label_loss: 2.7728, 
epoch: 25, [batch: 9100 / 11375], examples_per_second: 34734.0174, train_label_loss: 2.7725, 
=============================================================
epoch: 25, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 26, [batch: 1 / 11375], examples_per_second: 23.2406, train_label_loss: 2.7726, 
epoch: 26, [batch: 2275 / 11375], examples_per_second: 34744.8336, train_label_loss: 2.7727, 
epoch: 26, [batch: 4550 / 11375], examples_per_second: 34707.2451, train_label_loss: 2.7725, 
epoch: 26, [batch: 6825 / 11375], examples_per_second: 34739.8413, train_label_loss: 2.7726, 
epoch: 26, [batch: 9100 / 11375], examples_per_second: 34767.9787, train_label_loss: 2.7725, 
=============================================================
epoch: 26, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 27, [batch: 1 / 11375], examples_per_second: 23.1574, train_label_loss: 2.7726, 
epoch: 27, [batch: 2275 / 11375], examples_per_second: 34743.2125, train_label_loss: 2.7725, 
epoch: 27, [batch: 4550 / 11375], examples_per_second: 34753.0637, train_label_loss: 2.7725, 
epoch: 27, [batch: 6825 / 11375], examples_per_second: 34745.2481, train_label_loss: 2.7725, 
epoch: 27, [batch: 9100 / 11375], examples_per_second: 34736.7458, train_label_loss: 2.7724, 
=============================================================
epoch: 27, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 28, [batch: 1 / 11375], examples_per_second: 23.2303, train_label_loss: 2.7727, 
epoch: 28, [batch: 2275 / 11375], examples_per_second: 34737.4121, train_label_loss: 2.7720, 
epoch: 28, [batch: 4550 / 11375], examples_per_second: 34727.3921, train_label_loss: 2.7731, 
epoch: 28, [batch: 6825 / 11375], examples_per_second: 34747.1064, train_label_loss: 2.7724, 
epoch: 28, [batch: 9100 / 11375], examples_per_second: 34762.8983, train_label_loss: 2.7727, 
=============================================================
epoch: 28, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.06226442307692308 Target Test Label Accuracy: 0.06226442307692308
Source Val Label Accuracy: 0.06252564102564102 Target Val Label Accuracy: 0.06252564102564102
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
