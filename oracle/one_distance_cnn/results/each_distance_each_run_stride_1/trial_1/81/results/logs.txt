[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1875.5037, train_label_loss: 2.7726, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 34833.3712, train_label_loss: 2.7725, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 34907.3617, train_label_loss: 2.7725, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 34938.7574, train_label_loss: 2.7727, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 34956.9335, train_label_loss: 2.7727, 
=============================================================
epoch: 1, val_acc_label: 0.0619, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 22.5270, train_label_loss: 2.7724, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 34947.6747, train_label_loss: 2.7725, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 34928.0590, train_label_loss: 2.7723, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 34949.1013, train_label_loss: 2.7723, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 34829.8822, train_label_loss: 2.7728, 
=============================================================
epoch: 2, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 3, [batch: 1 / 11375], examples_per_second: 23.2275, train_label_loss: 2.7726, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 34783.8460, train_label_loss: 2.7728, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 34771.2431, train_label_loss: 2.7727, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 34794.7586, train_label_loss: 2.7728, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 34755.9129, train_label_loss: 2.7725, 
=============================================================
epoch: 3, val_acc_label: 0.0619, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 4, [batch: 1 / 11375], examples_per_second: 23.1360, train_label_loss: 2.7725, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 34782.5632, train_label_loss: 2.7726, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 34760.3730, train_label_loss: 2.7726, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 34748.5759, train_label_loss: 2.7726, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 34745.6523, train_label_loss: 2.7725, 
=============================================================
epoch: 4, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 5, [batch: 1 / 11375], examples_per_second: 23.1219, train_label_loss: 2.7724, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 34735.5307, train_label_loss: 2.7724, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 34752.0517, train_label_loss: 2.7725, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 34785.2770, train_label_loss: 2.7724, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 34761.7347, train_label_loss: 2.7724, 
=============================================================
epoch: 5, val_acc_label: 0.0619, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 23.1928, train_label_loss: 2.7727, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 34758.2859, train_label_loss: 2.7724, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 34734.2954, train_label_loss: 2.7727, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 34787.2382, train_label_loss: 2.7726, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 34772.8359, train_label_loss: 2.7725, 
=============================================================
epoch: 6, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 7, [batch: 1 / 11375], examples_per_second: 22.8487, train_label_loss: 2.7726, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 34731.0104, train_label_loss: 2.7726, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 34774.8882, train_label_loss: 2.7728, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 34752.3765, train_label_loss: 2.7727, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 34748.0880, train_label_loss: 2.7727, 
=============================================================
epoch: 7, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 23.1863, train_label_loss: 2.7728, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 34746.6615, train_label_loss: 2.7727, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 34755.5563, train_label_loss: 2.7728, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 34765.9989, train_label_loss: 2.7728, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 34775.9472, train_label_loss: 2.7725, 
=============================================================
epoch: 8, val_acc_label: 0.0628, val_label_loss: 2.7726, 
=============================================================
epoch: 9, [batch: 1 / 11375], examples_per_second: 23.2054, train_label_loss: 2.7726, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 34738.5166, train_label_loss: 2.7722, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 34744.9649, train_label_loss: 2.7725, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 34762.5965, train_label_loss: 2.7725, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 34755.4634, train_label_loss: 2.7725, 
=============================================================
epoch: 9, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 23.2567, train_label_loss: 2.7727, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 34766.9663, train_label_loss: 2.7726, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 34769.5959, train_label_loss: 2.7728, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 34780.9007, train_label_loss: 2.7723, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 34800.8205, train_label_loss: 2.7723, 
=============================================================
epoch: 10, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 11, [batch: 1 / 11375], examples_per_second: 23.1936, train_label_loss: 2.7727, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 34762.8554, train_label_loss: 2.7725, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 34768.9278, train_label_loss: 2.7727, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 34777.7202, train_label_loss: 2.7722, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 34757.4133, train_label_loss: 2.7728, 
=============================================================
epoch: 11, val_acc_label: 0.0629, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 12, [batch: 1 / 11375], examples_per_second: 23.1813, train_label_loss: 2.7726, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 34775.1542, train_label_loss: 2.7727, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 34731.9313, train_label_loss: 2.7727, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 34739.4302, train_label_loss: 2.7725, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 34761.3905, train_label_loss: 2.7722, 
=============================================================
epoch: 12, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 13, [batch: 1 / 11375], examples_per_second: 23.1650, train_label_loss: 2.7728, 
epoch: 13, [batch: 2275 / 11375], examples_per_second: 34738.8685, train_label_loss: 2.7731, 
epoch: 13, [batch: 4550 / 11375], examples_per_second: 34763.6176, train_label_loss: 2.7728, 
epoch: 13, [batch: 6825 / 11375], examples_per_second: 34752.5115, train_label_loss: 2.7726, 
epoch: 13, [batch: 9100 / 11375], examples_per_second: 34777.3577, train_label_loss: 2.7725, 
=============================================================
epoch: 13, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 14, [batch: 1 / 11375], examples_per_second: 23.1608, train_label_loss: 2.7724, 
epoch: 14, [batch: 2275 / 11375], examples_per_second: 34773.7606, train_label_loss: 2.7725, 
epoch: 14, [batch: 4550 / 11375], examples_per_second: 34733.7186, train_label_loss: 2.7725, 
epoch: 14, [batch: 6825 / 11375], examples_per_second: 34760.3917, train_label_loss: 2.7726, 
epoch: 14, [batch: 9100 / 11375], examples_per_second: 34755.2898, train_label_loss: 2.7727, 
=============================================================
epoch: 14, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 15, [batch: 1 / 11375], examples_per_second: 23.1633, train_label_loss: 2.7727, 
epoch: 15, [batch: 2275 / 11375], examples_per_second: 34734.1161, train_label_loss: 2.7724, 
epoch: 15, [batch: 4550 / 11375], examples_per_second: 34752.7518, train_label_loss: 2.7726, 
epoch: 15, [batch: 6825 / 11375], examples_per_second: 34766.6941, train_label_loss: 2.7727, 
epoch: 15, [batch: 9100 / 11375], examples_per_second: 34734.5360, train_label_loss: 2.7726, 
=============================================================
epoch: 15, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 16, [batch: 1 / 11375], examples_per_second: 23.1213, train_label_loss: 2.7728, 
epoch: 16, [batch: 2275 / 11375], examples_per_second: 34758.3195, train_label_loss: 2.7728, 
epoch: 16, [batch: 4550 / 11375], examples_per_second: 34758.4919, train_label_loss: 2.7727, 
epoch: 16, [batch: 6825 / 11375], examples_per_second: 34748.9026, train_label_loss: 2.7727, 
epoch: 16, [batch: 9100 / 11375], examples_per_second: 34758.3940, train_label_loss: 2.7725, 
=============================================================
epoch: 16, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 17, [batch: 1 / 11375], examples_per_second: 23.1999, train_label_loss: 2.7725, 
epoch: 17, [batch: 2275 / 11375], examples_per_second: 34742.6173, train_label_loss: 2.7727, 
epoch: 17, [batch: 4550 / 11375], examples_per_second: 34753.9176, train_label_loss: 2.7726, 
epoch: 17, [batch: 6825 / 11375], examples_per_second: 34741.7682, train_label_loss: 2.7729, 
epoch: 17, [batch: 9100 / 11375], examples_per_second: 34732.1199, train_label_loss: 2.7725, 
=============================================================
epoch: 17, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 18, [batch: 1 / 11375], examples_per_second: 23.1755, train_label_loss: 2.7726, 
epoch: 18, [batch: 2275 / 11375], examples_per_second: 34779.8843, train_label_loss: 2.7722, 
epoch: 18, [batch: 4550 / 11375], examples_per_second: 34772.1038, train_label_loss: 2.7726, 
epoch: 18, [batch: 6825 / 11375], examples_per_second: 34784.2601, train_label_loss: 2.7730, 
epoch: 18, [batch: 9100 / 11375], examples_per_second: 34783.7009, train_label_loss: 2.7729, 
=============================================================
epoch: 18, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 19, [batch: 1 / 11375], examples_per_second: 22.8285, train_label_loss: 2.7725, 
epoch: 19, [batch: 2275 / 11375], examples_per_second: 34763.7181, train_label_loss: 2.7727, 
epoch: 19, [batch: 4550 / 11375], examples_per_second: 34779.7662, train_label_loss: 2.7725, 
epoch: 19, [batch: 6825 / 11375], examples_per_second: 34771.8573, train_label_loss: 2.7725, 
epoch: 19, [batch: 9100 / 11375], examples_per_second: 34726.4867, train_label_loss: 2.7725, 
=============================================================
epoch: 19, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 20, [batch: 1 / 11375], examples_per_second: 23.1956, train_label_loss: 2.7725, 
epoch: 20, [batch: 2275 / 11375], examples_per_second: 34748.1173, train_label_loss: 2.7726, 
epoch: 20, [batch: 4550 / 11375], examples_per_second: 34771.7895, train_label_loss: 2.7725, 
epoch: 20, [batch: 6825 / 11375], examples_per_second: 34778.5312, train_label_loss: 2.7724, 
epoch: 20, [batch: 9100 / 11375], examples_per_second: 34772.7794, train_label_loss: 2.7726, 
=============================================================
epoch: 20, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 21, [batch: 1 / 11375], examples_per_second: 23.2089, train_label_loss: 2.7727, 
epoch: 21, [batch: 2275 / 11375], examples_per_second: 34766.9321, train_label_loss: 2.7730, 
epoch: 21, [batch: 4550 / 11375], examples_per_second: 34759.8392, train_label_loss: 2.7726, 
epoch: 21, [batch: 6825 / 11375], examples_per_second: 34790.9794, train_label_loss: 2.7726, 
epoch: 21, [batch: 9100 / 11375], examples_per_second: 34770.1601, train_label_loss: 2.7726, 
=============================================================
epoch: 21, val_acc_label: 0.0619, val_label_loss: 2.7726, 
=============================================================
epoch: 22, [batch: 1 / 11375], examples_per_second: 23.2220, train_label_loss: 2.7726, 
epoch: 22, [batch: 2275 / 11375], examples_per_second: 34738.8947, train_label_loss: 2.7727, 
epoch: 22, [batch: 4550 / 11375], examples_per_second: 34804.2061, train_label_loss: 2.7724, 
epoch: 22, [batch: 6825 / 11375], examples_per_second: 34777.4493, train_label_loss: 2.7724, 
epoch: 22, [batch: 9100 / 11375], examples_per_second: 34786.0844, train_label_loss: 2.7730, 
=============================================================
epoch: 22, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.06253205128205128 Target Test Label Accuracy: 0.06253205128205128
Source Val Label Accuracy: 0.06289262820512821 Target Val Label Accuracy: 0.06289262820512821
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
