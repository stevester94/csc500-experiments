[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1725.0042, train_label_loss: 2.7727, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 34935.1131, train_label_loss: 2.7725, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 34996.2215, train_label_loss: 2.7729, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 34840.2214, train_label_loss: 2.7729, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 34872.7688, train_label_loss: 2.7725, 
=============================================================
epoch: 1, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 22.5446, train_label_loss: 2.7725, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 34906.5948, train_label_loss: 2.7725, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 34905.2189, train_label_loss: 2.7727, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 34924.6198, train_label_loss: 2.7728, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 34750.9447, train_label_loss: 2.7728, 
=============================================================
epoch: 2, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 3, [batch: 1 / 11375], examples_per_second: 23.2537, train_label_loss: 2.7726, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 34733.4421, train_label_loss: 2.7726, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 34701.0515, train_label_loss: 2.7728, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 34737.5940, train_label_loss: 2.7726, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 34758.4440, train_label_loss: 2.7725, 
=============================================================
epoch: 3, val_acc_label: 0.0620, val_label_loss: 2.7726, 
=============================================================
epoch: 4, [batch: 1 / 11375], examples_per_second: 23.1601, train_label_loss: 2.7728, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 34740.9692, train_label_loss: 2.7730, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 34727.7471, train_label_loss: 2.7728, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 34725.3700, train_label_loss: 2.7726, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 34719.8688, train_label_loss: 2.7728, 
=============================================================
epoch: 4, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 5, [batch: 1 / 11375], examples_per_second: 23.1702, train_label_loss: 2.7726, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 34708.5618, train_label_loss: 2.7724, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 34703.7205, train_label_loss: 2.7725, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 34733.3921, train_label_loss: 2.7724, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 34702.4614, train_label_loss: 2.7727, 
=============================================================
epoch: 5, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 23.1416, train_label_loss: 2.7724, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 34603.5426, train_label_loss: 2.7726, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 34734.1823, train_label_loss: 2.7725, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 34725.8706, train_label_loss: 2.7726, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 34721.1090, train_label_loss: 2.7725, 
=============================================================
epoch: 6, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 7, [batch: 1 / 11375], examples_per_second: 22.8851, train_label_loss: 2.7729, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 34704.9181, train_label_loss: 2.7724, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 34695.2766, train_label_loss: 2.7720, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 34746.4515, train_label_loss: 2.7724, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 34706.1139, train_label_loss: 2.7725, 
=============================================================
epoch: 7, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 23.1669, train_label_loss: 2.7727, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 34736.9668, train_label_loss: 2.7727, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 34725.1889, train_label_loss: 2.7727, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 34707.0355, train_label_loss: 2.7726, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 34725.4451, train_label_loss: 2.7722, 
=============================================================
epoch: 8, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 9, [batch: 1 / 11375], examples_per_second: 23.1970, train_label_loss: 2.7729, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 34734.5993, train_label_loss: 2.7723, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 34725.6806, train_label_loss: 2.7725, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 34722.5935, train_label_loss: 2.7725, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 34725.1282, train_label_loss: 2.7726, 
=============================================================
epoch: 9, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 23.2558, train_label_loss: 2.7722, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 34684.1891, train_label_loss: 2.7728, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 34697.7170, train_label_loss: 2.7726, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 34714.6761, train_label_loss: 2.7725, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 34714.2770, train_label_loss: 2.7726, 
=============================================================
epoch: 10, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 11, [batch: 1 / 11375], examples_per_second: 23.1727, train_label_loss: 2.7729, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 34696.7863, train_label_loss: 2.7725, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 34741.7549, train_label_loss: 2.7722, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 34696.8851, train_label_loss: 2.7723, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 34702.8962, train_label_loss: 2.7724, 
=============================================================
epoch: 11, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 12, [batch: 1 / 11375], examples_per_second: 23.1541, train_label_loss: 2.7726, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 34711.7819, train_label_loss: 2.7727, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 34725.5710, train_label_loss: 2.7729, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 34739.1901, train_label_loss: 2.7724, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 34735.0027, train_label_loss: 2.7724, 
=============================================================
epoch: 12, val_acc_label: 0.0620, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.06236858974358974 Target Test Label Accuracy: 0.06236858974358974
Source Val Label Accuracy: 0.06268429487179487 Target Val Label Accuracy: 0.06268429487179487
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
