[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1537.4101, train_label_loss: 2.7725, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 34997.0594, train_label_loss: 2.7725, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 35061.1331, train_label_loss: 2.7724, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 34968.9776, train_label_loss: 2.7728, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 34975.3202, train_label_loss: 2.7724, 
=============================================================
epoch: 1, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 22.4854, train_label_loss: 2.7725, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 34907.4507, train_label_loss: 2.7730, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 34919.3567, train_label_loss: 2.7728, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 34753.6487, train_label_loss: 2.7725, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 34762.2586, train_label_loss: 2.7728, 
=============================================================
epoch: 2, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 3, [batch: 1 / 11375], examples_per_second: 23.2370, train_label_loss: 2.7730, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 34745.7102, train_label_loss: 2.7725, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 34779.0041, train_label_loss: 2.7726, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 34778.6589, train_label_loss: 2.7725, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 34754.5362, train_label_loss: 2.7728, 
=============================================================
epoch: 3, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 4, [batch: 1 / 11375], examples_per_second: 23.1207, train_label_loss: 2.7724, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 34733.5197, train_label_loss: 2.7727, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 34756.2961, train_label_loss: 2.7725, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 34783.5072, train_label_loss: 2.7727, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 34778.2123, train_label_loss: 2.7725, 
=============================================================
epoch: 4, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 5, [batch: 1 / 11375], examples_per_second: 23.1559, train_label_loss: 2.7727, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 34753.6428, train_label_loss: 2.7725, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 34748.6342, train_label_loss: 2.7728, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 34718.8937, train_label_loss: 2.7728, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 34746.3245, train_label_loss: 2.7730, 
=============================================================
epoch: 5, val_acc_label: 0.0628, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 23.1851, train_label_loss: 2.7725, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 34733.8201, train_label_loss: 2.7724, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 34747.5858, train_label_loss: 2.7723, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 34743.5056, train_label_loss: 2.7726, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 34731.4138, train_label_loss: 2.7728, 
=============================================================
epoch: 6, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 7, [batch: 1 / 11375], examples_per_second: 22.8171, train_label_loss: 2.7723, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 34723.3607, train_label_loss: 2.7722, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 34721.1124, train_label_loss: 2.7725, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 34738.3325, train_label_loss: 2.7726, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 34741.1842, train_label_loss: 2.7726, 
=============================================================
epoch: 7, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 23.2214, train_label_loss: 2.7727, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 34729.2404, train_label_loss: 2.7725, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 34750.8469, train_label_loss: 2.7725, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 34733.3561, train_label_loss: 2.7728, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 34754.4121, train_label_loss: 2.7723, 
=============================================================
epoch: 8, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 9, [batch: 1 / 11375], examples_per_second: 23.1993, train_label_loss: 2.7728, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 34749.1880, train_label_loss: 2.7729, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 34721.0364, train_label_loss: 2.7726, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 34725.7576, train_label_loss: 2.7727, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 34739.7800, train_label_loss: 2.7726, 
=============================================================
epoch: 9, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 23.1900, train_label_loss: 2.7726, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 34736.6584, train_label_loss: 2.7725, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 34732.3743, train_label_loss: 2.7730, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 34761.4038, train_label_loss: 2.7726, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 34775.2115, train_label_loss: 2.7727, 
=============================================================
epoch: 10, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 11, [batch: 1 / 11375], examples_per_second: 23.1847, train_label_loss: 2.7727, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 34747.7509, train_label_loss: 2.7725, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 34770.3136, train_label_loss: 2.7728, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 34758.8199, train_label_loss: 2.7724, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 34733.9487, train_label_loss: 2.7725, 
=============================================================
epoch: 11, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 12, [batch: 1 / 11375], examples_per_second: 23.0480, train_label_loss: 2.7728, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 34735.3598, train_label_loss: 2.7726, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 34767.1785, train_label_loss: 2.7726, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 34736.4628, train_label_loss: 2.7727, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 34734.3290, train_label_loss: 2.7723, 
=============================================================
epoch: 12, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 13, [batch: 1 / 11375], examples_per_second: 23.1910, train_label_loss: 2.7726, 
epoch: 13, [batch: 2275 / 11375], examples_per_second: 34728.8338, train_label_loss: 2.7724, 
epoch: 13, [batch: 4550 / 11375], examples_per_second: 34733.2454, train_label_loss: 2.7726, 
epoch: 13, [batch: 6825 / 11375], examples_per_second: 34737.8988, train_label_loss: 2.7723, 
epoch: 13, [batch: 9100 / 11375], examples_per_second: 34733.2202, train_label_loss: 2.7726, 
=============================================================
epoch: 13, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 14, [batch: 1 / 11375], examples_per_second: 23.1781, train_label_loss: 2.7728, 
epoch: 14, [batch: 2275 / 11375], examples_per_second: 34736.5833, train_label_loss: 2.7725, 
epoch: 14, [batch: 4550 / 11375], examples_per_second: 34742.9472, train_label_loss: 2.7727, 
epoch: 14, [batch: 6825 / 11375], examples_per_second: 34743.6558, train_label_loss: 2.7727, 
epoch: 14, [batch: 9100 / 11375], examples_per_second: 34744.1781, train_label_loss: 2.7727, 
=============================================================
epoch: 14, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 15, [batch: 1 / 11375], examples_per_second: 23.1774, train_label_loss: 2.7723, 
epoch: 15, [batch: 2275 / 11375], examples_per_second: 34737.7694, train_label_loss: 2.7724, 
epoch: 15, [batch: 4550 / 11375], examples_per_second: 34784.9724, train_label_loss: 2.7729, 
epoch: 15, [batch: 6825 / 11375], examples_per_second: 34755.2206, train_label_loss: 2.7725, 
epoch: 15, [batch: 9100 / 11375], examples_per_second: 34741.8690, train_label_loss: 2.7724, 
=============================================================
epoch: 15, val_acc_label: 0.0628, val_label_loss: 2.7726, 
=============================================================
epoch: 16, [batch: 1 / 11375], examples_per_second: 23.1775, train_label_loss: 2.7726, 
epoch: 16, [batch: 2275 / 11375], examples_per_second: 34699.3923, train_label_loss: 2.7727, 
epoch: 16, [batch: 4550 / 11375], examples_per_second: 34735.1593, train_label_loss: 2.7726, 
epoch: 16, [batch: 6825 / 11375], examples_per_second: 34739.1279, train_label_loss: 2.7725, 
epoch: 16, [batch: 9100 / 11375], examples_per_second: 34748.7523, train_label_loss: 2.7724, 
=============================================================
epoch: 16, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 17, [batch: 1 / 11375], examples_per_second: 23.1079, train_label_loss: 2.7726, 
epoch: 17, [batch: 2275 / 11375], examples_per_second: 34753.5221, train_label_loss: 2.7730, 
epoch: 17, [batch: 4550 / 11375], examples_per_second: 34762.0973, train_label_loss: 2.7719, 
epoch: 17, [batch: 6825 / 11375], examples_per_second: 34710.2080, train_label_loss: 2.7723, 
epoch: 17, [batch: 9100 / 11375], examples_per_second: 34713.8823, train_label_loss: 2.7727, 
=============================================================
epoch: 17, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 18, [batch: 1 / 11375], examples_per_second: 23.1390, train_label_loss: 2.7726, 
epoch: 18, [batch: 2275 / 11375], examples_per_second: 34735.4309, train_label_loss: 2.7725, 
epoch: 18, [batch: 4550 / 11375], examples_per_second: 34747.9773, train_label_loss: 2.7724, 
epoch: 18, [batch: 6825 / 11375], examples_per_second: 34725.7887, train_label_loss: 2.7726, 
epoch: 18, [batch: 9100 / 11375], examples_per_second: 34762.9809, train_label_loss: 2.7725, 
=============================================================
epoch: 18, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 19, [batch: 1 / 11375], examples_per_second: 22.7900, train_label_loss: 2.7726, 
epoch: 19, [batch: 2275 / 11375], examples_per_second: 34756.8738, train_label_loss: 2.7724, 
epoch: 19, [batch: 4550 / 11375], examples_per_second: 34726.9537, train_label_loss: 2.7727, 
epoch: 19, [batch: 6825 / 11375], examples_per_second: 34743.2412, train_label_loss: 2.7726, 
epoch: 19, [batch: 9100 / 11375], examples_per_second: 34753.4642, train_label_loss: 2.7729, 
=============================================================
epoch: 19, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 20, [batch: 1 / 11375], examples_per_second: 23.0916, train_label_loss: 2.7727, 
epoch: 20, [batch: 2275 / 11375], examples_per_second: 34717.3872, train_label_loss: 2.7725, 
epoch: 20, [batch: 4550 / 11375], examples_per_second: 34754.7800, train_label_loss: 2.7726, 
epoch: 20, [batch: 6825 / 11375], examples_per_second: 34743.3277, train_label_loss: 2.7728, 
epoch: 20, [batch: 9100 / 11375], examples_per_second: 34759.0914, train_label_loss: 2.7725, 
=============================================================
epoch: 20, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 21, [batch: 1 / 11375], examples_per_second: 23.1193, train_label_loss: 2.7726, 
epoch: 21, [batch: 2275 / 11375], examples_per_second: 34745.9945, train_label_loss: 2.7724, 
epoch: 21, [batch: 4550 / 11375], examples_per_second: 34731.3669, train_label_loss: 2.7730, 
epoch: 21, [batch: 6825 / 11375], examples_per_second: 34723.0595, train_label_loss: 2.7725, 
epoch: 21, [batch: 9100 / 11375], examples_per_second: 34511.8909, train_label_loss: 2.7726, 
=============================================================
epoch: 21, val_acc_label: 0.0628, val_label_loss: 2.7726, 
=============================================================
epoch: 22, [batch: 1 / 11375], examples_per_second: 23.1662, train_label_loss: 2.7724, 
epoch: 22, [batch: 2275 / 11375], examples_per_second: 34755.2797, train_label_loss: 2.7724, 
epoch: 22, [batch: 4550 / 11375], examples_per_second: 34773.8536, train_label_loss: 2.7728, 
epoch: 22, [batch: 6825 / 11375], examples_per_second: 34771.7103, train_label_loss: 2.7726, 
epoch: 22, [batch: 9100 / 11375], examples_per_second: 34764.9485, train_label_loss: 2.7724, 
=============================================================
epoch: 22, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 23, [batch: 1 / 11375], examples_per_second: 23.1767, train_label_loss: 2.7728, 
epoch: 23, [batch: 2275 / 11375], examples_per_second: 34755.2501, train_label_loss: 2.7725, 
epoch: 23, [batch: 4550 / 11375], examples_per_second: 34740.0300, train_label_loss: 2.7728, 
epoch: 23, [batch: 6825 / 11375], examples_per_second: 34737.2507, train_label_loss: 2.7728, 
epoch: 23, [batch: 9100 / 11375], examples_per_second: 34754.1723, train_label_loss: 2.7723, 
=============================================================
epoch: 23, val_acc_label: 0.0631, val_label_loss: 2.7726, 
=============================================================
epoch: 24, [batch: 1 / 11375], examples_per_second: 23.2015, train_label_loss: 2.7725, 
epoch: 24, [batch: 2275 / 11375], examples_per_second: 34724.0757, train_label_loss: 2.7725, 
epoch: 24, [batch: 4550 / 11375], examples_per_second: 34737.2917, train_label_loss: 2.7725, 
epoch: 24, [batch: 6825 / 11375], examples_per_second: 34759.8115, train_label_loss: 2.7725, 
epoch: 24, [batch: 9100 / 11375], examples_per_second: 34741.0858, train_label_loss: 2.7727, 
=============================================================
epoch: 24, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 25, [batch: 1 / 11375], examples_per_second: 23.1568, train_label_loss: 2.7725, 
epoch: 25, [batch: 2275 / 11375], examples_per_second: 34736.5680, train_label_loss: 2.7726, 
epoch: 25, [batch: 4550 / 11375], examples_per_second: 34743.0075, train_label_loss: 2.7727, 
epoch: 25, [batch: 6825 / 11375], examples_per_second: 34744.9614, train_label_loss: 2.7728, 
epoch: 25, [batch: 9100 / 11375], examples_per_second: 34745.6133, train_label_loss: 2.7725, 
=============================================================
epoch: 25, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 26, [batch: 1 / 11375], examples_per_second: 23.1568, train_label_loss: 2.7726, 
epoch: 26, [batch: 2275 / 11375], examples_per_second: 34741.6603, train_label_loss: 2.7727, 
epoch: 26, [batch: 4550 / 11375], examples_per_second: 34717.8930, train_label_loss: 2.7725, 
epoch: 26, [batch: 6825 / 11375], examples_per_second: 34724.5057, train_label_loss: 2.7726, 
epoch: 26, [batch: 9100 / 11375], examples_per_second: 34718.6006, train_label_loss: 2.7725, 
=============================================================
epoch: 26, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 27, [batch: 1 / 11375], examples_per_second: 23.1598, train_label_loss: 2.7726, 
epoch: 27, [batch: 2275 / 11375], examples_per_second: 34724.2505, train_label_loss: 2.7725, 
epoch: 27, [batch: 4550 / 11375], examples_per_second: 34737.8296, train_label_loss: 2.7725, 
epoch: 27, [batch: 6825 / 11375], examples_per_second: 34742.4862, train_label_loss: 2.7725, 
epoch: 27, [batch: 9100 / 11375], examples_per_second: 34743.5639, train_label_loss: 2.7724, 
=============================================================
epoch: 27, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 28, [batch: 1 / 11375], examples_per_second: 23.1348, train_label_loss: 2.7727, 
epoch: 28, [batch: 2275 / 11375], examples_per_second: 34088.0823, train_label_loss: 2.7720, 
epoch: 28, [batch: 4550 / 11375], examples_per_second: 34732.0478, train_label_loss: 2.7731, 
epoch: 28, [batch: 6825 / 11375], examples_per_second: 34737.1114, train_label_loss: 2.7724, 
epoch: 28, [batch: 9100 / 11375], examples_per_second: 34736.1743, train_label_loss: 2.7727, 
=============================================================
epoch: 28, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.06226442307692308 Target Test Label Accuracy: 0.06226442307692308
Source Val Label Accuracy: 0.06252564102564102 Target Val Label Accuracy: 0.06252564102564102
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
