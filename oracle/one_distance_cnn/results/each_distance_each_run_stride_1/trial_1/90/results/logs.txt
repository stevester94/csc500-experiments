[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1861.0818, train_label_loss: 2.7726, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 34831.1312, train_label_loss: 2.7726, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 34908.8668, train_label_loss: 2.7724, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 34907.5109, train_label_loss: 2.7727, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 34903.4578, train_label_loss: 2.7727, 
=============================================================
epoch: 1, val_acc_label: 0.0619, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 22.5530, train_label_loss: 2.7723, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 34901.3159, train_label_loss: 2.7725, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 34832.0878, train_label_loss: 2.7723, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 34752.5550, train_label_loss: 2.7723, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 34747.5824, train_label_loss: 2.7728, 
=============================================================
epoch: 2, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 3, [batch: 1 / 11375], examples_per_second: 23.2094, train_label_loss: 2.7726, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 34758.7490, train_label_loss: 2.7728, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 34733.9882, train_label_loss: 2.7727, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 34763.7418, train_label_loss: 2.7728, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 34723.6557, train_label_loss: 2.7725, 
=============================================================
epoch: 3, val_acc_label: 0.0619, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 4, [batch: 1 / 11375], examples_per_second: 23.1869, train_label_loss: 2.7725, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 34721.1683, train_label_loss: 2.7726, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 34748.9407, train_label_loss: 2.7726, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 34754.2257, train_label_loss: 2.7726, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 34731.9333, train_label_loss: 2.7725, 
=============================================================
epoch: 4, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 5, [batch: 1 / 11375], examples_per_second: 23.1728, train_label_loss: 2.7724, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 34715.4873, train_label_loss: 2.7724, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 34728.3973, train_label_loss: 2.7725, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 34742.5820, train_label_loss: 2.7724, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 34723.9647, train_label_loss: 2.7724, 
=============================================================
epoch: 5, val_acc_label: 0.0619, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 23.1461, train_label_loss: 2.7727, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 34732.7420, train_label_loss: 2.7724, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 34738.8201, train_label_loss: 2.7727, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 34715.3846, train_label_loss: 2.7726, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 34724.4282, train_label_loss: 2.7725, 
=============================================================
epoch: 6, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 7, [batch: 1 / 11375], examples_per_second: 23.1275, train_label_loss: 2.7726, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 34711.6304, train_label_loss: 2.7726, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 34729.7709, train_label_loss: 2.7728, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 34734.5769, train_label_loss: 2.7727, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 34720.0045, train_label_loss: 2.7727, 
=============================================================
epoch: 7, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 22.8288, train_label_loss: 2.7728, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 34718.1750, train_label_loss: 2.7727, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 34721.3044, train_label_loss: 2.7728, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 34726.5780, train_label_loss: 2.7728, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 34718.8606, train_label_loss: 2.7725, 
=============================================================
epoch: 8, val_acc_label: 0.0628, val_label_loss: 2.7726, 
=============================================================
epoch: 9, [batch: 1 / 11375], examples_per_second: 23.1572, train_label_loss: 2.7726, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 34730.9842, train_label_loss: 2.7722, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 34724.4509, train_label_loss: 2.7725, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 34722.5106, train_label_loss: 2.7725, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 34732.1876, train_label_loss: 2.7725, 
=============================================================
epoch: 9, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 23.2306, train_label_loss: 2.7727, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 34709.0305, train_label_loss: 2.7726, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 34727.7683, train_label_loss: 2.7728, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 34738.2851, train_label_loss: 2.7723, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 34730.1511, train_label_loss: 2.7723, 
=============================================================
epoch: 10, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 11, [batch: 1 / 11375], examples_per_second: 23.1394, train_label_loss: 2.7727, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 34721.4409, train_label_loss: 2.7725, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 34725.8711, train_label_loss: 2.7727, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 34729.3542, train_label_loss: 2.7722, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 34730.3951, train_label_loss: 2.7728, 
=============================================================
epoch: 11, val_acc_label: 0.0629, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 12, [batch: 1 / 11375], examples_per_second: 23.0768, train_label_loss: 2.7726, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 34743.1092, train_label_loss: 2.7727, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 34746.3008, train_label_loss: 2.7727, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 34734.0391, train_label_loss: 2.7725, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 34735.1128, train_label_loss: 2.7722, 
=============================================================
epoch: 12, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 13, [batch: 1 / 11375], examples_per_second: 23.2389, train_label_loss: 2.7728, 
epoch: 13, [batch: 2275 / 11375], examples_per_second: 34714.7849, train_label_loss: 2.7731, 
epoch: 13, [batch: 4550 / 11375], examples_per_second: 34728.9271, train_label_loss: 2.7728, 
epoch: 13, [batch: 6825 / 11375], examples_per_second: 34753.1196, train_label_loss: 2.7726, 
epoch: 13, [batch: 9100 / 11375], examples_per_second: 34730.2973, train_label_loss: 2.7725, 
=============================================================
epoch: 13, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 14, [batch: 1 / 11375], examples_per_second: 23.1627, train_label_loss: 2.7724, 
epoch: 14, [batch: 2275 / 11375], examples_per_second: 34704.5590, train_label_loss: 2.7725, 
epoch: 14, [batch: 4550 / 11375], examples_per_second: 34728.8027, train_label_loss: 2.7725, 
epoch: 14, [batch: 6825 / 11375], examples_per_second: 34730.3235, train_label_loss: 2.7726, 
epoch: 14, [batch: 9100 / 11375], examples_per_second: 34744.5606, train_label_loss: 2.7727, 
=============================================================
epoch: 14, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 15, [batch: 1 / 11375], examples_per_second: 23.2308, train_label_loss: 2.7727, 
epoch: 15, [batch: 2275 / 11375], examples_per_second: 34728.2411, train_label_loss: 2.7724, 
epoch: 15, [batch: 4550 / 11375], examples_per_second: 34733.4538, train_label_loss: 2.7726, 
epoch: 15, [batch: 6825 / 11375], examples_per_second: 34752.1654, train_label_loss: 2.7727, 
epoch: 15, [batch: 9100 / 11375], examples_per_second: 34725.4930, train_label_loss: 2.7726, 
=============================================================
epoch: 15, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 16, [batch: 1 / 11375], examples_per_second: 23.1973, train_label_loss: 2.7728, 
epoch: 16, [batch: 2275 / 11375], examples_per_second: 34734.7065, train_label_loss: 2.7728, 
epoch: 16, [batch: 4550 / 11375], examples_per_second: 34726.3258, train_label_loss: 2.7727, 
epoch: 16, [batch: 6825 / 11375], examples_per_second: 34742.2593, train_label_loss: 2.7727, 
epoch: 16, [batch: 9100 / 11375], examples_per_second: 34749.8181, train_label_loss: 2.7725, 
=============================================================
epoch: 16, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 17, [batch: 1 / 11375], examples_per_second: 23.1863, train_label_loss: 2.7725, 
epoch: 17, [batch: 2275 / 11375], examples_per_second: 34714.9039, train_label_loss: 2.7727, 
epoch: 17, [batch: 4550 / 11375], examples_per_second: 34737.4507, train_label_loss: 2.7726, 
epoch: 17, [batch: 6825 / 11375], examples_per_second: 34727.7856, train_label_loss: 2.7729, 
epoch: 17, [batch: 9100 / 11375], examples_per_second: 34698.4923, train_label_loss: 2.7725, 
=============================================================
epoch: 17, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 18, [batch: 1 / 11375], examples_per_second: 23.2468, train_label_loss: 2.7726, 
epoch: 18, [batch: 2275 / 11375], examples_per_second: 34728.8408, train_label_loss: 2.7722, 
epoch: 18, [batch: 4550 / 11375], examples_per_second: 34732.6291, train_label_loss: 2.7726, 
epoch: 18, [batch: 6825 / 11375], examples_per_second: 34703.8009, train_label_loss: 2.7730, 
epoch: 18, [batch: 9100 / 11375], examples_per_second: 34726.6215, train_label_loss: 2.7729, 
=============================================================
epoch: 18, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 19, [batch: 1 / 11375], examples_per_second: 23.1871, train_label_loss: 2.7725, 
epoch: 19, [batch: 2275 / 11375], examples_per_second: 34747.9853, train_label_loss: 2.7727, 
epoch: 19, [batch: 4550 / 11375], examples_per_second: 34716.8627, train_label_loss: 2.7725, 
epoch: 19, [batch: 6825 / 11375], examples_per_second: 34713.7334, train_label_loss: 2.7725, 
epoch: 19, [batch: 9100 / 11375], examples_per_second: 34721.5250, train_label_loss: 2.7725, 
=============================================================
epoch: 19, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 20, [batch: 1 / 11375], examples_per_second: 23.1647, train_label_loss: 2.7725, 
epoch: 20, [batch: 2275 / 11375], examples_per_second: 34732.2529, train_label_loss: 2.7726, 
epoch: 20, [batch: 4550 / 11375], examples_per_second: 34744.7450, train_label_loss: 2.7725, 
epoch: 20, [batch: 6825 / 11375], examples_per_second: 34723.7564, train_label_loss: 2.7724, 
epoch: 20, [batch: 9100 / 11375], examples_per_second: 34728.2487, train_label_loss: 2.7726, 
=============================================================
epoch: 20, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 21, [batch: 1 / 11375], examples_per_second: 22.7961, train_label_loss: 2.7727, 
epoch: 21, [batch: 2275 / 11375], examples_per_second: 34730.8977, train_label_loss: 2.7730, 
epoch: 21, [batch: 4550 / 11375], examples_per_second: 34723.0965, train_label_loss: 2.7726, 
epoch: 21, [batch: 6825 / 11375], examples_per_second: 34756.7956, train_label_loss: 2.7726, 
epoch: 21, [batch: 9100 / 11375], examples_per_second: 34750.2793, train_label_loss: 2.7726, 
=============================================================
epoch: 21, val_acc_label: 0.0619, val_label_loss: 2.7726, 
=============================================================
epoch: 22, [batch: 1 / 11375], examples_per_second: 23.1862, train_label_loss: 2.7726, 
epoch: 22, [batch: 2275 / 11375], examples_per_second: 34725.2767, train_label_loss: 2.7727, 
epoch: 22, [batch: 4550 / 11375], examples_per_second: 34745.4097, train_label_loss: 2.7724, 
epoch: 22, [batch: 6825 / 11375], examples_per_second: 34734.0643, train_label_loss: 2.7724, 
epoch: 22, [batch: 9100 / 11375], examples_per_second: 34730.2563, train_label_loss: 2.7730, 
=============================================================
epoch: 22, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.06253205128205128 Target Test Label Accuracy: 0.06253205128205128
Source Val Label Accuracy: 0.06289262820512821 Target Val Label Accuracy: 0.06289262820512821
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
