[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1747.7831, train_label_loss: 2.7725, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 34925.6511, train_label_loss: 2.7725, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 34961.4293, train_label_loss: 2.7724, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 34852.5034, train_label_loss: 2.7728, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 34859.9033, train_label_loss: 2.7724, 
=============================================================
epoch: 1, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 22.4954, train_label_loss: 2.7725, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 34838.1047, train_label_loss: 2.7730, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 34872.5089, train_label_loss: 2.7728, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 34721.3291, train_label_loss: 2.7724, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 34694.2230, train_label_loss: 2.7728, 
=============================================================
epoch: 2, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 3, [batch: 1 / 11375], examples_per_second: 23.1121, train_label_loss: 2.7730, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 34670.4559, train_label_loss: 2.7725, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 34681.1182, train_label_loss: 2.7726, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 34691.2756, train_label_loss: 2.7725, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 34687.0623, train_label_loss: 2.7728, 
=============================================================
epoch: 3, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 4, [batch: 1 / 11375], examples_per_second: 23.2827, train_label_loss: 2.7724, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 34664.2934, train_label_loss: 2.7727, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 34690.1223, train_label_loss: 2.7725, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 34663.8209, train_label_loss: 2.7727, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 34681.6731, train_label_loss: 2.7725, 
=============================================================
epoch: 4, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 5, [batch: 1 / 11375], examples_per_second: 23.0843, train_label_loss: 2.7727, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 34684.7537, train_label_loss: 2.7725, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 34689.5498, train_label_loss: 2.7728, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 34707.0148, train_label_loss: 2.7728, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 34661.0041, train_label_loss: 2.7730, 
=============================================================
epoch: 5, val_acc_label: 0.0628, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 22.9954, train_label_loss: 2.7725, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 34641.9713, train_label_loss: 2.7724, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 34633.6233, train_label_loss: 2.7723, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 34689.2355, train_label_loss: 2.7726, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 34668.3794, train_label_loss: 2.7728, 
=============================================================
epoch: 6, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 7, [batch: 1 / 11375], examples_per_second: 23.0993, train_label_loss: 2.7723, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 34671.8398, train_label_loss: 2.7722, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 34653.5458, train_label_loss: 2.7725, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 34654.9376, train_label_loss: 2.7726, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 34670.4982, train_label_loss: 2.7726, 
=============================================================
epoch: 7, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 22.7629, train_label_loss: 2.7727, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 34684.1428, train_label_loss: 2.7725, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 34702.8716, train_label_loss: 2.7725, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 34693.6041, train_label_loss: 2.7728, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 34669.5047, train_label_loss: 2.7723, 
=============================================================
epoch: 8, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 9, [batch: 1 / 11375], examples_per_second: 23.0660, train_label_loss: 2.7728, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 34673.8024, train_label_loss: 2.7729, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 34698.9615, train_label_loss: 2.7726, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 34671.5848, train_label_loss: 2.7727, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 34701.1294, train_label_loss: 2.7726, 
=============================================================
epoch: 9, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 23.1412, train_label_loss: 2.7726, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 34661.9599, train_label_loss: 2.7725, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 34667.3605, train_label_loss: 2.7730, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 34670.8412, train_label_loss: 2.7726, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 34665.9057, train_label_loss: 2.7727, 
=============================================================
epoch: 10, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 11, [batch: 1 / 11375], examples_per_second: 23.1703, train_label_loss: 2.7727, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 34640.2462, train_label_loss: 2.7725, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 34671.4169, train_label_loss: 2.7728, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 34683.3129, train_label_loss: 2.7724, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 34688.1040, train_label_loss: 2.7725, 
=============================================================
epoch: 11, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 12, [batch: 1 / 11375], examples_per_second: 23.1155, train_label_loss: 2.7728, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 34654.6397, train_label_loss: 2.7726, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 34676.0276, train_label_loss: 2.7726, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 34663.5194, train_label_loss: 2.7727, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 34659.1564, train_label_loss: 2.7723, 
=============================================================
epoch: 12, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 13, [batch: 1 / 11375], examples_per_second: 23.1716, train_label_loss: 2.7726, 
epoch: 13, [batch: 2275 / 11375], examples_per_second: 34675.4022, train_label_loss: 2.7724, 
epoch: 13, [batch: 4550 / 11375], examples_per_second: 34654.5773, train_label_loss: 2.7726, 
epoch: 13, [batch: 6825 / 11375], examples_per_second: 34663.6502, train_label_loss: 2.7723, 
epoch: 13, [batch: 9100 / 11375], examples_per_second: 34665.8314, train_label_loss: 2.7726, 
=============================================================
epoch: 13, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 14, [batch: 1 / 11375], examples_per_second: 23.0889, train_label_loss: 2.7728, 
epoch: 14, [batch: 2275 / 11375], examples_per_second: 34548.1871, train_label_loss: 2.7725, 
epoch: 14, [batch: 4550 / 11375], examples_per_second: 34652.1768, train_label_loss: 2.7727, 
epoch: 14, [batch: 6825 / 11375], examples_per_second: 34653.6486, train_label_loss: 2.7727, 
epoch: 14, [batch: 9100 / 11375], examples_per_second: 34681.0335, train_label_loss: 2.7727, 
=============================================================
epoch: 14, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 15, [batch: 1 / 11375], examples_per_second: 23.1364, train_label_loss: 2.7723, 
epoch: 15, [batch: 2275 / 11375], examples_per_second: 34685.6150, train_label_loss: 2.7724, 
epoch: 15, [batch: 4550 / 11375], examples_per_second: 34706.6740, train_label_loss: 2.7729, 
epoch: 15, [batch: 6825 / 11375], examples_per_second: 34662.7447, train_label_loss: 2.7725, 
epoch: 15, [batch: 9100 / 11375], examples_per_second: 34665.5067, train_label_loss: 2.7724, 
=============================================================
epoch: 15, val_acc_label: 0.0628, val_label_loss: 2.7726, 
=============================================================
epoch: 16, [batch: 1 / 11375], examples_per_second: 23.1473, train_label_loss: 2.7726, 
epoch: 16, [batch: 2275 / 11375], examples_per_second: 34664.5090, train_label_loss: 2.7727, 
epoch: 16, [batch: 4550 / 11375], examples_per_second: 34688.4154, train_label_loss: 2.7726, 
epoch: 16, [batch: 6825 / 11375], examples_per_second: 34694.7892, train_label_loss: 2.7725, 
epoch: 16, [batch: 9100 / 11375], examples_per_second: 34660.8836, train_label_loss: 2.7724, 
=============================================================
epoch: 16, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 17, [batch: 1 / 11375], examples_per_second: 23.2304, train_label_loss: 2.7726, 
epoch: 17, [batch: 2275 / 11375], examples_per_second: 34646.9931, train_label_loss: 2.7730, 
epoch: 17, [batch: 4550 / 11375], examples_per_second: 34649.9079, train_label_loss: 2.7719, 
epoch: 17, [batch: 6825 / 11375], examples_per_second: 34640.9747, train_label_loss: 2.7723, 
epoch: 17, [batch: 9100 / 11375], examples_per_second: 34674.8099, train_label_loss: 2.7727, 
=============================================================
epoch: 17, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 18, [batch: 1 / 11375], examples_per_second: 23.1651, train_label_loss: 2.7726, 
epoch: 18, [batch: 2275 / 11375], examples_per_second: 34647.4169, train_label_loss: 2.7725, 
epoch: 18, [batch: 4550 / 11375], examples_per_second: 34635.3327, train_label_loss: 2.7724, 
epoch: 18, [batch: 6825 / 11375], examples_per_second: 34663.3020, train_label_loss: 2.7726, 
epoch: 18, [batch: 9100 / 11375], examples_per_second: 34703.5224, train_label_loss: 2.7725, 
=============================================================
epoch: 18, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 19, [batch: 1 / 11375], examples_per_second: 23.1846, train_label_loss: 2.7726, 
epoch: 19, [batch: 2275 / 11375], examples_per_second: 34708.8963, train_label_loss: 2.7724, 
epoch: 19, [batch: 4550 / 11375], examples_per_second: 34666.4296, train_label_loss: 2.7727, 
epoch: 19, [batch: 6825 / 11375], examples_per_second: 34663.3822, train_label_loss: 2.7726, 
epoch: 19, [batch: 9100 / 11375], examples_per_second: 34674.1735, train_label_loss: 2.7729, 
=============================================================
epoch: 19, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 20, [batch: 1 / 11375], examples_per_second: 23.1685, train_label_loss: 2.7727, 
epoch: 20, [batch: 2275 / 11375], examples_per_second: 34642.5916, train_label_loss: 2.7725, 
epoch: 20, [batch: 4550 / 11375], examples_per_second: 34686.9938, train_label_loss: 2.7726, 
epoch: 20, [batch: 6825 / 11375], examples_per_second: 34716.6032, train_label_loss: 2.7728, 
epoch: 20, [batch: 9100 / 11375], examples_per_second: 34685.5522, train_label_loss: 2.7725, 
=============================================================
epoch: 20, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 21, [batch: 1 / 11375], examples_per_second: 22.8679, train_label_loss: 2.7726, 
epoch: 21, [batch: 2275 / 11375], examples_per_second: 34648.9784, train_label_loss: 2.7724, 
epoch: 21, [batch: 4550 / 11375], examples_per_second: 34663.9847, train_label_loss: 2.7730, 
epoch: 21, [batch: 6825 / 11375], examples_per_second: 34645.8427, train_label_loss: 2.7725, 
epoch: 21, [batch: 9100 / 11375], examples_per_second: 34670.0632, train_label_loss: 2.7726, 
=============================================================
epoch: 21, val_acc_label: 0.0628, val_label_loss: 2.7726, 
=============================================================
epoch: 22, [batch: 1 / 11375], examples_per_second: 23.1161, train_label_loss: 2.7724, 
epoch: 22, [batch: 2275 / 11375], examples_per_second: 34690.2862, train_label_loss: 2.7724, 
epoch: 22, [batch: 4550 / 11375], examples_per_second: 34661.7103, train_label_loss: 2.7728, 
epoch: 22, [batch: 6825 / 11375], examples_per_second: 34710.3954, train_label_loss: 2.7726, 
epoch: 22, [batch: 9100 / 11375], examples_per_second: 34672.4238, train_label_loss: 2.7724, 
=============================================================
epoch: 22, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 23, [batch: 1 / 11375], examples_per_second: 23.0928, train_label_loss: 2.7728, 
epoch: 23, [batch: 2275 / 11375], examples_per_second: 34639.7651, train_label_loss: 2.7725, 
epoch: 23, [batch: 4550 / 11375], examples_per_second: 34691.5022, train_label_loss: 2.7728, 
epoch: 23, [batch: 6825 / 11375], examples_per_second: 34671.3038, train_label_loss: 2.7728, 
epoch: 23, [batch: 9100 / 11375], examples_per_second: 34672.7078, train_label_loss: 2.7723, 
=============================================================
epoch: 23, val_acc_label: 0.0631, val_label_loss: 2.7726, 
=============================================================
epoch: 24, [batch: 1 / 11375], examples_per_second: 23.1130, train_label_loss: 2.7725, 
epoch: 24, [batch: 2275 / 11375], examples_per_second: 34666.8320, train_label_loss: 2.7725, 
epoch: 24, [batch: 4550 / 11375], examples_per_second: 34652.0215, train_label_loss: 2.7725, 
epoch: 24, [batch: 6825 / 11375], examples_per_second: 34670.5208, train_label_loss: 2.7725, 
epoch: 24, [batch: 9100 / 11375], examples_per_second: 34655.2144, train_label_loss: 2.7727, 
=============================================================
epoch: 24, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 25, [batch: 1 / 11375], examples_per_second: 23.1173, train_label_loss: 2.7725, 
epoch: 25, [batch: 2275 / 11375], examples_per_second: 34685.2967, train_label_loss: 2.7726, 
epoch: 25, [batch: 4550 / 11375], examples_per_second: 34684.4726, train_label_loss: 2.7727, 
epoch: 25, [batch: 6825 / 11375], examples_per_second: 34668.9261, train_label_loss: 2.7728, 
epoch: 25, [batch: 9100 / 11375], examples_per_second: 34675.7658, train_label_loss: 2.7725, 
=============================================================
epoch: 25, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 26, [batch: 1 / 11375], examples_per_second: 23.1432, train_label_loss: 2.7726, 
epoch: 26, [batch: 2275 / 11375], examples_per_second: 34670.0483, train_label_loss: 2.7727, 
epoch: 26, [batch: 4550 / 11375], examples_per_second: 34666.1123, train_label_loss: 2.7725, 
epoch: 26, [batch: 6825 / 11375], examples_per_second: 34690.7169, train_label_loss: 2.7726, 
epoch: 26, [batch: 9100 / 11375], examples_per_second: 34665.9465, train_label_loss: 2.7725, 
=============================================================
epoch: 26, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 27, [batch: 1 / 11375], examples_per_second: 23.1049, train_label_loss: 2.7726, 
epoch: 27, [batch: 2275 / 11375], examples_per_second: 34657.7961, train_label_loss: 2.7725, 
epoch: 27, [batch: 4550 / 11375], examples_per_second: 34677.6826, train_label_loss: 2.7725, 
epoch: 27, [batch: 6825 / 11375], examples_per_second: 34673.7846, train_label_loss: 2.7725, 
epoch: 27, [batch: 9100 / 11375], examples_per_second: 34676.6759, train_label_loss: 2.7724, 
=============================================================
epoch: 27, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 28, [batch: 1 / 11375], examples_per_second: 23.1469, train_label_loss: 2.7727, 
epoch: 28, [batch: 2275 / 11375], examples_per_second: 34680.4741, train_label_loss: 2.7720, 
epoch: 28, [batch: 4550 / 11375], examples_per_second: 34681.1915, train_label_loss: 2.7731, 
epoch: 28, [batch: 6825 / 11375], examples_per_second: 34657.2052, train_label_loss: 2.7724, 
epoch: 28, [batch: 9100 / 11375], examples_per_second: 34676.9565, train_label_loss: 2.7727, 
=============================================================
epoch: 28, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.06226442307692308 Target Test Label Accuracy: 0.06226442307692308
Source Val Label Accuracy: 0.06252564102564102 Target Val Label Accuracy: 0.06252564102564102
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
