[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1356.7779, train_label_loss: 2.7727, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 34894.1695, train_label_loss: 2.7725, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 34938.8419, train_label_loss: 2.7729, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 34953.7477, train_label_loss: 2.7728, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 34967.5489, train_label_loss: 2.7725, 
=============================================================
epoch: 1, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 22.4506, train_label_loss: 2.7725, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 34972.7383, train_label_loss: 2.7725, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 34910.7117, train_label_loss: 2.7727, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 34792.5141, train_label_loss: 2.7727, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 34793.7262, train_label_loss: 2.7728, 
=============================================================
epoch: 2, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 3, [batch: 1 / 11375], examples_per_second: 23.1396, train_label_loss: 2.7726, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 34795.5324, train_label_loss: 2.7727, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 34797.6795, train_label_loss: 2.7728, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 34774.8313, train_label_loss: 2.7726, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 34786.2880, train_label_loss: 2.7725, 
=============================================================
epoch: 3, val_acc_label: 0.0620, val_label_loss: 2.7726, 
=============================================================
epoch: 4, [batch: 1 / 11375], examples_per_second: 23.1232, train_label_loss: 2.7728, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 34748.6816, train_label_loss: 2.7730, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 34785.7436, train_label_loss: 2.7728, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 34771.4138, train_label_loss: 2.7726, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 34777.9855, train_label_loss: 2.7728, 
=============================================================
epoch: 4, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 5, [batch: 1 / 11375], examples_per_second: 23.0383, train_label_loss: 2.7726, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 34774.4505, train_label_loss: 2.7724, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 34764.4255, train_label_loss: 2.7725, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 34787.9744, train_label_loss: 2.7724, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 34789.8214, train_label_loss: 2.7727, 
=============================================================
epoch: 5, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 23.2646, train_label_loss: 2.7724, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 34794.7738, train_label_loss: 2.7726, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 34769.7538, train_label_loss: 2.7725, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 34766.6139, train_label_loss: 2.7726, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 34768.1549, train_label_loss: 2.7725, 
=============================================================
epoch: 6, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 7, [batch: 1 / 11375], examples_per_second: 22.8615, train_label_loss: 2.7729, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 34780.3143, train_label_loss: 2.7724, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 34742.8642, train_label_loss: 2.7720, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 34797.8827, train_label_loss: 2.7724, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 34795.2532, train_label_loss: 2.7725, 
=============================================================
epoch: 7, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 23.1414, train_label_loss: 2.7727, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 34760.4933, train_label_loss: 2.7727, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 34777.3483, train_label_loss: 2.7727, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 34780.5664, train_label_loss: 2.7726, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 34814.0324, train_label_loss: 2.7722, 
=============================================================
epoch: 8, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 9, [batch: 1 / 11375], examples_per_second: 23.1826, train_label_loss: 2.7729, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 34804.3073, train_label_loss: 2.7723, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 34793.4750, train_label_loss: 2.7725, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 34796.2955, train_label_loss: 2.7725, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 34798.9763, train_label_loss: 2.7726, 
=============================================================
epoch: 9, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 23.1415, train_label_loss: 2.7722, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 34776.4722, train_label_loss: 2.7728, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 34779.4388, train_label_loss: 2.7726, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 34798.8474, train_label_loss: 2.7725, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 34789.1198, train_label_loss: 2.7726, 
=============================================================
epoch: 10, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 11, [batch: 1 / 11375], examples_per_second: 23.0775, train_label_loss: 2.7729, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 34791.3861, train_label_loss: 2.7725, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 34758.3955, train_label_loss: 2.7722, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 34764.0594, train_label_loss: 2.7723, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 34786.3663, train_label_loss: 2.7724, 
=============================================================
epoch: 11, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 12, [batch: 1 / 11375], examples_per_second: 23.0823, train_label_loss: 2.7726, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 34732.5394, train_label_loss: 2.7727, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 34777.0686, train_label_loss: 2.7729, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 34774.8496, train_label_loss: 2.7724, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 34792.0522, train_label_loss: 2.7724, 
=============================================================
epoch: 12, val_acc_label: 0.0620, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.06236858974358974 Target Test Label Accuracy: 0.06236858974358974
Source Val Label Accuracy: 0.06268429487179487 Target Val Label Accuracy: 0.06268429487179487
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
