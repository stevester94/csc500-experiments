[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1403.6529, train_label_loss: 2.7727, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 34825.5383, train_label_loss: 2.7725, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 34904.3366, train_label_loss: 2.7729, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 34992.6556, train_label_loss: 2.7729, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 34923.4944, train_label_loss: 2.7725, 
=============================================================
epoch: 1, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 22.4053, train_label_loss: 2.7725, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 34957.4349, train_label_loss: 2.7725, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 34922.4030, train_label_loss: 2.7727, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 34789.2814, train_label_loss: 2.7727, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 34741.4075, train_label_loss: 2.7728, 
=============================================================
epoch: 2, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 3, [batch: 1 / 11375], examples_per_second: 23.2178, train_label_loss: 2.7726, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 34745.0872, train_label_loss: 2.7727, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 34762.5940, train_label_loss: 2.7728, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 34755.4678, train_label_loss: 2.7726, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 34792.3530, train_label_loss: 2.7725, 
=============================================================
epoch: 3, val_acc_label: 0.0620, val_label_loss: 2.7726, 
=============================================================
epoch: 4, [batch: 1 / 11375], examples_per_second: 23.2248, train_label_loss: 2.7728, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 34764.3784, train_label_loss: 2.7730, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 34731.7017, train_label_loss: 2.7728, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 34756.2333, train_label_loss: 2.7726, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 34758.0938, train_label_loss: 2.7728, 
=============================================================
epoch: 4, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 5, [batch: 1 / 11375], examples_per_second: 23.2491, train_label_loss: 2.7726, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 34730.5628, train_label_loss: 2.7724, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 34735.0304, train_label_loss: 2.7725, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 34744.7351, train_label_loss: 2.7724, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 34738.6699, train_label_loss: 2.7727, 
=============================================================
epoch: 5, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 23.1972, train_label_loss: 2.7724, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 34721.9504, train_label_loss: 2.7726, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 34739.9628, train_label_loss: 2.7725, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 34750.1473, train_label_loss: 2.7726, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 34771.4970, train_label_loss: 2.7725, 
=============================================================
epoch: 6, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 7, [batch: 1 / 11375], examples_per_second: 22.8550, train_label_loss: 2.7729, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 34741.2643, train_label_loss: 2.7724, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 34741.1931, train_label_loss: 2.7720, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 34754.2633, train_label_loss: 2.7724, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 34721.7244, train_label_loss: 2.7725, 
=============================================================
epoch: 7, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 23.1980, train_label_loss: 2.7727, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 34747.8176, train_label_loss: 2.7727, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 34758.2298, train_label_loss: 2.7727, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 34726.4013, train_label_loss: 2.7726, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 34756.6438, train_label_loss: 2.7722, 
=============================================================
epoch: 8, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 9, [batch: 1 / 11375], examples_per_second: 23.1728, train_label_loss: 2.7729, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 34716.6620, train_label_loss: 2.7723, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 34744.1673, train_label_loss: 2.7725, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 34766.7233, train_label_loss: 2.7725, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 34752.3142, train_label_loss: 2.7726, 
=============================================================
epoch: 9, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 23.0597, train_label_loss: 2.7722, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 34773.0276, train_label_loss: 2.7728, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 34756.2778, train_label_loss: 2.7726, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 34769.6761, train_label_loss: 2.7725, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 34774.0402, train_label_loss: 2.7726, 
=============================================================
epoch: 10, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 11, [batch: 1 / 11375], examples_per_second: 23.1957, train_label_loss: 2.7729, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 34736.5205, train_label_loss: 2.7725, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 34758.0419, train_label_loss: 2.7722, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 34765.1365, train_label_loss: 2.7723, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 34777.1032, train_label_loss: 2.7724, 
=============================================================
epoch: 11, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 12, [batch: 1 / 11375], examples_per_second: 23.1930, train_label_loss: 2.7726, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 34744.9528, train_label_loss: 2.7727, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 34756.2432, train_label_loss: 2.7729, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 34738.8226, train_label_loss: 2.7724, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 34753.4939, train_label_loss: 2.7724, 
=============================================================
epoch: 12, val_acc_label: 0.0620, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.06236858974358974 Target Test Label Accuracy: 0.06236858974358974
Source Val Label Accuracy: 0.06268429487179487 Target Val Label Accuracy: 0.06268429487179487
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
