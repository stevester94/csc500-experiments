[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1824.2130, train_label_loss: 2.7727, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 34935.9139, train_label_loss: 2.7725, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 34901.8371, train_label_loss: 2.7729, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 34896.3431, train_label_loss: 2.7729, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 34913.6342, train_label_loss: 2.7725, 
=============================================================
epoch: 1, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 22.5691, train_label_loss: 2.7725, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 34905.5479, train_label_loss: 2.7724, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 34924.2259, train_label_loss: 2.7727, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 34919.7885, train_label_loss: 2.7727, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 34921.8932, train_label_loss: 2.7728, 
=============================================================
epoch: 2, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 3, [batch: 1 / 11375], examples_per_second: 23.2917, train_label_loss: 2.7726, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 34903.1075, train_label_loss: 2.7727, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 34919.4506, train_label_loss: 2.7728, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 34889.1988, train_label_loss: 2.7726, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 34941.8840, train_label_loss: 2.7725, 
=============================================================
epoch: 3, val_acc_label: 0.0620, val_label_loss: 2.7726, 
=============================================================
epoch: 4, [batch: 1 / 11375], examples_per_second: 23.3934, train_label_loss: 2.7728, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 34903.5635, train_label_loss: 2.7730, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 34916.5307, train_label_loss: 2.7728, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 34923.2457, train_label_loss: 2.7726, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 34909.5373, train_label_loss: 2.7728, 
=============================================================
epoch: 4, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 5, [batch: 1 / 11375], examples_per_second: 23.2798, train_label_loss: 2.7726, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 34902.1870, train_label_loss: 2.7724, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 34915.9842, train_label_loss: 2.7725, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 34905.4374, train_label_loss: 2.7724, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 34926.6836, train_label_loss: 2.7727, 
=============================================================
epoch: 5, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 22.9541, train_label_loss: 2.7724, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 34902.5208, train_label_loss: 2.7726, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 34906.2314, train_label_loss: 2.7725, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 34919.4566, train_label_loss: 2.7726, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 34924.9918, train_label_loss: 2.7725, 
=============================================================
epoch: 6, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 7, [batch: 1 / 11375], examples_per_second: 23.2549, train_label_loss: 2.7729, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 34906.1617, train_label_loss: 2.7724, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 34913.4939, train_label_loss: 2.7720, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 34896.6442, train_label_loss: 2.7724, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 34879.8819, train_label_loss: 2.7725, 
=============================================================
epoch: 7, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 23.2389, train_label_loss: 2.7727, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 34889.3425, train_label_loss: 2.7727, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 34914.8089, train_label_loss: 2.7727, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 34924.2174, train_label_loss: 2.7726, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 34908.4891, train_label_loss: 2.7722, 
=============================================================
epoch: 8, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 9, [batch: 1 / 11375], examples_per_second: 23.3088, train_label_loss: 2.7729, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 34928.5524, train_label_loss: 2.7723, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 34947.2253, train_label_loss: 2.7725, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 34913.9371, train_label_loss: 2.7725, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 34909.8940, train_label_loss: 2.7726, 
=============================================================
epoch: 9, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 23.3179, train_label_loss: 2.7722, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 34893.4345, train_label_loss: 2.7728, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 34930.8270, train_label_loss: 2.7726, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 34902.4859, train_label_loss: 2.7725, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 34885.7762, train_label_loss: 2.7726, 
=============================================================
epoch: 10, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 11, [batch: 1 / 11375], examples_per_second: 23.2116, train_label_loss: 2.7729, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 34887.5190, train_label_loss: 2.7725, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 34905.0498, train_label_loss: 2.7722, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 34935.5564, train_label_loss: 2.7723, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 34909.4824, train_label_loss: 2.7724, 
=============================================================
epoch: 11, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 12, [batch: 1 / 11375], examples_per_second: 23.1840, train_label_loss: 2.7726, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 34909.1810, train_label_loss: 2.7727, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 34913.2150, train_label_loss: 2.7729, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 34922.0021, train_label_loss: 2.7724, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 34906.0409, train_label_loss: 2.7724, 
=============================================================
epoch: 12, val_acc_label: 0.0620, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.06236858974358974 Target Test Label Accuracy: 0.06236858974358974
Source Val Label Accuracy: 0.06268429487179487 Target Val Label Accuracy: 0.06268429487179487
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
