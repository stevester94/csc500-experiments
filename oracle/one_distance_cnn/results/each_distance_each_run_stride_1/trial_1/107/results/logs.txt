[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1492.7999, train_label_loss: 2.7725, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 34914.0664, train_label_loss: 2.7728, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 34969.3741, train_label_loss: 2.7727, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 34863.6611, train_label_loss: 2.7725, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 34861.2814, train_label_loss: 2.7725, 
=============================================================
epoch: 1, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 22.4289, train_label_loss: 2.7727, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 34833.2753, train_label_loss: 2.7726, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 34730.4049, train_label_loss: 2.7723, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 34701.2970, train_label_loss: 2.7723, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 34672.5085, train_label_loss: 2.7729, 
=============================================================
epoch: 2, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 3, [batch: 1 / 11375], examples_per_second: 23.1551, train_label_loss: 2.7727, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 34703.6918, train_label_loss: 2.7727, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 34684.3652, train_label_loss: 2.7724, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 34705.5887, train_label_loss: 2.7727, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 34707.9586, train_label_loss: 2.7726, 
=============================================================
epoch: 3, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 4, [batch: 1 / 11375], examples_per_second: 23.1098, train_label_loss: 2.7724, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 34678.7211, train_label_loss: 2.7728, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 34701.8368, train_label_loss: 2.7727, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 34712.8543, train_label_loss: 2.7726, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 34632.2200, train_label_loss: 2.7724, 
=============================================================
epoch: 4, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 5, [batch: 1 / 11375], examples_per_second: 23.0598, train_label_loss: 2.7725, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 34662.0962, train_label_loss: 2.7730, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 34655.9426, train_label_loss: 2.7726, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 34656.8640, train_label_loss: 2.7728, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 34679.3058, train_label_loss: 2.7727, 
=============================================================
epoch: 5, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 22.7566, train_label_loss: 2.7728, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 34678.2537, train_label_loss: 2.7725, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 34640.2801, train_label_loss: 2.7726, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 34684.7907, train_label_loss: 2.7729, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 34666.2230, train_label_loss: 2.7724, 
=============================================================
epoch: 6, val_acc_label: 0.0630, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 7, [batch: 1 / 11375], examples_per_second: 23.0700, train_label_loss: 2.7726, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 34656.4680, train_label_loss: 2.7725, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 34687.7538, train_label_loss: 2.7726, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 34702.8247, train_label_loss: 2.7727, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 34686.4830, train_label_loss: 2.7728, 
=============================================================
epoch: 7, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 23.0818, train_label_loss: 2.7725, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 34691.5534, train_label_loss: 2.7726, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 34699.0251, train_label_loss: 2.7729, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 34700.5482, train_label_loss: 2.7725, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 34702.1375, train_label_loss: 2.7724, 
=============================================================
epoch: 8, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 9, [batch: 1 / 11375], examples_per_second: 23.0443, train_label_loss: 2.7723, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 34674.8355, train_label_loss: 2.7726, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 34699.3637, train_label_loss: 2.7725, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 34695.4214, train_label_loss: 2.7726, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 34702.8242, train_label_loss: 2.7724, 
=============================================================
epoch: 9, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 23.1562, train_label_loss: 2.7726, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 34703.8645, train_label_loss: 2.7723, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 34676.9383, train_label_loss: 2.7725, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 34683.0780, train_label_loss: 2.7724, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 34670.1592, train_label_loss: 2.7725, 
=============================================================
epoch: 10, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 11, [batch: 1 / 11375], examples_per_second: 23.1632, train_label_loss: 2.7724, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 34682.4204, train_label_loss: 2.7729, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 34660.3298, train_label_loss: 2.7723, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 34672.7255, train_label_loss: 2.7726, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 34677.6703, train_label_loss: 2.7728, 
=============================================================
epoch: 11, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 12, [batch: 1 / 11375], examples_per_second: 23.1405, train_label_loss: 2.7727, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 34670.0419, train_label_loss: 2.7727, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 34687.5730, train_label_loss: 2.7730, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 34685.5645, train_label_loss: 2.7727, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 34670.1902, train_label_loss: 2.7729, 
=============================================================
epoch: 12, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 13, [batch: 1 / 11375], examples_per_second: 23.0579, train_label_loss: 2.7723, 
epoch: 13, [batch: 2275 / 11375], examples_per_second: 34672.4085, train_label_loss: 2.7725, 
epoch: 13, [batch: 4550 / 11375], examples_per_second: 34683.1385, train_label_loss: 2.7722, 
epoch: 13, [batch: 6825 / 11375], examples_per_second: 34679.6381, train_label_loss: 2.7726, 
epoch: 13, [batch: 9100 / 11375], examples_per_second: 34677.5054, train_label_loss: 2.7728, 
=============================================================
epoch: 13, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 14, [batch: 1 / 11375], examples_per_second: 23.1126, train_label_loss: 2.7731, 
epoch: 14, [batch: 2275 / 11375], examples_per_second: 34686.4798, train_label_loss: 2.7728, 
epoch: 14, [batch: 4550 / 11375], examples_per_second: 34673.2216, train_label_loss: 2.7726, 
epoch: 14, [batch: 6825 / 11375], examples_per_second: 34675.0087, train_label_loss: 2.7727, 
epoch: 14, [batch: 9100 / 11375], examples_per_second: 34693.7554, train_label_loss: 2.7726, 
=============================================================
epoch: 14, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 15, [batch: 1 / 11375], examples_per_second: 23.1293, train_label_loss: 2.7725, 
epoch: 15, [batch: 2275 / 11375], examples_per_second: 34670.9098, train_label_loss: 2.7726, 
epoch: 15, [batch: 4550 / 11375], examples_per_second: 34677.1657, train_label_loss: 2.7729, 
epoch: 15, [batch: 6825 / 11375], examples_per_second: 34676.7508, train_label_loss: 2.7727, 
epoch: 15, [batch: 9100 / 11375], examples_per_second: 34679.3220, train_label_loss: 2.7722, 
=============================================================
epoch: 15, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 16, [batch: 1 / 11375], examples_per_second: 23.0743, train_label_loss: 2.7726, 
epoch: 16, [batch: 2275 / 11375], examples_per_second: 34683.4052, train_label_loss: 2.7728, 
epoch: 16, [batch: 4550 / 11375], examples_per_second: 34691.2051, train_label_loss: 2.7727, 
epoch: 16, [batch: 6825 / 11375], examples_per_second: 34689.9390, train_label_loss: 2.7723, 
epoch: 16, [batch: 9100 / 11375], examples_per_second: 34706.7026, train_label_loss: 2.7726, 
=============================================================
epoch: 16, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 17, [batch: 1 / 11375], examples_per_second: 23.1240, train_label_loss: 2.7726, 
epoch: 17, [batch: 2275 / 11375], examples_per_second: 34661.2593, train_label_loss: 2.7728, 
epoch: 17, [batch: 4550 / 11375], examples_per_second: 34682.6422, train_label_loss: 2.7724, 
epoch: 17, [batch: 6825 / 11375], examples_per_second: 34674.4717, train_label_loss: 2.7725, 
epoch: 17, [batch: 9100 / 11375], examples_per_second: 34691.4963, train_label_loss: 2.7728, 
=============================================================
epoch: 17, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 18, [batch: 1 / 11375], examples_per_second: 22.8023, train_label_loss: 2.7728, 
epoch: 18, [batch: 2275 / 11375], examples_per_second: 34685.8924, train_label_loss: 2.7725, 
epoch: 18, [batch: 4550 / 11375], examples_per_second: 34642.8484, train_label_loss: 2.7726, 
epoch: 18, [batch: 6825 / 11375], examples_per_second: 34685.1266, train_label_loss: 2.7725, 
epoch: 18, [batch: 9100 / 11375], examples_per_second: 34675.5216, train_label_loss: 2.7726, 
=============================================================
epoch: 18, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 19, [batch: 1 / 11375], examples_per_second: 23.1043, train_label_loss: 2.7725, 
epoch: 19, [batch: 2275 / 11375], examples_per_second: 34653.9132, train_label_loss: 2.7727, 
epoch: 19, [batch: 4550 / 11375], examples_per_second: 34679.5327, train_label_loss: 2.7727, 
epoch: 19, [batch: 6825 / 11375], examples_per_second: 34689.3351, train_label_loss: 2.7727, 
epoch: 19, [batch: 9100 / 11375], examples_per_second: 34698.4538, train_label_loss: 2.7729, 
=============================================================
epoch: 19, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 20, [batch: 1 / 11375], examples_per_second: 23.1174, train_label_loss: 2.7728, 
epoch: 20, [batch: 2275 / 11375], examples_per_second: 34672.4759, train_label_loss: 2.7727, 
epoch: 20, [batch: 4550 / 11375], examples_per_second: 34668.2810, train_label_loss: 2.7730, 
epoch: 20, [batch: 6825 / 11375], examples_per_second: 34667.7659, train_label_loss: 2.7729, 
epoch: 20, [batch: 9100 / 11375], examples_per_second: 34669.0132, train_label_loss: 2.7726, 
=============================================================
epoch: 20, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 21, [batch: 1 / 11375], examples_per_second: 23.0953, train_label_loss: 2.7727, 
epoch: 21, [batch: 2275 / 11375], examples_per_second: 34683.9240, train_label_loss: 2.7725, 
epoch: 21, [batch: 4550 / 11375], examples_per_second: 34677.3494, train_label_loss: 2.7727, 
epoch: 21, [batch: 6825 / 11375], examples_per_second: 34685.2192, train_label_loss: 2.7728, 
epoch: 21, [batch: 9100 / 11375], examples_per_second: 34673.2083, train_label_loss: 2.7726, 
=============================================================
epoch: 21, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 22, [batch: 1 / 11375], examples_per_second: 23.1482, train_label_loss: 2.7729, 
epoch: 22, [batch: 2275 / 11375], examples_per_second: 34687.4096, train_label_loss: 2.7730, 
epoch: 22, [batch: 4550 / 11375], examples_per_second: 34688.7129, train_label_loss: 2.7726, 
epoch: 22, [batch: 6825 / 11375], examples_per_second: 34663.3069, train_label_loss: 2.7726, 
epoch: 22, [batch: 9100 / 11375], examples_per_second: 34662.7191, train_label_loss: 2.7725, 
=============================================================
epoch: 22, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.06275320512820513 Target Test Label Accuracy: 0.06275320512820513
Source Val Label Accuracy: 0.062301282051282054 Target Val Label Accuracy: 0.062301282051282054
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
