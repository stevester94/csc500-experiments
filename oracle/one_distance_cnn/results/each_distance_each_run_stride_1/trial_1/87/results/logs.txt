[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1822.8086, train_label_loss: 2.7726, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 34870.2491, train_label_loss: 2.7725, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 34929.5179, train_label_loss: 2.7725, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 34941.2157, train_label_loss: 2.7727, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 34928.0765, train_label_loss: 2.7728, 
=============================================================
epoch: 1, val_acc_label: 0.0619, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 22.6411, train_label_loss: 2.7723, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 34954.8396, train_label_loss: 2.7725, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 34933.8348, train_label_loss: 2.7723, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 34796.2901, train_label_loss: 2.7723, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 34756.1616, train_label_loss: 2.7728, 
=============================================================
epoch: 2, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 3, [batch: 1 / 11375], examples_per_second: 23.2317, train_label_loss: 2.7726, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 34711.7834, train_label_loss: 2.7728, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 34745.5871, train_label_loss: 2.7727, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 34772.5800, train_label_loss: 2.7728, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 34769.3891, train_label_loss: 2.7725, 
=============================================================
epoch: 3, val_acc_label: 0.0619, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 4, [batch: 1 / 11375], examples_per_second: 23.1293, train_label_loss: 2.7725, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 34729.0423, train_label_loss: 2.7726, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 34756.6804, train_label_loss: 2.7726, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 34757.9123, train_label_loss: 2.7726, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 34743.2012, train_label_loss: 2.7725, 
=============================================================
epoch: 4, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 5, [batch: 1 / 11375], examples_per_second: 23.1986, train_label_loss: 2.7724, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 34759.7307, train_label_loss: 2.7724, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 34752.6336, train_label_loss: 2.7725, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 34751.9014, train_label_loss: 2.7724, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 34771.5113, train_label_loss: 2.7724, 
=============================================================
epoch: 5, val_acc_label: 0.0619, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 23.2072, train_label_loss: 2.7727, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 34762.5030, train_label_loss: 2.7724, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 34740.8660, train_label_loss: 2.7727, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 34759.3966, train_label_loss: 2.7726, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 34764.4715, train_label_loss: 2.7725, 
=============================================================
epoch: 6, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 7, [batch: 1 / 11375], examples_per_second: 22.9065, train_label_loss: 2.7726, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 34746.8307, train_label_loss: 2.7726, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 34741.6294, train_label_loss: 2.7728, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 34752.5817, train_label_loss: 2.7727, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 34765.2077, train_label_loss: 2.7727, 
=============================================================
epoch: 7, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 23.2334, train_label_loss: 2.7728, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 34768.9708, train_label_loss: 2.7727, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 34740.4322, train_label_loss: 2.7728, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 34723.5185, train_label_loss: 2.7728, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 34756.1755, train_label_loss: 2.7725, 
=============================================================
epoch: 8, val_acc_label: 0.0628, val_label_loss: 2.7726, 
=============================================================
epoch: 9, [batch: 1 / 11375], examples_per_second: 23.1802, train_label_loss: 2.7726, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 34754.1835, train_label_loss: 2.7722, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 34749.9155, train_label_loss: 2.7725, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 34729.0500, train_label_loss: 2.7725, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 34739.6165, train_label_loss: 2.7725, 
=============================================================
epoch: 9, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 23.1681, train_label_loss: 2.7727, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 34751.4422, train_label_loss: 2.7726, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 34749.2907, train_label_loss: 2.7728, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 34743.4700, train_label_loss: 2.7723, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 34748.8650, train_label_loss: 2.7723, 
=============================================================
epoch: 10, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 11, [batch: 1 / 11375], examples_per_second: 23.2850, train_label_loss: 2.7727, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 34734.9304, train_label_loss: 2.7725, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 34744.0047, train_label_loss: 2.7727, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 34753.4084, train_label_loss: 2.7722, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 34753.5270, train_label_loss: 2.7728, 
=============================================================
epoch: 11, val_acc_label: 0.0629, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 12, [batch: 1 / 11375], examples_per_second: 23.1135, train_label_loss: 2.7726, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 34745.4081, train_label_loss: 2.7727, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 34722.8161, train_label_loss: 2.7727, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 34750.6293, train_label_loss: 2.7725, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 34780.3936, train_label_loss: 2.7722, 
=============================================================
epoch: 12, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 13, [batch: 1 / 11375], examples_per_second: 23.2571, train_label_loss: 2.7728, 
epoch: 13, [batch: 2275 / 11375], examples_per_second: 34733.9940, train_label_loss: 2.7731, 
epoch: 13, [batch: 4550 / 11375], examples_per_second: 34747.5913, train_label_loss: 2.7728, 
epoch: 13, [batch: 6825 / 11375], examples_per_second: 34767.5492, train_label_loss: 2.7726, 
epoch: 13, [batch: 9100 / 11375], examples_per_second: 34746.8182, train_label_loss: 2.7725, 
=============================================================
epoch: 13, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 14, [batch: 1 / 11375], examples_per_second: 23.1130, train_label_loss: 2.7724, 
epoch: 14, [batch: 2275 / 11375], examples_per_second: 34741.1259, train_label_loss: 2.7725, 
epoch: 14, [batch: 4550 / 11375], examples_per_second: 34743.6261, train_label_loss: 2.7725, 
epoch: 14, [batch: 6825 / 11375], examples_per_second: 34783.6296, train_label_loss: 2.7726, 
epoch: 14, [batch: 9100 / 11375], examples_per_second: 34770.6655, train_label_loss: 2.7727, 
=============================================================
epoch: 14, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 15, [batch: 1 / 11375], examples_per_second: 23.2127, train_label_loss: 2.7727, 
epoch: 15, [batch: 2275 / 11375], examples_per_second: 34720.7452, train_label_loss: 2.7724, 
epoch: 15, [batch: 4550 / 11375], examples_per_second: 34737.4799, train_label_loss: 2.7726, 
epoch: 15, [batch: 6825 / 11375], examples_per_second: 34746.2528, train_label_loss: 2.7727, 
epoch: 15, [batch: 9100 / 11375], examples_per_second: 34764.5611, train_label_loss: 2.7726, 
=============================================================
epoch: 15, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 16, [batch: 1 / 11375], examples_per_second: 23.2375, train_label_loss: 2.7728, 
epoch: 16, [batch: 2275 / 11375], examples_per_second: 34748.9966, train_label_loss: 2.7728, 
epoch: 16, [batch: 4550 / 11375], examples_per_second: 34770.2062, train_label_loss: 2.7727, 
epoch: 16, [batch: 6825 / 11375], examples_per_second: 34743.5718, train_label_loss: 2.7727, 
epoch: 16, [batch: 9100 / 11375], examples_per_second: 34742.9185, train_label_loss: 2.7725, 
=============================================================
epoch: 16, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 17, [batch: 1 / 11375], examples_per_second: 23.1855, train_label_loss: 2.7725, 
epoch: 17, [batch: 2275 / 11375], examples_per_second: 34729.9680, train_label_loss: 2.7727, 
epoch: 17, [batch: 4550 / 11375], examples_per_second: 34739.5182, train_label_loss: 2.7726, 
epoch: 17, [batch: 6825 / 11375], examples_per_second: 34757.5379, train_label_loss: 2.7729, 
epoch: 17, [batch: 9100 / 11375], examples_per_second: 34751.9740, train_label_loss: 2.7725, 
=============================================================
epoch: 17, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 18, [batch: 1 / 11375], examples_per_second: 23.1360, train_label_loss: 2.7726, 
epoch: 18, [batch: 2275 / 11375], examples_per_second: 34756.2890, train_label_loss: 2.7722, 
epoch: 18, [batch: 4550 / 11375], examples_per_second: 34776.3472, train_label_loss: 2.7726, 
epoch: 18, [batch: 6825 / 11375], examples_per_second: 34749.0005, train_label_loss: 2.7730, 
epoch: 18, [batch: 9100 / 11375], examples_per_second: 34756.1384, train_label_loss: 2.7729, 
=============================================================
epoch: 18, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 19, [batch: 1 / 11375], examples_per_second: 23.2204, train_label_loss: 2.7725, 
epoch: 19, [batch: 2275 / 11375], examples_per_second: 34745.3275, train_label_loss: 2.7727, 
epoch: 19, [batch: 4550 / 11375], examples_per_second: 34744.5503, train_label_loss: 2.7725, 
epoch: 19, [batch: 6825 / 11375], examples_per_second: 34748.5482, train_label_loss: 2.7725, 
epoch: 19, [batch: 9100 / 11375], examples_per_second: 34762.7073, train_label_loss: 2.7725, 
=============================================================
epoch: 19, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 20, [batch: 1 / 11375], examples_per_second: 22.8426, train_label_loss: 2.7725, 
epoch: 20, [batch: 2275 / 11375], examples_per_second: 34721.2488, train_label_loss: 2.7726, 
epoch: 20, [batch: 4550 / 11375], examples_per_second: 34744.6348, train_label_loss: 2.7725, 
epoch: 20, [batch: 6825 / 11375], examples_per_second: 34749.4533, train_label_loss: 2.7724, 
epoch: 20, [batch: 9100 / 11375], examples_per_second: 34749.7870, train_label_loss: 2.7726, 
=============================================================
epoch: 20, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 21, [batch: 1 / 11375], examples_per_second: 23.1390, train_label_loss: 2.7727, 
epoch: 21, [batch: 2275 / 11375], examples_per_second: 34740.3469, train_label_loss: 2.7730, 
epoch: 21, [batch: 4550 / 11375], examples_per_second: 34741.3443, train_label_loss: 2.7726, 
epoch: 21, [batch: 6825 / 11375], examples_per_second: 34745.4823, train_label_loss: 2.7726, 
epoch: 21, [batch: 9100 / 11375], examples_per_second: 34747.9719, train_label_loss: 2.7726, 
=============================================================
epoch: 21, val_acc_label: 0.0619, val_label_loss: 2.7726, 
=============================================================
epoch: 22, [batch: 1 / 11375], examples_per_second: 23.2470, train_label_loss: 2.7726, 
epoch: 22, [batch: 2275 / 11375], examples_per_second: 34749.1528, train_label_loss: 2.7727, 
epoch: 22, [batch: 4550 / 11375], examples_per_second: 34758.6710, train_label_loss: 2.7724, 
epoch: 22, [batch: 6825 / 11375], examples_per_second: 34747.3323, train_label_loss: 2.7724, 
epoch: 22, [batch: 9100 / 11375], examples_per_second: 34739.1921, train_label_loss: 2.7730, 
=============================================================
epoch: 22, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.06253205128205128 Target Test Label Accuracy: 0.06253205128205128
Source Val Label Accuracy: 0.06289262820512821 Target Val Label Accuracy: 0.06289262820512821
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
