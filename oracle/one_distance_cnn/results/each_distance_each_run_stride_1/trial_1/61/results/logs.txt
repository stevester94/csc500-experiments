[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1310.4752, train_label_loss: 2.7726, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 23032.6008, train_label_loss: 2.7725, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 23073.2306, train_label_loss: 2.7724, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 23100.2215, train_label_loss: 2.7727, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 23122.1057, train_label_loss: 2.7726, 
=============================================================
epoch: 1, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 16.3126, train_label_loss: 2.7726, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 23089.6099, train_label_loss: 2.7726, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 23095.3544, train_label_loss: 2.7727, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 23077.8654, train_label_loss: 2.7727, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 23057.2900, train_label_loss: 2.7727, 
=============================================================
epoch: 2, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 3, [batch: 1 / 11375], examples_per_second: 16.7385, train_label_loss: 2.7726, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 23068.4949, train_label_loss: 2.7727, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 23082.5801, train_label_loss: 2.7727, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 23128.7946, train_label_loss: 2.7725, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 23097.7895, train_label_loss: 2.7729, 
=============================================================
epoch: 3, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 4, [batch: 1 / 11375], examples_per_second: 16.7480, train_label_loss: 2.7725, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 23072.9979, train_label_loss: 2.7724, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 23091.1493, train_label_loss: 2.7726, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 23101.9078, train_label_loss: 2.7724, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 23096.0881, train_label_loss: 2.7729, 
=============================================================
epoch: 4, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 5, [batch: 1 / 11375], examples_per_second: 16.7693, train_label_loss: 2.7726, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 23062.4764, train_label_loss: 2.7725, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 23074.2842, train_label_loss: 2.7726, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 23084.8123, train_label_loss: 2.7723, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 23082.9171, train_label_loss: 2.7729, 
=============================================================
epoch: 5, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 16.7255, train_label_loss: 2.7727, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 23094.4608, train_label_loss: 2.7724, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 23104.3621, train_label_loss: 2.7723, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 23076.7875, train_label_loss: 2.7729, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 23100.5454, train_label_loss: 2.7722, 
=============================================================
epoch: 6, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 7, [batch: 1 / 11375], examples_per_second: 16.5507, train_label_loss: 2.7727, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 23104.0862, train_label_loss: 2.7729, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 23075.9813, train_label_loss: 2.7728, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 23069.5382, train_label_loss: 2.7726, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 23075.1253, train_label_loss: 2.7727, 
=============================================================
epoch: 7, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 16.7782, train_label_loss: 2.7723, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 23090.4815, train_label_loss: 2.7727, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 23093.0832, train_label_loss: 2.7725, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 23090.8016, train_label_loss: 2.7728, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 23106.0145, train_label_loss: 2.7723, 
=============================================================
epoch: 8, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 9, [batch: 1 / 11375], examples_per_second: 16.7416, train_label_loss: 2.7729, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 23043.6237, train_label_loss: 2.7725, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 23071.5805, train_label_loss: 2.7726, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 23099.4917, train_label_loss: 2.7724, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 23095.5229, train_label_loss: 2.7726, 
=============================================================
epoch: 9, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 16.7424, train_label_loss: 2.7725, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 23083.4097, train_label_loss: 2.7724, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 23090.1152, train_label_loss: 2.7723, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 23070.8416, train_label_loss: 2.7726, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 23074.0577, train_label_loss: 2.7726, 
=============================================================
epoch: 10, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 11, [batch: 1 / 11375], examples_per_second: 16.7192, train_label_loss: 2.7729, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 23115.6570, train_label_loss: 2.7728, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 23113.0396, train_label_loss: 2.7725, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 23085.6902, train_label_loss: 2.7725, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 23119.7477, train_label_loss: 2.7727, 
=============================================================
epoch: 11, val_acc_label: 0.0620, val_label_loss: 2.7726, 
=============================================================
epoch: 12, [batch: 1 / 11375], examples_per_second: 16.7051, train_label_loss: 2.7725, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 23075.4853, train_label_loss: 2.7724, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 23083.2685, train_label_loss: 2.7724, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 23072.3938, train_label_loss: 2.7730, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 23079.8082, train_label_loss: 2.7725, 
=============================================================
epoch: 12, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.062400641025641024 Target Test Label Accuracy: 0.062400641025641024
Source Val Label Accuracy: 0.0625801282051282 Target Val Label Accuracy: 0.0625801282051282
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
