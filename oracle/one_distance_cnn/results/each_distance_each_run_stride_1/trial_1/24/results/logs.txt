[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1727.2783, train_label_loss: 2.7726, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 23137.8318, train_label_loss: 2.7725, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 23149.8229, train_label_loss: 2.7724, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 23043.3587, train_label_loss: 2.7728, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 23056.1216, train_label_loss: 2.7726, 
=============================================================
epoch: 1, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 16.3474, train_label_loss: 2.7726, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 23069.4099, train_label_loss: 2.7726, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 23069.7067, train_label_loss: 2.7727, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 23067.0550, train_label_loss: 2.7727, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 23075.1247, train_label_loss: 2.7726, 
=============================================================
epoch: 2, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 3, [batch: 1 / 11375], examples_per_second: 16.7171, train_label_loss: 2.7727, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 23084.8418, train_label_loss: 2.7726, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 23051.0864, train_label_loss: 2.7726, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 23063.5506, train_label_loss: 2.7725, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 23074.1661, train_label_loss: 2.7729, 
=============================================================
epoch: 3, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 4, [batch: 1 / 11375], examples_per_second: 16.7225, train_label_loss: 2.7725, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 23060.2151, train_label_loss: 2.7724, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 23061.9576, train_label_loss: 2.7726, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 23063.4591, train_label_loss: 2.7725, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 23062.7656, train_label_loss: 2.7730, 
=============================================================
epoch: 4, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 5, [batch: 1 / 11375], examples_per_second: 16.7315, train_label_loss: 2.7726, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 23037.4334, train_label_loss: 2.7725, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 23055.3129, train_label_loss: 2.7726, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 23034.1474, train_label_loss: 2.7723, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 23035.0173, train_label_loss: 2.7729, 
=============================================================
epoch: 5, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 16.7363, train_label_loss: 2.7727, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 23063.8467, train_label_loss: 2.7724, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 23052.3927, train_label_loss: 2.7723, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 23050.8737, train_label_loss: 2.7729, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 23050.5402, train_label_loss: 2.7722, 
=============================================================
epoch: 6, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 7, [batch: 1 / 11375], examples_per_second: 16.5312, train_label_loss: 2.7727, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 23061.0732, train_label_loss: 2.7729, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 23071.2560, train_label_loss: 2.7728, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 23060.2470, train_label_loss: 2.7726, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 23073.1288, train_label_loss: 2.7727, 
=============================================================
epoch: 7, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 16.7419, train_label_loss: 2.7723, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 23076.9303, train_label_loss: 2.7727, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 23052.8917, train_label_loss: 2.7725, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 23056.5688, train_label_loss: 2.7728, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 23051.2001, train_label_loss: 2.7723, 
=============================================================
epoch: 8, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 9, [batch: 1 / 11375], examples_per_second: 16.7178, train_label_loss: 2.7729, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 23057.1295, train_label_loss: 2.7725, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 23045.2805, train_label_loss: 2.7726, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 23050.8040, train_label_loss: 2.7724, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 23088.6972, train_label_loss: 2.7726, 
=============================================================
epoch: 9, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 16.7394, train_label_loss: 2.7725, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 23066.0956, train_label_loss: 2.7724, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 23033.6826, train_label_loss: 2.7723, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 23042.0971, train_label_loss: 2.7726, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 23051.9563, train_label_loss: 2.7726, 
=============================================================
epoch: 10, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 11, [batch: 1 / 11375], examples_per_second: 16.7582, train_label_loss: 2.7729, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 23052.7173, train_label_loss: 2.7728, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 23065.1638, train_label_loss: 2.7725, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 23063.2995, train_label_loss: 2.7725, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 23068.2084, train_label_loss: 2.7727, 
=============================================================
epoch: 11, val_acc_label: 0.0620, val_label_loss: 2.7726, 
=============================================================
epoch: 12, [batch: 1 / 11375], examples_per_second: 16.7632, train_label_loss: 2.7725, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 23067.7043, train_label_loss: 2.7724, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 23100.5732, train_label_loss: 2.7724, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 23072.9155, train_label_loss: 2.7730, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 23049.8583, train_label_loss: 2.7725, 
=============================================================
epoch: 12, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.062400641025641024 Target Test Label Accuracy: 0.062400641025641024
Source Val Label Accuracy: 0.0625801282051282 Target Val Label Accuracy: 0.0625801282051282
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
