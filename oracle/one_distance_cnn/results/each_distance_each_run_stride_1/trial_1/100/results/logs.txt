[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1299.3829, train_label_loss: 2.7725, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 34990.1926, train_label_loss: 2.7725, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 34984.6927, train_label_loss: 2.7724, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 34904.9142, train_label_loss: 2.7728, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 34880.6808, train_label_loss: 2.7724, 
=============================================================
epoch: 1, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 22.4065, train_label_loss: 2.7725, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 34867.3087, train_label_loss: 2.7730, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 34719.5076, train_label_loss: 2.7728, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 34677.5955, train_label_loss: 2.7724, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 34679.9429, train_label_loss: 2.7728, 
=============================================================
epoch: 2, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 3, [batch: 1 / 11375], examples_per_second: 23.1544, train_label_loss: 2.7730, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 34687.7472, train_label_loss: 2.7725, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 34668.0591, train_label_loss: 2.7726, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 34688.5395, train_label_loss: 2.7725, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 34584.9509, train_label_loss: 2.7728, 
=============================================================
epoch: 3, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 4, [batch: 1 / 11375], examples_per_second: 23.0423, train_label_loss: 2.7724, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 34654.1237, train_label_loss: 2.7727, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 34688.4434, train_label_loss: 2.7725, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 34718.3262, train_label_loss: 2.7727, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 34685.2424, train_label_loss: 2.7725, 
=============================================================
epoch: 4, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 5, [batch: 1 / 11375], examples_per_second: 23.1478, train_label_loss: 2.7727, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 34685.9412, train_label_loss: 2.7725, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 34687.8981, train_label_loss: 2.7728, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 34680.8414, train_label_loss: 2.7728, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 34692.1072, train_label_loss: 2.7730, 
=============================================================
epoch: 5, val_acc_label: 0.0628, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 23.1265, train_label_loss: 2.7725, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 34641.5727, train_label_loss: 2.7724, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 34663.6753, train_label_loss: 2.7723, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 34709.3040, train_label_loss: 2.7726, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 34691.0228, train_label_loss: 2.7728, 
=============================================================
epoch: 6, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 7, [batch: 1 / 11375], examples_per_second: 22.8637, train_label_loss: 2.7723, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 34686.7380, train_label_loss: 2.7722, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 34684.2815, train_label_loss: 2.7725, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 34656.7558, train_label_loss: 2.7726, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 34685.4906, train_label_loss: 2.7726, 
=============================================================
epoch: 7, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 23.1231, train_label_loss: 2.7727, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 34683.5348, train_label_loss: 2.7725, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 34669.3468, train_label_loss: 2.7725, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 34676.7143, train_label_loss: 2.7728, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 34684.8700, train_label_loss: 2.7723, 
=============================================================
epoch: 8, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 9, [batch: 1 / 11375], examples_per_second: 23.1331, train_label_loss: 2.7728, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 34689.9821, train_label_loss: 2.7729, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 34670.6424, train_label_loss: 2.7726, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 34694.4847, train_label_loss: 2.7727, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 34676.2319, train_label_loss: 2.7726, 
=============================================================
epoch: 9, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 23.0733, train_label_loss: 2.7726, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 34655.4901, train_label_loss: 2.7725, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 34682.7155, train_label_loss: 2.7730, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 34691.7072, train_label_loss: 2.7726, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 34696.6022, train_label_loss: 2.7727, 
=============================================================
epoch: 10, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 11, [batch: 1 / 11375], examples_per_second: 23.0637, train_label_loss: 2.7727, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 34673.9644, train_label_loss: 2.7725, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 34673.2423, train_label_loss: 2.7728, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 34683.2134, train_label_loss: 2.7724, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 34684.0146, train_label_loss: 2.7725, 
=============================================================
epoch: 11, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 12, [batch: 1 / 11375], examples_per_second: 23.0007, train_label_loss: 2.7728, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 34663.2005, train_label_loss: 2.7726, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 34681.6081, train_label_loss: 2.7726, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 34680.4421, train_label_loss: 2.7727, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 34668.0606, train_label_loss: 2.7723, 
=============================================================
epoch: 12, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 13, [batch: 1 / 11375], examples_per_second: 23.1261, train_label_loss: 2.7726, 
epoch: 13, [batch: 2275 / 11375], examples_per_second: 34654.8305, train_label_loss: 2.7724, 
epoch: 13, [batch: 4550 / 11375], examples_per_second: 34674.0849, train_label_loss: 2.7726, 
epoch: 13, [batch: 6825 / 11375], examples_per_second: 34689.7237, train_label_loss: 2.7723, 
epoch: 13, [batch: 9100 / 11375], examples_per_second: 34672.9179, train_label_loss: 2.7726, 
=============================================================
epoch: 13, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 14, [batch: 1 / 11375], examples_per_second: 23.0500, train_label_loss: 2.7728, 
epoch: 14, [batch: 2275 / 11375], examples_per_second: 34674.8468, train_label_loss: 2.7725, 
epoch: 14, [batch: 4550 / 11375], examples_per_second: 34675.8573, train_label_loss: 2.7727, 
epoch: 14, [batch: 6825 / 11375], examples_per_second: 34690.9849, train_label_loss: 2.7727, 
epoch: 14, [batch: 9100 / 11375], examples_per_second: 34681.5042, train_label_loss: 2.7727, 
=============================================================
epoch: 14, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 15, [batch: 1 / 11375], examples_per_second: 22.9968, train_label_loss: 2.7723, 
epoch: 15, [batch: 2275 / 11375], examples_per_second: 34685.9703, train_label_loss: 2.7724, 
epoch: 15, [batch: 4550 / 11375], examples_per_second: 34689.3769, train_label_loss: 2.7729, 
epoch: 15, [batch: 6825 / 11375], examples_per_second: 34677.8283, train_label_loss: 2.7725, 
epoch: 15, [batch: 9100 / 11375], examples_per_second: 34677.1564, train_label_loss: 2.7724, 
=============================================================
epoch: 15, val_acc_label: 0.0628, val_label_loss: 2.7726, 
=============================================================
epoch: 16, [batch: 1 / 11375], examples_per_second: 23.0552, train_label_loss: 2.7726, 
epoch: 16, [batch: 2275 / 11375], examples_per_second: 34642.6540, train_label_loss: 2.7727, 
epoch: 16, [batch: 4550 / 11375], examples_per_second: 34673.5184, train_label_loss: 2.7726, 
epoch: 16, [batch: 6825 / 11375], examples_per_second: 34706.9033, train_label_loss: 2.7725, 
epoch: 16, [batch: 9100 / 11375], examples_per_second: 34657.9492, train_label_loss: 2.7724, 
=============================================================
epoch: 16, val_acc_label: 0.0627, val_label_loss: 2.7726, 
=============================================================
epoch: 17, [batch: 1 / 11375], examples_per_second: 23.0555, train_label_loss: 2.7726, 
epoch: 17, [batch: 2275 / 11375], examples_per_second: 34679.1082, train_label_loss: 2.7730, 
epoch: 17, [batch: 4550 / 11375], examples_per_second: 34668.3110, train_label_loss: 2.7719, 
epoch: 17, [batch: 6825 / 11375], examples_per_second: 34653.9740, train_label_loss: 2.7723, 
epoch: 17, [batch: 9100 / 11375], examples_per_second: 34659.5144, train_label_loss: 2.7727, 
=============================================================
epoch: 17, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 18, [batch: 1 / 11375], examples_per_second: 23.0282, train_label_loss: 2.7726, 
epoch: 18, [batch: 2275 / 11375], examples_per_second: 34666.8251, train_label_loss: 2.7725, 
epoch: 18, [batch: 4550 / 11375], examples_per_second: 34666.6963, train_label_loss: 2.7724, 
epoch: 18, [batch: 6825 / 11375], examples_per_second: 34670.9987, train_label_loss: 2.7726, 
epoch: 18, [batch: 9100 / 11375], examples_per_second: 34676.8861, train_label_loss: 2.7725, 
=============================================================
epoch: 18, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 19, [batch: 1 / 11375], examples_per_second: 23.1433, train_label_loss: 2.7726, 
epoch: 19, [batch: 2275 / 11375], examples_per_second: 34657.4262, train_label_loss: 2.7724, 
epoch: 19, [batch: 4550 / 11375], examples_per_second: 34665.0650, train_label_loss: 2.7727, 
epoch: 19, [batch: 6825 / 11375], examples_per_second: 34681.7218, train_label_loss: 2.7726, 
epoch: 19, [batch: 9100 / 11375], examples_per_second: 34668.9192, train_label_loss: 2.7729, 
=============================================================
epoch: 19, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 20, [batch: 1 / 11375], examples_per_second: 22.7657, train_label_loss: 2.7727, 
epoch: 20, [batch: 2275 / 11375], examples_per_second: 34660.6024, train_label_loss: 2.7725, 
epoch: 20, [batch: 4550 / 11375], examples_per_second: 34704.0499, train_label_loss: 2.7726, 
epoch: 20, [batch: 6825 / 11375], examples_per_second: 34687.7154, train_label_loss: 2.7728, 
epoch: 20, [batch: 9100 / 11375], examples_per_second: 34682.0882, train_label_loss: 2.7725, 
=============================================================
epoch: 20, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 21, [batch: 1 / 11375], examples_per_second: 23.1450, train_label_loss: 2.7726, 
epoch: 21, [batch: 2275 / 11375], examples_per_second: 34695.3531, train_label_loss: 2.7724, 
epoch: 21, [batch: 4550 / 11375], examples_per_second: 34695.5023, train_label_loss: 2.7730, 
epoch: 21, [batch: 6825 / 11375], examples_per_second: 34692.4694, train_label_loss: 2.7725, 
epoch: 21, [batch: 9100 / 11375], examples_per_second: 34689.0429, train_label_loss: 2.7726, 
=============================================================
epoch: 21, val_acc_label: 0.0628, val_label_loss: 2.7726, 
=============================================================
epoch: 22, [batch: 1 / 11375], examples_per_second: 23.1648, train_label_loss: 2.7724, 
epoch: 22, [batch: 2275 / 11375], examples_per_second: 34676.6624, train_label_loss: 2.7724, 
epoch: 22, [batch: 4550 / 11375], examples_per_second: 34665.1525, train_label_loss: 2.7728, 
epoch: 22, [batch: 6825 / 11375], examples_per_second: 34661.9056, train_label_loss: 2.7726, 
epoch: 22, [batch: 9100 / 11375], examples_per_second: 34663.0162, train_label_loss: 2.7724, 
=============================================================
epoch: 22, val_acc_label: 0.0624, val_label_loss: 2.7726, 
=============================================================
epoch: 23, [batch: 1 / 11375], examples_per_second: 23.1402, train_label_loss: 2.7728, 
epoch: 23, [batch: 2275 / 11375], examples_per_second: 34652.8568, train_label_loss: 2.7725, 
epoch: 23, [batch: 4550 / 11375], examples_per_second: 34669.8575, train_label_loss: 2.7728, 
epoch: 23, [batch: 6825 / 11375], examples_per_second: 34684.4770, train_label_loss: 2.7728, 
epoch: 23, [batch: 9100 / 11375], examples_per_second: 34673.4007, train_label_loss: 2.7723, 
=============================================================
epoch: 23, val_acc_label: 0.0631, val_label_loss: 2.7726, 
=============================================================
epoch: 24, [batch: 1 / 11375], examples_per_second: 23.1495, train_label_loss: 2.7725, 
epoch: 24, [batch: 2275 / 11375], examples_per_second: 34665.5710, train_label_loss: 2.7725, 
epoch: 24, [batch: 4550 / 11375], examples_per_second: 34689.4242, train_label_loss: 2.7725, 
epoch: 24, [batch: 6825 / 11375], examples_per_second: 34687.3440, train_label_loss: 2.7725, 
epoch: 24, [batch: 9100 / 11375], examples_per_second: 34704.8491, train_label_loss: 2.7727, 
=============================================================
epoch: 24, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 25, [batch: 1 / 11375], examples_per_second: 23.0345, train_label_loss: 2.7725, 
epoch: 25, [batch: 2275 / 11375], examples_per_second: 34657.2639, train_label_loss: 2.7726, 
epoch: 25, [batch: 4550 / 11375], examples_per_second: 34682.3620, train_label_loss: 2.7727, 
epoch: 25, [batch: 6825 / 11375], examples_per_second: 34684.1077, train_label_loss: 2.7728, 
epoch: 25, [batch: 9100 / 11375], examples_per_second: 34695.9926, train_label_loss: 2.7725, 
=============================================================
epoch: 25, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 26, [batch: 1 / 11375], examples_per_second: 23.0723, train_label_loss: 2.7726, 
epoch: 26, [batch: 2275 / 11375], examples_per_second: 34686.1161, train_label_loss: 2.7727, 
epoch: 26, [batch: 4550 / 11375], examples_per_second: 34686.8849, train_label_loss: 2.7725, 
epoch: 26, [batch: 6825 / 11375], examples_per_second: 34671.7137, train_label_loss: 2.7726, 
epoch: 26, [batch: 9100 / 11375], examples_per_second: 34662.5563, train_label_loss: 2.7725, 
=============================================================
epoch: 26, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 27, [batch: 1 / 11375], examples_per_second: 22.9779, train_label_loss: 2.7726, 
epoch: 27, [batch: 2275 / 11375], examples_per_second: 34700.8845, train_label_loss: 2.7725, 
epoch: 27, [batch: 4550 / 11375], examples_per_second: 34701.8595, train_label_loss: 2.7725, 
epoch: 27, [batch: 6825 / 11375], examples_per_second: 34680.4431, train_label_loss: 2.7725, 
epoch: 27, [batch: 9100 / 11375], examples_per_second: 34672.0016, train_label_loss: 2.7724, 
=============================================================
epoch: 27, val_acc_label: 0.0621, val_label_loss: 2.7726, 
=============================================================
epoch: 28, [batch: 1 / 11375], examples_per_second: 23.0809, train_label_loss: 2.7727, 
epoch: 28, [batch: 2275 / 11375], examples_per_second: 34099.0106, train_label_loss: 2.7720, 
epoch: 28, [batch: 4550 / 11375], examples_per_second: 34684.2825, train_label_loss: 2.7731, 
epoch: 28, [batch: 6825 / 11375], examples_per_second: 34678.9026, train_label_loss: 2.7724, 
epoch: 28, [batch: 9100 / 11375], examples_per_second: 34678.7613, train_label_loss: 2.7727, 
=============================================================
epoch: 28, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.06226442307692308 Target Test Label Accuracy: 0.06226442307692308
Source Val Label Accuracy: 0.06252564102564102 Target Val Label Accuracy: 0.06252564102564102
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
