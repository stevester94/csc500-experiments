[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1659.3969, train_label_loss: 2.7726, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 24052.8298, train_label_loss: 2.7725, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 24061.7924, train_label_loss: 2.7724, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 24064.9224, train_label_loss: 2.7727, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 24065.7972, train_label_loss: 2.7726, 
=============================================================
epoch: 1, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 16.9142, train_label_loss: 2.7726, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 24063.7592, train_label_loss: 2.7726, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 23989.0917, train_label_loss: 2.7727, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 23836.2959, train_label_loss: 2.7727, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 23828.6956, train_label_loss: 2.7727, 
=============================================================
epoch: 2, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 3, [batch: 1 / 11375], examples_per_second: 17.2679, train_label_loss: 2.7726, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 23847.7890, train_label_loss: 2.7727, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 23811.2604, train_label_loss: 2.7727, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 23857.2992, train_label_loss: 2.7725, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 23896.9736, train_label_loss: 2.7728, 
=============================================================
epoch: 3, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 4, [batch: 1 / 11375], examples_per_second: 17.2407, train_label_loss: 2.7725, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 23846.0413, train_label_loss: 2.7724, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 23881.1190, train_label_loss: 2.7726, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 23856.9163, train_label_loss: 2.7724, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 23810.4870, train_label_loss: 2.7729, 
=============================================================
epoch: 4, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 5, [batch: 1 / 11375], examples_per_second: 17.0269, train_label_loss: 2.7726, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 21996.3528, train_label_loss: 2.7725, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 23406.9931, train_label_loss: 2.7726, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 22401.3903, train_label_loss: 2.7723, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 22730.6452, train_label_loss: 2.7729, 
=============================================================
epoch: 5, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 16.8565, train_label_loss: 2.7727, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 23507.8655, train_label_loss: 2.7724, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 23674.3852, train_label_loss: 2.7723, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 23437.4574, train_label_loss: 2.7729, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 23719.9259, train_label_loss: 2.7722, 
=============================================================
epoch: 6, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 7, [batch: 1 / 11375], examples_per_second: 16.3651, train_label_loss: 2.7727, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 22327.0569, train_label_loss: 2.7729, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 23574.7680, train_label_loss: 2.7728, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 23436.2164, train_label_loss: 2.7726, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 23269.1719, train_label_loss: 2.7727, 
=============================================================
epoch: 7, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 16.4073, train_label_loss: 2.7723, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 22492.1870, train_label_loss: 2.7727, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 22322.8372, train_label_loss: 2.7725, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 22719.1775, train_label_loss: 2.7728, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 23217.3572, train_label_loss: 2.7723, 
=============================================================
epoch: 8, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 9, [batch: 1 / 11375], examples_per_second: 17.1246, train_label_loss: 2.7729, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 23649.3817, train_label_loss: 2.7725, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 22914.7595, train_label_loss: 2.7726, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 22234.5009, train_label_loss: 2.7724, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 22359.0436, train_label_loss: 2.7726, 
=============================================================
epoch: 9, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 16.2460, train_label_loss: 2.7725, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 21832.6090, train_label_loss: 2.7724, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 23697.7560, train_label_loss: 2.7723, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 22588.4797, train_label_loss: 2.7726, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 22439.9160, train_label_loss: 2.7726, 
=============================================================
epoch: 10, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 11, [batch: 1 / 11375], examples_per_second: 16.4443, train_label_loss: 2.7729, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 23594.2642, train_label_loss: 2.7728, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 23572.4730, train_label_loss: 2.7725, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 21959.5886, train_label_loss: 2.7725, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 23665.6586, train_label_loss: 2.7727, 
=============================================================
epoch: 11, val_acc_label: 0.0620, val_label_loss: 2.7726, 
=============================================================
epoch: 12, [batch: 1 / 11375], examples_per_second: 16.8661, train_label_loss: 2.7725, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 23575.1435, train_label_loss: 2.7724, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 23386.2962, train_label_loss: 2.7724, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 23536.6098, train_label_loss: 2.7730, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 23494.7754, train_label_loss: 2.7725, 
=============================================================
epoch: 12, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.062400641025641024 Target Test Label Accuracy: 0.062400641025641024
Source Val Label Accuracy: 0.0625801282051282 Target Val Label Accuracy: 0.0625801282051282
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
