[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 11375], examples_per_second: 1500.7713, train_label_loss: 2.7726, 
epoch: 1, [batch: 2275 / 11375], examples_per_second: 23119.9632, train_label_loss: 2.7725, 
epoch: 1, [batch: 4550 / 11375], examples_per_second: 23158.3373, train_label_loss: 2.7725, 
epoch: 1, [batch: 6825 / 11375], examples_per_second: 23055.4111, train_label_loss: 2.7728, 
epoch: 1, [batch: 9100 / 11375], examples_per_second: 23056.3897, train_label_loss: 2.7726, 
=============================================================
epoch: 1, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
New best
epoch: 2, [batch: 1 / 11375], examples_per_second: 16.2762, train_label_loss: 2.7726, 
epoch: 2, [batch: 2275 / 11375], examples_per_second: 23073.8156, train_label_loss: 2.7726, 
epoch: 2, [batch: 4550 / 11375], examples_per_second: 23078.6771, train_label_loss: 2.7727, 
epoch: 2, [batch: 6825 / 11375], examples_per_second: 23073.5314, train_label_loss: 2.7727, 
epoch: 2, [batch: 9100 / 11375], examples_per_second: 23099.6109, train_label_loss: 2.7727, 
=============================================================
epoch: 2, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 3, [batch: 1 / 11375], examples_per_second: 16.7587, train_label_loss: 2.7726, 
epoch: 3, [batch: 2275 / 11375], examples_per_second: 23055.2556, train_label_loss: 2.7727, 
epoch: 3, [batch: 4550 / 11375], examples_per_second: 23071.2393, train_label_loss: 2.7727, 
epoch: 3, [batch: 6825 / 11375], examples_per_second: 23075.9914, train_label_loss: 2.7725, 
epoch: 3, [batch: 9100 / 11375], examples_per_second: 23029.8704, train_label_loss: 2.7729, 
=============================================================
epoch: 3, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 4, [batch: 1 / 11375], examples_per_second: 16.7405, train_label_loss: 2.7725, 
epoch: 4, [batch: 2275 / 11375], examples_per_second: 23060.9118, train_label_loss: 2.7724, 
epoch: 4, [batch: 4550 / 11375], examples_per_second: 23101.9310, train_label_loss: 2.7726, 
epoch: 4, [batch: 6825 / 11375], examples_per_second: 23072.2412, train_label_loss: 2.7724, 
epoch: 4, [batch: 9100 / 11375], examples_per_second: 23071.5616, train_label_loss: 2.7729, 
=============================================================
epoch: 4, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 5, [batch: 1 / 11375], examples_per_second: 16.7156, train_label_loss: 2.7726, 
epoch: 5, [batch: 2275 / 11375], examples_per_second: 23064.7918, train_label_loss: 2.7725, 
epoch: 5, [batch: 4550 / 11375], examples_per_second: 23086.2527, train_label_loss: 2.7726, 
epoch: 5, [batch: 6825 / 11375], examples_per_second: 23058.9882, train_label_loss: 2.7723, 
epoch: 5, [batch: 9100 / 11375], examples_per_second: 23049.8777, train_label_loss: 2.7729, 
=============================================================
epoch: 5, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 6, [batch: 1 / 11375], examples_per_second: 16.7442, train_label_loss: 2.7727, 
epoch: 6, [batch: 2275 / 11375], examples_per_second: 23065.6361, train_label_loss: 2.7724, 
epoch: 6, [batch: 4550 / 11375], examples_per_second: 23062.9966, train_label_loss: 2.7723, 
epoch: 6, [batch: 6825 / 11375], examples_per_second: 23071.2595, train_label_loss: 2.7729, 
epoch: 6, [batch: 9100 / 11375], examples_per_second: 23054.4606, train_label_loss: 2.7722, 
=============================================================
epoch: 6, val_acc_label: 0.0625, val_label_loss: 2.7726, 
=============================================================
epoch: 7, [batch: 1 / 11375], examples_per_second: 16.5796, train_label_loss: 2.7727, 
epoch: 7, [batch: 2275 / 11375], examples_per_second: 23056.7785, train_label_loss: 2.7729, 
epoch: 7, [batch: 4550 / 11375], examples_per_second: 23072.2471, train_label_loss: 2.7728, 
epoch: 7, [batch: 6825 / 11375], examples_per_second: 23081.2069, train_label_loss: 2.7726, 
epoch: 7, [batch: 9100 / 11375], examples_per_second: 23062.4638, train_label_loss: 2.7727, 
=============================================================
epoch: 7, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 8, [batch: 1 / 11375], examples_per_second: 16.8181, train_label_loss: 2.7723, 
epoch: 8, [batch: 2275 / 11375], examples_per_second: 23052.8229, train_label_loss: 2.7727, 
epoch: 8, [batch: 4550 / 11375], examples_per_second: 23078.4013, train_label_loss: 2.7725, 
epoch: 8, [batch: 6825 / 11375], examples_per_second: 23083.1365, train_label_loss: 2.7728, 
epoch: 8, [batch: 9100 / 11375], examples_per_second: 23078.6854, train_label_loss: 2.7723, 
=============================================================
epoch: 8, val_acc_label: 0.0622, val_label_loss: 2.7726, 
=============================================================
epoch: 9, [batch: 1 / 11375], examples_per_second: 16.7817, train_label_loss: 2.7729, 
epoch: 9, [batch: 2275 / 11375], examples_per_second: 23063.5123, train_label_loss: 2.7725, 
epoch: 9, [batch: 4550 / 11375], examples_per_second: 23056.1910, train_label_loss: 2.7726, 
epoch: 9, [batch: 6825 / 11375], examples_per_second: 23058.5350, train_label_loss: 2.7724, 
epoch: 9, [batch: 9100 / 11375], examples_per_second: 23054.2561, train_label_loss: 2.7726, 
=============================================================
epoch: 9, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
epoch: 10, [batch: 1 / 11375], examples_per_second: 16.7028, train_label_loss: 2.7725, 
epoch: 10, [batch: 2275 / 11375], examples_per_second: 23065.7742, train_label_loss: 2.7724, 
epoch: 10, [batch: 4550 / 11375], examples_per_second: 23061.7784, train_label_loss: 2.7723, 
epoch: 10, [batch: 6825 / 11375], examples_per_second: 23080.5684, train_label_loss: 2.7726, 
epoch: 10, [batch: 9100 / 11375], examples_per_second: 23059.6342, train_label_loss: 2.7726, 
=============================================================
epoch: 10, val_acc_label: 0.0623, val_label_loss: 2.7726, 
=============================================================
epoch: 11, [batch: 1 / 11375], examples_per_second: 16.7116, train_label_loss: 2.7729, 
epoch: 11, [batch: 2275 / 11375], examples_per_second: 23068.1382, train_label_loss: 2.7728, 
epoch: 11, [batch: 4550 / 11375], examples_per_second: 23082.0821, train_label_loss: 2.7725, 
epoch: 11, [batch: 6825 / 11375], examples_per_second: 23078.3483, train_label_loss: 2.7725, 
epoch: 11, [batch: 9100 / 11375], examples_per_second: 23079.9617, train_label_loss: 2.7727, 
=============================================================
epoch: 11, val_acc_label: 0.0620, val_label_loss: 2.7726, 
=============================================================
epoch: 12, [batch: 1 / 11375], examples_per_second: 16.6846, train_label_loss: 2.7725, 
epoch: 12, [batch: 2275 / 11375], examples_per_second: 23064.0872, train_label_loss: 2.7724, 
epoch: 12, [batch: 4550 / 11375], examples_per_second: 23057.2881, train_label_loss: 2.7724, 
epoch: 12, [batch: 6825 / 11375], examples_per_second: 23050.4921, train_label_loss: 2.7730, 
epoch: 12, [batch: 9100 / 11375], examples_per_second: 23059.8824, train_label_loss: 2.7725, 
=============================================================
epoch: 12, val_acc_label: 0.0626, val_label_loss: 2.7726, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.062400641025641024 Target Test Label Accuracy: 0.062400641025641024
Source Val Label Accuracy: 0.0625801282051282 Target Val Label Accuracy: 0.0625801282051282
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
