{
  "experiment_name": "CNN SampsPerSymbol Train One Test Several Trial 1",
  "parameters": {
    "experiment_name": "CNN SampsPerSymbol Train One Test Several Trial 1",
    "lr": 0.001,
    "n_epoch": 1000,
    "batch_size": 256,
    "patience": 10,
    "device": "cuda",
    "source_domains": [
      8
    ],
    "target_domains": [
      2,
      6,
      10,
      12
    ],
    "x_net": [
      {
        "class": "Conv1d",
        "kargs": {
          "in_channels": 2,
          "out_channels": 50,
          "kernel_size": 7,
          "stride": 1,
          "padding": 0
        }
      },
      {
        "class": "ReLU",
        "kargs": {
          "inplace": true
        }
      },
      {
        "class": "Conv1d",
        "kargs": {
          "in_channels": 50,
          "out_channels": 50,
          "kernel_size": 7,
          "stride": 1,
          "padding": 0
        }
      },
      {
        "class": "ReLU",
        "kargs": {
          "inplace": true
        }
      },
      {
        "class": "Dropout",
        "kargs": {
          "p": 0.5
        }
      },
      {
        "class": "Flatten",
        "kargs": {}
      },
      {
        "class": "Linear",
        "kargs": {
          "in_features": 5800,
          "out_features": 256
        }
      },
      {
        "class": "ReLU",
        "kargs": {
          "inplace": true
        }
      },
      {
        "class": "Dropout",
        "kargs": {
          "p": 0.5
        }
      },
      {
        "class": "Linear",
        "kargs": {
          "in_features": 256,
          "out_features": 80
        }
      },
      {
        "class": "ReLU",
        "kargs": {
          "inplace": true
        }
      },
      {
        "class": "Dropout",
        "kargs": {
          "p": 0.5
        }
      },
      {
        "class": "Linear",
        "kargs": {
          "in_features": 80,
          "out_features": 16
        }
      }
    ],
    "seed": 5578
  },
  "results": {
    "source_test_label_accuracy": 0.124875,
    "source_test_label_loss": 2.0796704317661043,
    "target_test_label_accuracy": 0.12691666666666668,
    "target_test_label_loss": 2.079569690068563,
    "source_val_label_accuracy": 0.125875,
    "source_val_label_loss": 2.0794197523847537,
    "target_val_label_accuracy": 0.12434375,
    "target_val_label_loss": 2.0796332092285157,
    "total_epochs_trained": 24,
    "total_experiment_time_secs": 281.533420085907,
    "confusion": {
      "10": {
        "3": {
          "5": 2996
        },
        "1": {
          "5": 2994
        },
        "5": {
          "5": 2977
        },
        "2": {
          "5": 3042
        },
        "6": {
          "5": 3011
        },
        "4": {
          "5": 2933
        },
        "7": {
          "5": 2923
        },
        "0": {
          "5": 3067
        }
      },
      "8": {
        "7": {
          "5": 3037
        },
        "3": {
          "5": 2996
        },
        "2": {
          "5": 2941
        },
        "0": {
          "5": 2898
        },
        "4": {
          "5": 3162
        },
        "6": {
          "5": 2897
        },
        "5": {
          "5": 3021
        },
        "1": {
          "5": 3048
        }
      },
      "2": {
        "7": {
          "5": 3022
        },
        "5": {
          "5": 3023
        },
        "4": {
          "5": 2961
        },
        "3": {
          "5": 2991
        },
        "6": {
          "5": 3051
        },
        "1": {
          "5": 2959
        },
        "0": {
          "5": 3054
        },
        "2": {
          "5": 3011
        }
      },
      "12": {
        "6": {
          "5": 2935
        },
        "4": {
          "5": 2992
        },
        "2": {
          "5": 2989
        },
        "0": {
          "5": 2989
        },
        "7": {
          "5": 2977
        },
        "1": {
          "5": 3003
        },
        "3": {
          "5": 3063
        },
        "5": {
          "5": 3028
        }
      },
      "6": {
        "7": {
          "5": 3048
        },
        "3": {
          "5": 3025
        },
        "5": {
          "5": 2909
        },
        "4": {
          "5": 2992
        },
        "2": {
          "5": 2908
        },
        "6": {
          "5": 3096
        },
        "0": {
          "5": 3021
        },
        "1": {
          "5": 3010
        }
      }
    },
    "per_domain_accuracy": {
      "10": {
        "accuracy": 0.12433696696320427,
        "source?": false
      },
      "8": {
        "accuracy": 0.125875,
        "source?": true
      },
      "2": {
        "accuracy": 0.12558158856763044,
        "source?": false
      },
      "12": {
        "accuracy": 0.12629295962629297,
        "source?": false
      },
      "6": {
        "accuracy": 0.12116289724686576,
        "source?": false
      }
    }
  },
  "history": {
    "epoch_indices": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24
    ],
    "train_label_loss": [
      2.1017580516806476,
      2.083766445177331,
      2.083244561604713,
      2.082265937709373,
      2.0820327354892747,
      2.08155438399206,
      2.0813880826784597,
      2.0812013100271356,
      2.08083651435974,
      2.080904348255837,
      2.0806274555589512,
      2.080807096337619,
      2.0805894381379426,
      2.0805616068513424,
      2.0803646469769412,
      2.080481748602706,
      2.0803749343575952,
      2.0802394031933997,
      2.0802405795005905,
      2.0801619498152712,
      2.079976496631152,
      2.0801101367767543,
      2.0800895173800047,
      2.080076649308749
    ],
    "val_label_loss": [
      2.083299439004127,
      2.0814843989433127,
      2.080522298812866,
      2.0801983615185353,
      2.0798150174161223,
      2.0804583113244237,
      2.080153434834582,
      2.0797843882378113,
      2.079835039504031,
      2.079813335804229,
      2.079657364398875,
      2.080025462394065,
      2.0794194150478282,
      2.0800725728907485,
      2.079823876949067,
      2.0801061188921017,
      2.0798041845889803,
      2.080033081643125,
      2.0801066692839276,
      2.080127906292043,
      2.0798363939244697,
      2.079949543831196,
      2.0795076121675207,
      2.0799415618815322
    ]
  }
}