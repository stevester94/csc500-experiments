[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 438], examples_per_second: 1410.6845, train_label_loss: 2.0795, 
epoch: 1, [batch: 88 / 438], examples_per_second: 27403.8279, train_label_loss: 2.0794, 
epoch: 1, [batch: 175 / 438], examples_per_second: 27713.4616, train_label_loss: 2.0803, 
epoch: 1, [batch: 263 / 438], examples_per_second: 28298.2611, train_label_loss: 2.0792, 
epoch: 1, [batch: 350 / 438], examples_per_second: 28746.9842, train_label_loss: 2.0809, 
=============================================================
epoch: 1, val_acc_label: 0.1237, val_label_loss: 2.0795, 
=============================================================
New best
epoch: 2, [batch: 1 / 438], examples_per_second: 462.7619, train_label_loss: 2.0787, 
epoch: 2, [batch: 88 / 438], examples_per_second: 28141.4486, train_label_loss: 2.0797, 
epoch: 2, [batch: 175 / 438], examples_per_second: 28571.2525, train_label_loss: 2.0789, 
epoch: 2, [batch: 263 / 438], examples_per_second: 27774.6595, train_label_loss: 2.0795, 
epoch: 2, [batch: 350 / 438], examples_per_second: 28605.2597, train_label_loss: 2.0794, 
=============================================================
epoch: 2, val_acc_label: 0.1235, val_label_loss: 2.0795, 
=============================================================
New best
epoch: 3, [batch: 1 / 438], examples_per_second: 511.7395, train_label_loss: 2.0795, 
epoch: 3, [batch: 88 / 438], examples_per_second: 28512.0581, train_label_loss: 2.0798, 
epoch: 3, [batch: 175 / 438], examples_per_second: 28918.8289, train_label_loss: 2.0793, 
epoch: 3, [batch: 263 / 438], examples_per_second: 28912.3915, train_label_loss: 2.0800, 
epoch: 3, [batch: 350 / 438], examples_per_second: 28619.1763, train_label_loss: 2.0792, 
=============================================================
epoch: 3, val_acc_label: 0.1214, val_label_loss: 2.0797, 
=============================================================
epoch: 4, [batch: 1 / 438], examples_per_second: 516.0136, train_label_loss: 2.0814, 
epoch: 4, [batch: 88 / 438], examples_per_second: 28406.5335, train_label_loss: 2.0796, 
epoch: 4, [batch: 175 / 438], examples_per_second: 28613.6536, train_label_loss: 2.0793, 
epoch: 4, [batch: 263 / 438], examples_per_second: 28449.4440, train_label_loss: 2.0795, 
epoch: 4, [batch: 350 / 438], examples_per_second: 28896.5723, train_label_loss: 2.0795, 
=============================================================
epoch: 4, val_acc_label: 0.1214, val_label_loss: 2.0797, 
=============================================================
epoch: 5, [batch: 1 / 438], examples_per_second: 528.9423, train_label_loss: 2.0788, 
epoch: 5, [batch: 88 / 438], examples_per_second: 28592.1354, train_label_loss: 2.0794, 
epoch: 5, [batch: 175 / 438], examples_per_second: 28734.8167, train_label_loss: 2.0798, 
epoch: 5, [batch: 263 / 438], examples_per_second: 28482.7179, train_label_loss: 2.0794, 
epoch: 5, [batch: 350 / 438], examples_per_second: 28804.4233, train_label_loss: 2.0790, 
=============================================================
epoch: 5, val_acc_label: 0.1248, val_label_loss: 2.0796, 
=============================================================
epoch: 6, [batch: 1 / 438], examples_per_second: 512.1827, train_label_loss: 2.0795, 
epoch: 6, [batch: 88 / 438], examples_per_second: 28580.7457, train_label_loss: 2.0798, 
epoch: 6, [batch: 175 / 438], examples_per_second: 28844.2775, train_label_loss: 2.0793, 
epoch: 6, [batch: 263 / 438], examples_per_second: 28276.2857, train_label_loss: 2.0803, 
epoch: 6, [batch: 350 / 438], examples_per_second: 28714.9165, train_label_loss: 2.0786, 
=============================================================
epoch: 6, val_acc_label: 0.1248, val_label_loss: 2.0795, 
=============================================================
epoch: 7, [batch: 1 / 438], examples_per_second: 526.2991, train_label_loss: 2.0791, 
epoch: 7, [batch: 88 / 438], examples_per_second: 28366.2681, train_label_loss: 2.0796, 
epoch: 7, [batch: 175 / 438], examples_per_second: 28323.1451, train_label_loss: 2.0784, 
epoch: 7, [batch: 263 / 438], examples_per_second: 28552.8817, train_label_loss: 2.0792, 
epoch: 7, [batch: 350 / 438], examples_per_second: 28417.8798, train_label_loss: 2.0799, 
=============================================================
epoch: 7, val_acc_label: 0.1214, val_label_loss: 2.0795, 
=============================================================
epoch: 8, [batch: 1 / 438], examples_per_second: 525.1280, train_label_loss: 2.0791, 
epoch: 8, [batch: 88 / 438], examples_per_second: 28191.4450, train_label_loss: 2.0792, 
epoch: 8, [batch: 175 / 438], examples_per_second: 28151.0825, train_label_loss: 2.0791, 
epoch: 8, [batch: 263 / 438], examples_per_second: 28118.8639, train_label_loss: 2.0793, 
epoch: 8, [batch: 350 / 438], examples_per_second: 28172.7064, train_label_loss: 2.0793, 
=============================================================
epoch: 8, val_acc_label: 0.1214, val_label_loss: 2.0796, 
=============================================================
epoch: 9, [batch: 1 / 438], examples_per_second: 522.1324, train_label_loss: 2.0792, 
epoch: 9, [batch: 88 / 438], examples_per_second: 27401.8022, train_label_loss: 2.0788, 
epoch: 9, [batch: 175 / 438], examples_per_second: 27233.5885, train_label_loss: 2.0787, 
epoch: 9, [batch: 263 / 438], examples_per_second: 28487.3464, train_label_loss: 2.0793, 
epoch: 9, [batch: 350 / 438], examples_per_second: 28373.5829, train_label_loss: 2.0795, 
=============================================================
epoch: 9, val_acc_label: 0.1248, val_label_loss: 2.0795, 
=============================================================
New best
epoch: 10, [batch: 1 / 438], examples_per_second: 501.9064, train_label_loss: 2.0793, 
epoch: 10, [batch: 88 / 438], examples_per_second: 28219.0201, train_label_loss: 2.0792, 
epoch: 10, [batch: 175 / 438], examples_per_second: 28326.4001, train_label_loss: 2.0786, 
epoch: 10, [batch: 263 / 438], examples_per_second: 28557.4122, train_label_loss: 2.0790, 
epoch: 10, [batch: 350 / 438], examples_per_second: 28424.6937, train_label_loss: 2.0797, 
=============================================================
epoch: 10, val_acc_label: 0.1248, val_label_loss: 2.0795, 
=============================================================
New best
epoch: 11, [batch: 1 / 438], examples_per_second: 493.9030, train_label_loss: 2.0795, 
epoch: 11, [batch: 88 / 438], examples_per_second: 28164.4757, train_label_loss: 2.0794, 
epoch: 11, [batch: 175 / 438], examples_per_second: 28490.7793, train_label_loss: 2.0800, 
epoch: 11, [batch: 263 / 438], examples_per_second: 28693.2668, train_label_loss: 2.0799, 
epoch: 11, [batch: 350 / 438], examples_per_second: 29090.5208, train_label_loss: 2.0793, 
=============================================================
epoch: 11, val_acc_label: 0.1248, val_label_loss: 2.0795, 
=============================================================
epoch: 12, [batch: 1 / 438], examples_per_second: 515.4841, train_label_loss: 2.0804, 
epoch: 12, [batch: 88 / 438], examples_per_second: 28643.2557, train_label_loss: 2.0799, 
epoch: 12, [batch: 175 / 438], examples_per_second: 29018.2013, train_label_loss: 2.0797, 
epoch: 12, [batch: 263 / 438], examples_per_second: 28440.4528, train_label_loss: 2.0787, 
epoch: 12, [batch: 350 / 438], examples_per_second: 28594.1659, train_label_loss: 2.0791, 
=============================================================
epoch: 12, val_acc_label: 0.1237, val_label_loss: 2.0796, 
=============================================================
epoch: 13, [batch: 1 / 438], examples_per_second: 511.7065, train_label_loss: 2.0807, 
epoch: 13, [batch: 88 / 438], examples_per_second: 27968.9251, train_label_loss: 2.0800, 
epoch: 13, [batch: 175 / 438], examples_per_second: 28369.5072, train_label_loss: 2.0789, 
epoch: 13, [batch: 263 / 438], examples_per_second: 28592.7649, train_label_loss: 2.0797, 
epoch: 13, [batch: 350 / 438], examples_per_second: 28056.2108, train_label_loss: 2.0784, 
=============================================================
epoch: 13, val_acc_label: 0.1214, val_label_loss: 2.0795, 
=============================================================
epoch: 14, [batch: 1 / 438], examples_per_second: 521.9336, train_label_loss: 2.0791, 
epoch: 14, [batch: 88 / 438], examples_per_second: 28139.1429, train_label_loss: 2.0798, 
epoch: 14, [batch: 175 / 438], examples_per_second: 28537.0820, train_label_loss: 2.0804, 
epoch: 14, [batch: 263 / 438], examples_per_second: 28562.2636, train_label_loss: 2.0798, 
epoch: 14, [batch: 350 / 438], examples_per_second: 28451.3060, train_label_loss: 2.0793, 
=============================================================
epoch: 14, val_acc_label: 0.1237, val_label_loss: 2.0795, 
=============================================================
epoch: 15, [batch: 1 / 438], examples_per_second: 518.1800, train_label_loss: 2.0796, 
epoch: 15, [batch: 88 / 438], examples_per_second: 27917.6199, train_label_loss: 2.0790, 
epoch: 15, [batch: 175 / 438], examples_per_second: 28439.2923, train_label_loss: 2.0791, 
epoch: 15, [batch: 263 / 438], examples_per_second: 28452.6736, train_label_loss: 2.0799, 
epoch: 15, [batch: 350 / 438], examples_per_second: 28169.3422, train_label_loss: 2.0792, 
=============================================================
epoch: 15, val_acc_label: 0.1248, val_label_loss: 2.0795, 
=============================================================
epoch: 16, [batch: 1 / 438], examples_per_second: 530.5068, train_label_loss: 2.0789, 
epoch: 16, [batch: 88 / 438], examples_per_second: 27883.4792, train_label_loss: 2.0798, 
epoch: 16, [batch: 175 / 438], examples_per_second: 28638.9353, train_label_loss: 2.0797, 
epoch: 16, [batch: 263 / 438], examples_per_second: 28602.3894, train_label_loss: 2.0796, 
epoch: 16, [batch: 350 / 438], examples_per_second: 28941.4426, train_label_loss: 2.0799, 
=============================================================
epoch: 16, val_acc_label: 0.1248, val_label_loss: 2.0795, 
=============================================================
epoch: 17, [batch: 1 / 438], examples_per_second: 521.3930, train_label_loss: 2.0798, 
epoch: 17, [batch: 88 / 438], examples_per_second: 28590.7003, train_label_loss: 2.0792, 
epoch: 17, [batch: 175 / 438], examples_per_second: 28498.8453, train_label_loss: 2.0793, 
epoch: 17, [batch: 263 / 438], examples_per_second: 28400.8053, train_label_loss: 2.0787, 
epoch: 17, [batch: 350 / 438], examples_per_second: 28538.9477, train_label_loss: 2.0795, 
=============================================================
epoch: 17, val_acc_label: 0.1248, val_label_loss: 2.0795, 
=============================================================
epoch: 18, [batch: 1 / 438], examples_per_second: 525.0573, train_label_loss: 2.0794, 
epoch: 18, [batch: 88 / 438], examples_per_second: 28465.3855, train_label_loss: 2.0791, 
epoch: 18, [batch: 175 / 438], examples_per_second: 28610.0694, train_label_loss: 2.0794, 
epoch: 18, [batch: 263 / 438], examples_per_second: 28636.1525, train_label_loss: 2.0790, 
epoch: 18, [batch: 350 / 438], examples_per_second: 28116.0133, train_label_loss: 2.0795, 
=============================================================
epoch: 18, val_acc_label: 0.1248, val_label_loss: 2.0795, 
=============================================================
epoch: 19, [batch: 1 / 438], examples_per_second: 517.6815, train_label_loss: 2.0793, 
epoch: 19, [batch: 88 / 438], examples_per_second: 28698.9932, train_label_loss: 2.0795, 
epoch: 19, [batch: 175 / 438], examples_per_second: 27985.0376, train_label_loss: 2.0794, 
epoch: 19, [batch: 263 / 438], examples_per_second: 27430.8144, train_label_loss: 2.0800, 
epoch: 19, [batch: 350 / 438], examples_per_second: 26957.8998, train_label_loss: 2.0796, 
=============================================================
epoch: 19, val_acc_label: 0.1248, val_label_loss: 2.0795, 
=============================================================
epoch: 20, [batch: 1 / 438], examples_per_second: 518.8048, train_label_loss: 2.0798, 
epoch: 20, [batch: 88 / 438], examples_per_second: 28112.8403, train_label_loss: 2.0797, 
epoch: 20, [batch: 175 / 438], examples_per_second: 28647.3929, train_label_loss: 2.0787, 
epoch: 20, [batch: 263 / 438], examples_per_second: 28434.2821, train_label_loss: 2.0790, 
epoch: 20, [batch: 350 / 438], examples_per_second: 28399.5729, train_label_loss: 2.0800, 
=============================================================
epoch: 20, val_acc_label: 0.1214, val_label_loss: 2.0795, 
=============================================================
epoch: 21, [batch: 1 / 438], examples_per_second: 512.0411, train_label_loss: 2.0788, 
epoch: 21, [batch: 88 / 438], examples_per_second: 28766.6012, train_label_loss: 2.0800, 
epoch: 21, [batch: 175 / 438], examples_per_second: 28925.1597, train_label_loss: 2.0794, 
epoch: 21, [batch: 263 / 438], examples_per_second: 28773.2059, train_label_loss: 2.0801, 
epoch: 21, [batch: 350 / 438], examples_per_second: 28618.5451, train_label_loss: 2.0794, 
=============================================================
epoch: 21, val_acc_label: 0.1249, val_label_loss: 2.0795, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.12270833333333334 Target Test Label Accuracy: 0.12332291666666667
Source Val Label Accuracy: 0.12483333333333334 Target Val Label Accuracy: 0.12530208333333334
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
