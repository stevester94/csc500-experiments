{
  "experiment_name": "CNN SampsPerSymbol Train One Test Several Trial 2",
  "parameters": {
    "experiment_name": "CNN SampsPerSymbol Train One Test Several Trial 2",
    "lr": 0.001,
    "n_epoch": 1000,
    "batch_size": 256,
    "patience": 10,
    "device": "cuda",
    "source_domains": [
      8
    ],
    "target_domains": [
      2,
      6,
      10,
      12
    ],
    "x_net": [
      {
        "class": "Conv1d",
        "kargs": {
          "in_channels": 2,
          "out_channels": 50,
          "kernel_size": 7,
          "stride": 1,
          "padding": 0
        }
      },
      {
        "class": "ReLU",
        "kargs": {
          "inplace": true
        }
      },
      {
        "class": "Conv1d",
        "kargs": {
          "in_channels": 50,
          "out_channels": 50,
          "kernel_size": 7,
          "stride": 2,
          "padding": 0
        }
      },
      {
        "class": "ReLU",
        "kargs": {
          "inplace": true
        }
      },
      {
        "class": "Dropout",
        "kargs": {
          "p": 0.5
        }
      },
      {
        "class": "Flatten",
        "kargs": {}
      },
      {
        "class": "Linear",
        "kargs": {
          "in_features": 2900,
          "out_features": 256
        }
      },
      {
        "class": "ReLU",
        "kargs": {
          "inplace": true
        }
      },
      {
        "class": "Dropout",
        "kargs": {
          "p": 0.5
        }
      },
      {
        "class": "Linear",
        "kargs": {
          "in_features": 256,
          "out_features": 80
        }
      },
      {
        "class": "ReLU",
        "kargs": {
          "inplace": true
        }
      },
      {
        "class": "Linear",
        "kargs": {
          "in_features": 80,
          "out_features": 8
        }
      }
    ],
    "seed": 179
  },
  "results": {
    "source_test_label_accuracy": 0.12233333333333334,
    "source_test_label_loss": 2.0795218132911844,
    "target_test_label_accuracy": 0.12386458333333333,
    "target_test_label_loss": 2.079462224324544,
    "source_val_label_accuracy": 0.12708333333333333,
    "source_val_label_loss": 2.0793833935514408,
    "target_val_label_accuracy": 0.12538541666666667,
    "target_val_label_loss": 2.079469986597697,
    "total_epochs_trained": 31,
    "total_experiment_time_secs": 170.81603860855103,
    "confusion": {
      "6": {
        "0": {
          "5": 2989
        },
        "3": {
          "5": 2967
        },
        "1": {
          "5": 2936
        },
        "5": {
          "5": 3055
        },
        "7": {
          "5": 2970
        },
        "4": {
          "5": 3013
        },
        "2": {
          "5": 3003
        },
        "6": {
          "5": 2990
        }
      },
      "2": {
        "4": {
          "5": 3066
        },
        "6": {
          "5": 3023
        },
        "1": {
          "5": 3039
        },
        "3": {
          "5": 2917
        },
        "7": {
          "5": 2992
        },
        "2": {
          "5": 3122
        },
        "0": {
          "5": 2985
        },
        "5": {
          "5": 2913
        }
      },
      "8": {
        "1": {
          "5": 2960
        },
        "2": {
          "5": 2944
        },
        "4": {
          "5": 2971
        },
        "3": {
          "5": 3003
        },
        "0": {
          "5": 3020
        },
        "6": {
          "5": 2951
        },
        "7": {
          "5": 3101
        },
        "5": {
          "5": 3050
        }
      },
      "12": {
        "0": {
          "5": 3003
        },
        "1": {
          "5": 3044
        },
        "5": {
          "5": 2998
        },
        "3": {
          "5": 2967
        },
        "2": {
          "5": 2961
        },
        "7": {
          "5": 3024
        },
        "6": {
          "5": 3058
        },
        "4": {
          "5": 2914
        }
      },
      "10": {
        "7": {
          "5": 2972
        },
        "1": {
          "5": 2976
        },
        "2": {
          "5": 3016
        },
        "3": {
          "5": 3107
        },
        "5": {
          "5": 3071
        },
        "6": {
          "5": 2988
        },
        "4": {
          "5": 2937
        },
        "0": {
          "5": 2984
        }
      }
    },
    "per_domain_accuracy": {
      "6": {
        "accuracy": 0.12770137524557956,
        "source?": false
      },
      "2": {
        "accuracy": 0.12108741738371367,
        "source?": false
      },
      "8": {
        "accuracy": 0.12708333333333333,
        "source?": true
      },
      "12": {
        "accuracy": 0.12507822604197089,
        "source?": false
      },
      "10": {
        "accuracy": 0.12768699846160242,
        "source?": false
      }
    }
  },
  "history": {
    "epoch_indices": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31
    ],
    "train_label_loss": [
      2.0795029967887215,
      2.0794903034488903,
      2.079496847984453,
      2.07951026692238,
      2.0794967951839918,
      2.0795004928493066,
      2.0794966498466385,
      2.079500276748448,
      2.079508531039164,
      2.0794975256810995,
      2.079489877234855,
      2.079498897948766,
      2.0794977733533675,
      2.079503369113626,
      2.0794823137048173,
      2.079523607476117,
      2.0794797596866137,
      2.079493492705637,
      2.0795083720934446,
      2.0794882589279244,
      2.079502280444315,
      2.079499545707006,
      2.079514975961485,
      2.079487335192014,
      2.0795002794701216,
      2.0794876313100668,
      2.079486021168156,
      2.0795008227161076,
      2.0794975284027726,
      2.0794932434003646,
      2.0794996458645825
    ],
    "val_label_loss": [
      2.079482522416622,
      2.079533297964867,
      2.079478258782245,
      2.0794596697421786,
      2.0794719229353236,
      2.0794387117345283,
      2.0795426064349236,
      2.079470368141824,
      2.079478494664456,
      2.0795378558179167,
      2.0794874531157475,
      2.07948133793283,
      2.0795324584271047,
      2.0795464896141214,
      2.079384058079821,
      2.0794652319969016,
      2.0795648960357016,
      2.079525280506053,
      2.0794890231274543,
      2.0793838779977025,
      2.0795220694643386,
      2.0794809067502933,
      2.0794708728790283,
      2.079462411555838,
      2.079438790361932,
      2.0794215506695686,
      2.07956304702353,
      2.079429976483609,
      2.079473170828312,
      2.0794667512812515,
      2.079473632447263
    ]
  }
}