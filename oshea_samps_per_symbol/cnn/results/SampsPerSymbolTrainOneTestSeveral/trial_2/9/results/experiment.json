{
  "experiment_name": "CNN SampsPerSymbol Train One Test Several Trial 2",
  "parameters": {
    "experiment_name": "CNN SampsPerSymbol Train One Test Several Trial 2",
    "lr": 0.001,
    "n_epoch": 1000,
    "batch_size": 256,
    "patience": 10,
    "device": "cuda",
    "source_domains": [
      8
    ],
    "target_domains": [
      2,
      6,
      10,
      12
    ],
    "x_net": [
      {
        "class": "Conv1d",
        "kargs": {
          "in_channels": 2,
          "out_channels": 50,
          "kernel_size": 7,
          "stride": 1,
          "padding": 0
        }
      },
      {
        "class": "ReLU",
        "kargs": {
          "inplace": true
        }
      },
      {
        "class": "Conv1d",
        "kargs": {
          "in_channels": 50,
          "out_channels": 50,
          "kernel_size": 7,
          "stride": 2,
          "padding": 0
        }
      },
      {
        "class": "ReLU",
        "kargs": {
          "inplace": true
        }
      },
      {
        "class": "Dropout",
        "kargs": {
          "p": 0.5
        }
      },
      {
        "class": "Flatten",
        "kargs": {}
      },
      {
        "class": "Linear",
        "kargs": {
          "in_features": 2900,
          "out_features": 256
        }
      },
      {
        "class": "ReLU",
        "kargs": {
          "inplace": true
        }
      },
      {
        "class": "Dropout",
        "kargs": {
          "p": 0.5
        }
      },
      {
        "class": "Linear",
        "kargs": {
          "in_features": 256,
          "out_features": 80
        }
      },
      {
        "class": "ReLU",
        "kargs": {
          "inplace": true
        }
      },
      {
        "class": "Linear",
        "kargs": {
          "in_features": 80,
          "out_features": 8
        }
      }
    ],
    "seed": 1316
  },
  "results": {
    "source_test_label_accuracy": 0.12429166666666666,
    "source_test_label_loss": 2.0794478451952023,
    "target_test_label_accuracy": 0.125625,
    "target_test_label_loss": 2.07944571685791,
    "source_val_label_accuracy": 0.126625,
    "source_val_label_loss": 2.0794252182574984,
    "target_val_label_accuracy": 0.12383333333333334,
    "target_val_label_loss": 2.0794546998341876,
    "total_epochs_trained": 26,
    "total_experiment_time_secs": 239.91003799438477,
    "confusion": {
      "6": {
        "1": {
          "1": 2931
        },
        "7": {
          "1": 3009
        },
        "5": {
          "1": 2964
        },
        "3": {
          "1": 2975
        },
        "4": {
          "1": 3021
        },
        "6": {
          "1": 2933
        },
        "0": {
          "1": 2960
        },
        "2": {
          "1": 3019
        }
      },
      "2": {
        "5": {
          "1": 3019
        },
        "0": {
          "1": 3030
        },
        "1": {
          "1": 2980
        },
        "4": {
          "1": 2993
        },
        "7": {
          "1": 2984
        },
        "2": {
          "1": 3011
        },
        "3": {
          "1": 3051
        },
        "6": {
          "1": 3051
        }
      },
      "12": {
        "3": {
          "1": 3030
        },
        "6": {
          "1": 3010
        },
        "2": {
          "1": 2965
        },
        "0": {
          "1": 3000
        },
        "1": {
          "1": 2983
        },
        "5": {
          "1": 3020
        },
        "4": {
          "1": 2941
        },
        "7": {
          "1": 2953
        }
      },
      "8": {
        "6": {
          "1": 3037
        },
        "3": {
          "1": 3036
        },
        "4": {
          "1": 2953
        },
        "0": {
          "1": 2980
        },
        "1": {
          "1": 3039
        },
        "2": {
          "1": 2962
        },
        "5": {
          "1": 2964
        },
        "7": {
          "1": 3029
        }
      },
      "10": {
        "0": {
          "1": 2948
        },
        "5": {
          "1": 3005
        },
        "1": {
          "1": 2994
        },
        "2": {
          "1": 2988
        },
        "6": {
          "1": 3090
        },
        "4": {
          "1": 3108
        },
        "7": {
          "1": 3011
        },
        "3": {
          "1": 3023
        }
      }
    },
    "per_domain_accuracy": {
      "6": {
        "accuracy": 0.12308919872333278,
        "source?": false
      },
      "2": {
        "accuracy": 0.12355404452920933,
        "source?": false
      },
      "12": {
        "accuracy": 0.12480127186009539,
        "source?": false
      },
      "8": {
        "accuracy": 0.126625,
        "source?": true
      },
      "10": {
        "accuracy": 0.12388794637315348,
        "source?": false
      }
    }
  },
  "history": {
    "epoch_indices": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26
    ],
    "train_label_loss": [
      2.0795119554484818,
      2.0795071723798637,
      2.0795039836674523,
      2.0794955900270646,
      2.0795134741421704,
      2.0794906436580503,
      2.079504639046377,
      2.0795077085494995,
      2.0794872883792337,
      2.079494758283711,
      2.079510192892867,
      2.0795004231744705,
      2.0795038198227207,
      2.0795086867188752,
      2.0794986856582502,
      2.0794965045092857,
      2.0794895827498068,
      2.079509031827047,
      2.079511117717447,
      2.0794958159259465,
      2.0794966433146227,
      2.0795007851570166,
      2.0795043064579026,
      2.0794962960291126,
      2.0795095293489223,
      2.079494916685096
    ],
    "val_label_loss": [
      2.0794856979491865,
      2.0794607806713024,
      2.0795290977396865,
      2.0795335439925497,
      2.0794859896314906,
      2.079507604558417,
      2.079494904964528,
      2.0795223662193787,
      2.079471159488597,
      2.079476371724555,
      2.0795049210812184,
      2.079458939268234,
      2.0794538842870836,
      2.0794830626629768,
      2.079424538510911,
      2.0794893046642873,
      2.0795056946734163,
      2.079481061468733,
      2.079455880408591,
      2.079487567252301,
      2.0794710428156753,
      2.0794810132777437,
      2.07949575718413,
      2.07949035725695,
      2.0794756919779678,
      2.07949061850284
    ]
  }
}