[CONDUCTOR]: Begin experiment
[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
epoch: 1, [batch: 1 / 438], examples_per_second: 3232.6724, train_label_loss: 2.0795, 
epoch: 1, [batch: 88 / 438], examples_per_second: 13305.2676, train_label_loss: 2.0794, 
epoch: 1, [batch: 175 / 438], examples_per_second: 13602.2429, train_label_loss: 2.0804, 
epoch: 1, [batch: 263 / 438], examples_per_second: 13537.8638, train_label_loss: 2.0790, 
epoch: 1, [batch: 350 / 438], examples_per_second: 13752.2132, train_label_loss: 2.0793, 
=============================================================
epoch: 1, val_acc_label: 0.1237, val_label_loss: 2.0795, 
=============================================================
New best
epoch: 2, [batch: 1 / 438], examples_per_second: 237.4838, train_label_loss: 2.0792, 
epoch: 2, [batch: 88 / 438], examples_per_second: 13713.4758, train_label_loss: 2.0792, 
epoch: 2, [batch: 175 / 438], examples_per_second: 13838.1418, train_label_loss: 2.0795, 
epoch: 2, [batch: 263 / 438], examples_per_second: 13735.5721, train_label_loss: 2.0797, 
epoch: 2, [batch: 350 / 438], examples_per_second: 13962.8701, train_label_loss: 2.0794, 
=============================================================
epoch: 2, val_acc_label: 0.1234, val_label_loss: 2.0795, 
=============================================================
New best
epoch: 3, [batch: 1 / 438], examples_per_second: 245.2030, train_label_loss: 2.0793, 
epoch: 3, [batch: 88 / 438], examples_per_second: 13725.6601, train_label_loss: 2.0787, 
epoch: 3, [batch: 175 / 438], examples_per_second: 13856.0155, train_label_loss: 2.0792, 
epoch: 3, [batch: 263 / 438], examples_per_second: 13632.3756, train_label_loss: 2.0793, 
epoch: 3, [batch: 350 / 438], examples_per_second: 13486.7592, train_label_loss: 2.0800, 
=============================================================
epoch: 3, val_acc_label: 0.1260, val_label_loss: 2.0795, 
=============================================================
New best
epoch: 4, [batch: 1 / 438], examples_per_second: 249.0654, train_label_loss: 2.0797, 
epoch: 4, [batch: 88 / 438], examples_per_second: 13744.4454, train_label_loss: 2.0795, 
epoch: 4, [batch: 175 / 438], examples_per_second: 13805.1901, train_label_loss: 2.0798, 
epoch: 4, [batch: 263 / 438], examples_per_second: 13420.1868, train_label_loss: 2.0800, 
epoch: 4, [batch: 350 / 438], examples_per_second: 13492.5427, train_label_loss: 2.0801, 
=============================================================
epoch: 4, val_acc_label: 0.1259, val_label_loss: 2.0794, 
=============================================================
New best
epoch: 5, [batch: 1 / 438], examples_per_second: 248.6992, train_label_loss: 2.0791, 
epoch: 5, [batch: 88 / 438], examples_per_second: 13591.5480, train_label_loss: 2.0794, 
epoch: 5, [batch: 175 / 438], examples_per_second: 13614.2938, train_label_loss: 2.0799, 
epoch: 5, [batch: 263 / 438], examples_per_second: 13666.0258, train_label_loss: 2.0796, 
epoch: 5, [batch: 350 / 438], examples_per_second: 13680.5374, train_label_loss: 2.0802, 
=============================================================
epoch: 5, val_acc_label: 0.1260, val_label_loss: 2.0795, 
=============================================================
epoch: 6, [batch: 1 / 438], examples_per_second: 244.9016, train_label_loss: 2.0797, 
epoch: 6, [batch: 88 / 438], examples_per_second: 13827.3738, train_label_loss: 2.0802, 
epoch: 6, [batch: 175 / 438], examples_per_second: 13435.3336, train_label_loss: 2.0789, 
epoch: 6, [batch: 263 / 438], examples_per_second: 13411.3961, train_label_loss: 2.0792, 
epoch: 6, [batch: 350 / 438], examples_per_second: 13247.0563, train_label_loss: 2.0791, 
=============================================================
epoch: 6, val_acc_label: 0.1280, val_label_loss: 2.0794, 
=============================================================
epoch: 7, [batch: 1 / 438], examples_per_second: 243.9262, train_label_loss: 2.0795, 
epoch: 7, [batch: 88 / 438], examples_per_second: 13317.1756, train_label_loss: 2.0794, 
epoch: 7, [batch: 175 / 438], examples_per_second: 13385.9730, train_label_loss: 2.0794, 
epoch: 7, [batch: 263 / 438], examples_per_second: 13588.3732, train_label_loss: 2.0795, 
epoch: 7, [batch: 350 / 438], examples_per_second: 13526.4649, train_label_loss: 2.0793, 
=============================================================
epoch: 7, val_acc_label: 0.1239, val_label_loss: 2.0795, 
=============================================================
epoch: 8, [batch: 1 / 438], examples_per_second: 245.5610, train_label_loss: 2.0794, 
epoch: 8, [batch: 88 / 438], examples_per_second: 13456.6867, train_label_loss: 2.0798, 
epoch: 8, [batch: 175 / 438], examples_per_second: 13449.4989, train_label_loss: 2.0793, 
epoch: 8, [batch: 263 / 438], examples_per_second: 13536.5276, train_label_loss: 2.0789, 
epoch: 8, [batch: 350 / 438], examples_per_second: 13352.1460, train_label_loss: 2.0794, 
=============================================================
epoch: 8, val_acc_label: 0.1234, val_label_loss: 2.0795, 
=============================================================
epoch: 9, [batch: 1 / 438], examples_per_second: 397.5167, train_label_loss: 2.0793, 
epoch: 9, [batch: 88 / 438], examples_per_second: 22910.9080, train_label_loss: 2.0786, 
epoch: 9, [batch: 175 / 438], examples_per_second: 22904.0604, train_label_loss: 2.0792, 
epoch: 9, [batch: 263 / 438], examples_per_second: 22798.1829, train_label_loss: 2.0792, 
epoch: 9, [batch: 350 / 438], examples_per_second: 22903.2630, train_label_loss: 2.0792, 
=============================================================
epoch: 9, val_acc_label: 0.1260, val_label_loss: 2.0795, 
=============================================================
epoch: 10, [batch: 1 / 438], examples_per_second: 430.1799, train_label_loss: 2.0794, 
epoch: 10, [batch: 88 / 438], examples_per_second: 22958.2791, train_label_loss: 2.0791, 
epoch: 10, [batch: 175 / 438], examples_per_second: 23038.9651, train_label_loss: 2.0795, 
epoch: 10, [batch: 263 / 438], examples_per_second: 23010.2924, train_label_loss: 2.0793, 
epoch: 10, [batch: 350 / 438], examples_per_second: 19640.3097, train_label_loss: 2.0794, 
=============================================================
epoch: 10, val_acc_label: 0.1239, val_label_loss: 2.0795, 
=============================================================
epoch: 11, [batch: 1 / 438], examples_per_second: 245.9239, train_label_loss: 2.0794, 
epoch: 11, [batch: 88 / 438], examples_per_second: 13358.9244, train_label_loss: 2.0793, 
epoch: 11, [batch: 175 / 438], examples_per_second: 13525.3741, train_label_loss: 2.0802, 
epoch: 11, [batch: 263 / 438], examples_per_second: 13471.9731, train_label_loss: 2.0795, 
epoch: 11, [batch: 350 / 438], examples_per_second: 13501.5991, train_label_loss: 2.0791, 
=============================================================
epoch: 11, val_acc_label: 0.1234, val_label_loss: 2.0795, 
=============================================================
epoch: 12, [batch: 1 / 438], examples_per_second: 248.5405, train_label_loss: 2.0792, 
epoch: 12, [batch: 88 / 438], examples_per_second: 13912.1397, train_label_loss: 2.0788, 
epoch: 12, [batch: 175 / 438], examples_per_second: 13728.9744, train_label_loss: 2.0797, 
epoch: 12, [batch: 263 / 438], examples_per_second: 13911.8002, train_label_loss: 2.0796, 
epoch: 12, [batch: 350 / 438], examples_per_second: 13934.4962, train_label_loss: 2.0796, 
=============================================================
epoch: 12, val_acc_label: 0.1234, val_label_loss: 2.0795, 
=============================================================
epoch: 13, [batch: 1 / 438], examples_per_second: 254.5199, train_label_loss: 2.0800, 
epoch: 13, [batch: 88 / 438], examples_per_second: 13544.2274, train_label_loss: 2.0795, 
epoch: 13, [batch: 175 / 438], examples_per_second: 13423.0669, train_label_loss: 2.0791, 
epoch: 13, [batch: 263 / 438], examples_per_second: 13435.0552, train_label_loss: 2.0795, 
epoch: 13, [batch: 350 / 438], examples_per_second: 13476.0040, train_label_loss: 2.0799, 
=============================================================
epoch: 13, val_acc_label: 0.1234, val_label_loss: 2.0795, 
=============================================================
epoch: 14, [batch: 1 / 438], examples_per_second: 244.3201, train_label_loss: 2.0796, 
epoch: 14, [batch: 88 / 438], examples_per_second: 13600.0289, train_label_loss: 2.0800, 
epoch: 14, [batch: 175 / 438], examples_per_second: 13774.7244, train_label_loss: 2.0793, 
epoch: 14, [batch: 263 / 438], examples_per_second: 13596.6305, train_label_loss: 2.0795, 
epoch: 14, [batch: 350 / 438], examples_per_second: 13662.2040, train_label_loss: 2.0796, 
=============================================================
epoch: 14, val_acc_label: 0.1237, val_label_loss: 2.0796, 
=============================================================
epoch: 15, [batch: 1 / 438], examples_per_second: 249.3227, train_label_loss: 2.0795, 
epoch: 15, [batch: 88 / 438], examples_per_second: 13453.6808, train_label_loss: 2.0798, 
epoch: 15, [batch: 175 / 438], examples_per_second: 13414.6126, train_label_loss: 2.0789, 
epoch: 15, [batch: 263 / 438], examples_per_second: 13289.6521, train_label_loss: 2.0790, 
epoch: 15, [batch: 350 / 438], examples_per_second: 13801.2741, train_label_loss: 2.0795, 
=============================================================
epoch: 15, val_acc_label: 0.1259, val_label_loss: 2.0795, 
=============================================================
Patience (10) exhausted
Source Test Label Accuracy: 0.12508333333333332 Target Test Label Accuracy: 0.12671875
Source Val Label Accuracy: 0.12591666666666668 Target Val Label Accuracy: 0.1246875
[CONDUCTOR]: Experiment proc ended
[CONDUCTOR]: Flush the output buffer
[CONDUCTOR]: Done flushing
